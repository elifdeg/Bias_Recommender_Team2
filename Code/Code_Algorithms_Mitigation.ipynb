{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b67ffa35-f408-4ea4-98db-8a817ef2c838",
   "metadata": {},
   "source": [
    " # Reproducing Popularity and Gender Bias in Music Recommenders with Cross-Domain Extension to Books\n",
    " \n",
    " Team 2<br>\n",
    "Elif Deger<br>\n",
    "Nataliya Kharitonova\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7162d86b-9cad-46b1-9b3b-ec4b0e1a7383",
   "metadata": {},
   "source": [
    "This notebook contains the code to replicate the study by Lesota et al., including the bias mitigation techniques we employed.\n",
    "\n",
    "In section 1 we begin by running seven recommender algorithms on the LFM-2b dataset. Some of the code was executed within Jupyter notebooks, while other parts were run locally using PyCharm. The results of each algorithm are presented at the end of their respective code sections and are collectively analysed after all seven have been executed in section 1.1\n",
    "\n",
    "Next, bias mitigation techniques are applied to three selected algorithms in section 1.2, and analysed in section 1.3.  The notebook then repeats the same process on the Book-Crossing dataset to evaluate the generalizability of the findings in section 2.\n",
    "\n",
    "In Section 3 we provide a final comparison of both datasets and in section 4 we comment on generalizability of results from LFM-2b to Book-Crossing dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08d01b0",
   "metadata": {},
   "source": [
    "# 1. LAST FM DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07b7185",
   "metadata": {},
   "source": [
    "* The LFM-2b dataset used in our study is considered derivative work according to paragraph 4.1 of Last.fmâ€™s API Terms of Service (https://www.last.fm/api/tos). The Last.fm Terms of Service further grant us a license to use this data (according to paragraph 4).\n",
    "\n",
    "* The exact dataset we are using is LFM-2b Dataset, which is a subset of LAST FM dataset and an extension of the LFM-1b dataset and was created by the respective authors of the paper we are replicating \"Analyzing Item Popularity Bias of Music Recommender Systems: Are Different Genders Equally Affected?\". Unfortunately due to licensing issues (see: https://www.cp.jku.at/datasets/LFM-2b/) the dataset is not avaliable to public. We had to contact the authors ourselves, and they were very kind to provide us with the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dafb053",
   "metadata": {},
   "source": [
    "## Upload dataset\n",
    "\n",
    "We start by uploading the files we created during the data processing step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1359c2d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted fold_1.zip to folds\\fold_1\n",
      "Extracted fold_2.zip to folds\\fold_2\n",
      "Extracted fold_3.zip to folds\\fold_3\n",
      "Extracted fold_4.zip to folds\\fold_4\n",
      "Extracted fold_5.zip to folds\\fold_5\n",
      "Loaded fold_1 datasets\n",
      "Loaded fold_2 datasets\n",
      "Loaded fold_3 datasets\n",
      "Loaded fold_4 datasets\n",
      "Loaded fold_5 datasets\n",
      "\n",
      " Sample from fold_1 train set:\n",
      "   user_id country  age gender        creation_time  track_id  binary_listen\n",
      "0    17629      ES   28      m  2008-01-01 01:57:59  49789869              1\n",
      "1    17629      ES   28      m  2008-01-01 01:57:59  50612073              1\n",
      "2    17629      ES   28      m  2008-01-01 01:57:59  45885619              1\n",
      "3    17629      ES   28      m  2008-01-01 01:57:59  49980953              1\n",
      "4    17629      ES   28      m  2008-01-01 01:57:59  49986065              1\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Path to ZIPs\n",
    "zip_folder_path = \"./\"  \n",
    "\n",
    "# Extracting all our 5 folds\n",
    "extracted_dir = \"folds\"\n",
    "os.makedirs(extracted_dir, exist_ok=True)\n",
    "\n",
    "# Step 1: Extract all zip files\n",
    "for i in range(1, 6):\n",
    "    zip_filename = f\"fold_{i}.zip\"\n",
    "    zip_path = os.path.join(zip_folder_path, zip_filename)\n",
    "    \n",
    "    fold_extract_path = os.path.join(extracted_dir, f\"fold_{i}\")\n",
    "    os.makedirs(fold_extract_path, exist_ok=True)\n",
    "    \n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(fold_extract_path)\n",
    "    print(f\"Extracted {zip_filename} to {fold_extract_path}\")\n",
    "\n",
    "# Step 2: Load all datasets into a dictionary\n",
    "folds_data = {}\n",
    "\n",
    "for i in range(1, 6):\n",
    "    base_fold_path = os.path.join(extracted_dir, f\"fold_{i}\")\n",
    "    \n",
    "    subdirs = [d for d in os.listdir(base_fold_path) if os.path.isdir(os.path.join(base_fold_path, d))]\n",
    "    if subdirs:\n",
    "        fold_path = os.path.join(base_fold_path, subdirs[0])\n",
    "    else:\n",
    "        fold_path = base_fold_path\n",
    "    \n",
    "    data = {\n",
    "        'train': pd.read_csv(os.path.join(fold_path, 'train.tsv'), sep='\\t'),\n",
    "        'val_input': pd.read_csv(os.path.join(fold_path, 'val_input.tsv'), sep='\\t'),\n",
    "        'val_target': pd.read_csv(os.path.join(fold_path, 'val_target.tsv'), sep='\\t'),\n",
    "        'test_input': pd.read_csv(os.path.join(fold_path, 'test_input.tsv'), sep='\\t'),\n",
    "        'test_target': pd.read_csv(os.path.join(fold_path, 'test_target.tsv'), sep='\\t'),\n",
    "    }\n",
    "    folds_data[f'fold_{i}'] = data\n",
    "    print(f\"Loaded fold_{i} datasets\")\n",
    "\n",
    "# Verify\n",
    "print(\"\\n Sample from fold_1 train set:\")\n",
    "print(folds_data['fold_1']['train'].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7de4f2f",
   "metadata": {},
   "source": [
    "## POP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ae650972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Validation Recall@10: 0.0226 | NDCG@10: 0.0293\n",
      "Fold 1 Test Recall@10: 0.0210 | NDCG@10: 0.0320\n",
      "Fold 2 Validation Recall@10: 0.0231 | NDCG@10: 0.0292\n",
      "Fold 2 Test Recall@10: 0.0188 | NDCG@10: 0.0326\n",
      "Fold 3 Validation Recall@10: 0.0228 | NDCG@10: 0.0291\n",
      "Fold 3 Test Recall@10: 0.0205 | NDCG@10: 0.0350\n",
      "Fold 4 Validation Recall@10: 0.0225 | NDCG@10: 0.0295\n",
      "Fold 4 Test Recall@10: 0.0208 | NDCG@10: 0.0341\n",
      "Fold 5 Validation Recall@10: 0.0228 | NDCG@10: 0.0288\n",
      "Fold 5 Test Recall@10: 0.0226 | NDCG@10: 0.0354\n",
      "\n",
      "Average Validation Recall@10: 0.0228\n",
      "Average Validation NDCG@10:   0.0292\n",
      "Average Test Recall@10:       0.0207\n",
      "Average Test NDCG@10:         0.0338\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def recall_at_k(recommended, ground_truth, k=10):\n",
    "    recommended_k = recommended[:k]\n",
    "    hits = len(set(recommended_k) & set(ground_truth))\n",
    "    return hits / len(ground_truth) if ground_truth else 0\n",
    "\n",
    "def ndcg_at_k(recommended, ground_truth, k=10):\n",
    "    recommended_k = recommended[:k]\n",
    "    gains = [1 if item in ground_truth else 0 for item in recommended_k]\n",
    "    dcg = sum(gain / np.log2(idx + 2) for idx, gain in enumerate(gains))\n",
    "\n",
    "    ideal_gains = [1] * min(len(ground_truth), k)\n",
    "    idcg = sum(gain / np.log2(idx + 2) for idx, gain in enumerate(ideal_gains))\n",
    "\n",
    "    return dcg / idcg if idcg > 0 else 0\n",
    "\n",
    "def evaluate_pop(fold_data, input_key, target_key, k=10):\n",
    "    train_df = fold_data['train']\n",
    "    input_df = fold_data[input_key]\n",
    "    target_df = fold_data[target_key]\n",
    "\n",
    "    item_popularity = train_df.groupby('track_id')['binary_listen'].sum().sort_values(ascending=False)\n",
    "    popular_tracks = item_popularity.index.tolist()\n",
    "\n",
    "    input_groups = input_df.groupby('user_id')['track_id'].apply(set).to_dict()\n",
    "    target_groups = target_df.groupby('user_id')['track_id'].apply(set).to_dict()\n",
    "\n",
    "    user_ids = input_groups.keys()\n",
    "    recalls = []\n",
    "    ndcgs = []\n",
    "    user_recommendations = dict()\n",
    "\n",
    "    for user in user_ids:\n",
    "        known_tracks = input_groups[user]\n",
    "        true_tracks = target_groups.get(user, set())\n",
    "\n",
    "        recommendations = []\n",
    "        for track in popular_tracks:\n",
    "            if track not in known_tracks:\n",
    "                recommendations.append(track)\n",
    "                if len(recommendations) == k:\n",
    "                    break\n",
    "\n",
    "        recalls.append(recall_at_k(recommendations, true_tracks, k))\n",
    "        ndcgs.append(ndcg_at_k(recommendations, true_tracks, k))\n",
    "        user_recommendations[user] = recommendations\n",
    "\n",
    "    avg_recall = sum(recalls) / len(recalls)\n",
    "    avg_ndcg = sum(ndcgs) / len(ndcgs)\n",
    "\n",
    "    return avg_recall, avg_ndcg, user_recommendations, target_groups\n",
    "\n",
    "# --- Main Evaluation Loop ---\n",
    "all_val_recalls = []\n",
    "all_val_ndcgs = []\n",
    "all_test_recalls = []\n",
    "all_test_ndcgs = []\n",
    "\n",
    "for i in range(1, 6):\n",
    "    fold_key = f'fold_{i}'\n",
    "    fold_data = folds_data[fold_key]\n",
    "\n",
    "    val_recall, val_ndcg, val_recs, val_targets = evaluate_pop(fold_data, 'val_input', 'val_target', k=10)\n",
    "    test_recall, test_ndcg, test_recs, test_targets = evaluate_pop(fold_data, 'test_input', 'test_target', k=10)\n",
    "\n",
    "    print(f\"Fold {i} Validation Recall@10: {val_recall:.4f} | NDCG@10: {val_ndcg:.4f}\")\n",
    "    print(f\"Fold {i} Test Recall@10: {test_recall:.4f} | NDCG@10: {test_ndcg:.4f}\")\n",
    "\n",
    "    all_val_recalls.append(val_recall)\n",
    "    all_val_ndcgs.append(val_ndcg)\n",
    "    all_test_recalls.append(test_recall)\n",
    "    all_test_ndcgs.append(test_ndcg)\n",
    "\n",
    "\n",
    "print(f\"\\nAverage Validation Recall@10: {np.mean(all_val_recalls):.4f}\")\n",
    "print(f\"Average Validation NDCG@10:   {np.mean(all_val_ndcgs):.4f}\")\n",
    "print(f\"Average Test Recall@10:       {np.mean(all_test_recalls):.4f}\")\n",
    "print(f\"Average Test NDCG@10:         {np.mean(all_test_ndcgs):.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "44f1caf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khari\\AppData\\Local\\Temp\\ipykernel_3292\\2200500438.py:43: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  '%Î”Skew': percent_delta_metric(stats.skew(rec_vals), stats.skew(hist_vals)),\n",
      "C:\\Users\\khari\\AppData\\Local\\Temp\\ipykernel_3292\\2200500438.py:44: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  '%Î”Kurtosis': percent_delta_metric(stats.kurtosis(rec_vals), stats.kurtosis(hist_vals)),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Test NDCG@10: 0.0320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khari\\AppData\\Local\\Temp\\ipykernel_3292\\2200500438.py:43: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  '%Î”Skew': percent_delta_metric(stats.skew(rec_vals), stats.skew(hist_vals)),\n",
      "C:\\Users\\khari\\AppData\\Local\\Temp\\ipykernel_3292\\2200500438.py:44: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  '%Î”Kurtosis': percent_delta_metric(stats.kurtosis(rec_vals), stats.kurtosis(hist_vals)),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Test NDCG@10: 0.0326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khari\\AppData\\Local\\Temp\\ipykernel_3292\\2200500438.py:43: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  '%Î”Skew': percent_delta_metric(stats.skew(rec_vals), stats.skew(hist_vals)),\n",
      "C:\\Users\\khari\\AppData\\Local\\Temp\\ipykernel_3292\\2200500438.py:44: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  '%Î”Kurtosis': percent_delta_metric(stats.kurtosis(rec_vals), stats.kurtosis(hist_vals)),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Test NDCG@10: 0.0350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khari\\AppData\\Local\\Temp\\ipykernel_3292\\2200500438.py:43: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  '%Î”Skew': percent_delta_metric(stats.skew(rec_vals), stats.skew(hist_vals)),\n",
      "C:\\Users\\khari\\AppData\\Local\\Temp\\ipykernel_3292\\2200500438.py:44: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  '%Î”Kurtosis': percent_delta_metric(stats.kurtosis(rec_vals), stats.kurtosis(hist_vals)),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 Test NDCG@10: 0.0341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khari\\AppData\\Local\\Temp\\ipykernel_3292\\2200500438.py:43: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  '%Î”Skew': percent_delta_metric(stats.skew(rec_vals), stats.skew(hist_vals)),\n",
      "C:\\Users\\khari\\AppData\\Local\\Temp\\ipykernel_3292\\2200500438.py:44: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  '%Î”Kurtosis': percent_delta_metric(stats.kurtosis(rec_vals), stats.kurtosis(hist_vals)),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 Test NDCG@10: 0.0354\n",
      "\n",
      "ðŸ“Š POP Model Popularity Bias Results:\n",
      "           | %Î”Mean   | %Î”Median | %Î”Var    | %Î”Skew   | %Î”Kurtosis |    KL    | KendallÏ„ | NDCG@10 \n",
      "-----------------------------------------------------------------------------------------------\n",
      "All       |    956.08 |   2321.62 |    310.19 |      0.00 |    -86.52 |      5.68 |      0.61 |   0.0341 \n",
      "Î”Female   |    138.43 |    579.05 |     81.30 |     -4.03 |     23.69 |      0.66 |     -0.01 \n",
      "Î”Male     |    -74.30 |   -254.76 |    -32.56 |      0.00 |     -2.22 |     -0.24 |      0.00 \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "def percent_delta_metric(m_reco, m_hist):\n",
    "    return 100 * (m_reco - m_hist) / m_hist if m_hist != 0 else 0.0\n",
    "\n",
    "def kl_divergence(p, q):\n",
    "    epsilon = 1e-10\n",
    "    p = np.array(p) + epsilon\n",
    "    q = np.array(q) + epsilon\n",
    "    return np.sum(p * np.log(p / q))\n",
    "\n",
    "def kendalls_tau(x, y):\n",
    "    return stats.kendalltau(x, y).correlation\n",
    "\n",
    "def pop_bias_metrics(train_df, recommendations, targets, user_info, top_k=10):\n",
    "    popularity_dict = train_df['track_id'].value_counts().to_dict()\n",
    "    all_pop = np.array(list(popularity_dict.values()))\n",
    "    bins = np.quantile(all_pop, np.linspace(0, 1, 11))\n",
    "\n",
    "    def bin_distribution(vals, bins):\n",
    "        binned_counts, _ = np.histogram(vals, bins=bins)\n",
    "        return binned_counts / binned_counts.sum() if binned_counts.sum() > 0 else np.zeros_like(binned_counts, dtype=float)\n",
    "\n",
    "    user_metrics = []\n",
    "\n",
    "    for user_id, rec_tracks in recommendations.items():\n",
    "        true_tracks = targets.get(user_id, [])\n",
    "        if not true_tracks:\n",
    "            continue\n",
    "        hist_tracks = true_tracks  # or combine input + target if you want full history\n",
    "\n",
    "        hist_vals = [popularity_dict.get(t, 0) for t in hist_tracks]\n",
    "        rec_vals = [popularity_dict.get(t, 0) for t in rec_tracks]\n",
    "\n",
    "        metrics = {\n",
    "            'user_id': user_id,\n",
    "            'gender': user_info.get(user_id, None),\n",
    "            '%Î”Mean': percent_delta_metric(np.mean(rec_vals), np.mean(hist_vals)),\n",
    "            '%Î”Median': percent_delta_metric(np.median(rec_vals), np.median(hist_vals)),\n",
    "            '%Î”Var': percent_delta_metric(np.var(rec_vals), np.var(hist_vals)),\n",
    "            '%Î”Skew': percent_delta_metric(stats.skew(rec_vals), stats.skew(hist_vals)),\n",
    "            '%Î”Kurtosis': percent_delta_metric(stats.kurtosis(rec_vals), stats.kurtosis(hist_vals)),\n",
    "        }\n",
    "\n",
    "        hist_binned = bin_distribution(hist_vals, bins)\n",
    "        rec_binned = bin_distribution(rec_vals, bins)\n",
    "\n",
    "        metrics['KL'] = kl_divergence(hist_binned, rec_binned)\n",
    "        metrics['Kendall_tau'] = kendalls_tau(hist_binned, rec_binned)\n",
    "\n",
    "        user_metrics.append(metrics)\n",
    "\n",
    "    return user_metrics\n",
    "\n",
    "\n",
    "# ---- Main loop ----\n",
    "all_metrics = []\n",
    "gender_metrics = {'f': [], 'm': []}\n",
    "all_ndcgs = []\n",
    "\n",
    "for i in range(1, 6):\n",
    "    fold_key = f'fold_{i}'\n",
    "    fold_data = folds_data[fold_key]\n",
    "\n",
    "    train_df = fold_data['train']\n",
    "\n",
    "    val_recall, val_ndcg, val_recs, val_targets = evaluate_pop(fold_data, 'val_input', 'val_target', k=10)\n",
    "    test_recall, test_ndcg, test_recs, test_targets = evaluate_pop(fold_data, 'test_input', 'test_target', k=10)\n",
    "\n",
    "    all_ndcgs.append(test_ndcg)  \n",
    "\n",
    "    combined_users = pd.concat([\n",
    "        train_df[['user_id', 'gender']],\n",
    "        fold_data['test_input'][['user_id', 'gender']],\n",
    "        fold_data['val_input'][['user_id', 'gender']],\n",
    "    ]).drop_duplicates()\n",
    "    user_info = combined_users.set_index('user_id')['gender'].to_dict()\n",
    "\n",
    "    user_metrics = pop_bias_metrics(train_df, test_recs, test_targets, user_info, top_k=10)\n",
    "\n",
    "    if user_metrics:\n",
    "        df = pd.DataFrame(user_metrics)\n",
    "        all_metrics.append(df.median(numeric_only=True).to_dict())\n",
    "\n",
    "        for gender in ['f', 'm']:\n",
    "            gdf = df[df['gender'] == gender]\n",
    "            if not gdf.empty:\n",
    "                gender_metrics[gender].append(gdf.median(numeric_only=True).to_dict())\n",
    "\n",
    "    print(f\"Fold {i} Test NDCG@10: {test_ndcg:.4f}\")\n",
    "\n",
    "\n",
    "def average_metrics(metrics_list, agg_func=np.median):\n",
    "    keys = metrics_list[0].keys()\n",
    "    return {k: agg_func([m[k] for m in metrics_list if k in m]) for k in keys}\n",
    "\n",
    "# Median aggregation\n",
    "final_all_median = average_metrics(all_metrics, agg_func=np.median)\n",
    "final_female_median = average_metrics(gender_metrics['f'], agg_func=np.median) if gender_metrics['f'] else None\n",
    "final_male_median = average_metrics(gender_metrics['m'], agg_func=np.median) if gender_metrics['m'] else None\n",
    "final_ndcg_median = np.median(all_ndcgs)\n",
    "\n",
    "\n",
    "def delta(group, overall):\n",
    "    return {k: overall[k] - group.get(k, 0) for k in overall if k in group}\n",
    "\n",
    "delta_f_median = delta(final_female_median, final_all_median) if final_female_median else {}\n",
    "delta_m_median = delta(final_male_median, final_all_median) if final_male_median else {}\n",
    "\n",
    "def print_metrics(label, metrics, include_ndcg):\n",
    "    print(f\"{label:<10}\", end=\"\")\n",
    "    for k in ['%Î”Mean', '%Î”Median', '%Î”Var', '%Î”Skew', '%Î”Kurtosis', 'KL', 'Kendall_tau']:\n",
    "        v = metrics.get(k, 0)\n",
    "        print(f\"| {v:9.2f} \", end=\"\")\n",
    "    if include_ndcg:\n",
    "        print(f\"| {metrics.get('NDCG@10', 0):8.4f} \", end=\"\")\n",
    "    print()\n",
    "\n",
    "final_all_median['NDCG@10'] = final_ndcg_median\n",
    "\n",
    "if final_female_median:\n",
    "    final_female_median['NDCG@10'] = final_ndcg_median  \n",
    "if final_male_median:\n",
    "    final_male_median['NDCG@10'] = final_ndcg_median\n",
    "\n",
    "\n",
    "print(\"\\nðŸ“Š POP Model Popularity Bias Results:\")\n",
    "print(\"           | %Î”Mean   | %Î”Median | %Î”Var    | %Î”Skew   | %Î”Kurtosis |    KL    | KendallÏ„ | NDCG@10 \")\n",
    "print(\"-\" * 95)\n",
    "print_metrics(\"All\", final_all_median, include_ndcg=True)\n",
    "if final_female_median:\n",
    "    print_metrics(\"Î”Female\", delta_f_median, include_ndcg=False)\n",
    "if final_male_median:\n",
    "    print_metrics(\"Î”Male\", delta_m_median, include_ndcg=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04a7a39",
   "metadata": {},
   "source": [
    "## RAND:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bf34fa2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Validation Recall@10: 0.0000 | NDCG@10: 0.0001\n",
      "Fold 1 Test Recall@10: 0.0001 | NDCG@10: 0.0001\n",
      "Fold 2 Validation Recall@10: 0.0000 | NDCG@10: 0.0000\n",
      "Fold 2 Test Recall@10: 0.0001 | NDCG@10: 0.0002\n",
      "Fold 3 Validation Recall@10: 0.0001 | NDCG@10: 0.0002\n",
      "Fold 3 Test Recall@10: 0.0000 | NDCG@10: 0.0001\n",
      "Fold 4 Validation Recall@10: 0.0001 | NDCG@10: 0.0001\n",
      "Fold 4 Test Recall@10: 0.0001 | NDCG@10: 0.0001\n",
      "Fold 5 Validation Recall@10: 0.0002 | NDCG@10: 0.0002\n",
      "Fold 5 Test Recall@10: 0.0000 | NDCG@10: 0.0002\n",
      "\n",
      "Average Validation Recall@10: 0.0001\n",
      "Average Validation NDCG@10:   0.0001\n",
      "Average Test Recall@10:       0.0001\n",
      "Average Test NDCG@10:         0.0002\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def evaluate_rand(fold_data, input_key, target_key, k=10, seed=42):\n",
    "    random.seed(seed)\n",
    "    train_df = fold_data['train']\n",
    "    input_df = fold_data[input_key]\n",
    "    target_df = fold_data[target_key]\n",
    "\n",
    "    # All unique tracks in training data\n",
    "    all_tracks = set(train_df['track_id'].unique())\n",
    "\n",
    "    input_groups = input_df.groupby('user_id')['track_id'].apply(set).to_dict()\n",
    "    target_groups = target_df.groupby('user_id')['track_id'].apply(set).to_dict()\n",
    "\n",
    "    user_ids = input_groups.keys()\n",
    "    recalls = []\n",
    "    ndcgs = []\n",
    "    user_recommendations = dict()\n",
    "\n",
    "    for user in user_ids:\n",
    "        known_tracks = input_groups[user]\n",
    "        true_tracks = target_groups.get(user, set())\n",
    "\n",
    "        # all tracks excluding known tracks\n",
    "        candidate_tracks = list(all_tracks - known_tracks)\n",
    "\n",
    "        # Randomly sample k recommendations\n",
    "        if len(candidate_tracks) >= k:\n",
    "            recommendations = random.sample(candidate_tracks, k)\n",
    "        else:\n",
    "            recommendations = candidate_tracks\n",
    "\n",
    "        recalls.append(recall_at_k(recommendations, true_tracks, k))\n",
    "        ndcgs.append(ndcg_at_k(recommendations, true_tracks, k))\n",
    "        user_recommendations[user] = recommendations\n",
    "\n",
    "    avg_recall = sum(recalls) / len(recalls) if recalls else 0\n",
    "    avg_ndcg = sum(ndcgs) / len(ndcgs) if ndcgs else 0\n",
    "\n",
    "    return avg_recall, avg_ndcg, user_recommendations, target_groups\n",
    "\n",
    "all_val_recalls = []\n",
    "all_val_ndcgs = []\n",
    "all_test_recalls = []\n",
    "all_test_ndcgs = []\n",
    "\n",
    "for i in range(1, 6):\n",
    "    fold_key = f'fold_{i}'\n",
    "    fold_data = folds_data[fold_key]\n",
    "\n",
    "    val_recall, val_ndcg, val_recs, val_targets = evaluate_rand(fold_data, 'val_input', 'val_target', k=10)\n",
    "    test_recall, test_ndcg, test_recs, test_targets = evaluate_rand(fold_data, 'test_input', 'test_target', k=10)\n",
    "\n",
    "    print(f\"Fold {i} Validation Recall@10: {val_recall:.4f} | NDCG@10: {val_ndcg:.4f}\")\n",
    "    print(f\"Fold {i} Test Recall@10: {test_recall:.4f} | NDCG@10: {test_ndcg:.4f}\")\n",
    "\n",
    "    all_val_recalls.append(val_recall)\n",
    "    all_val_ndcgs.append(val_ndcg)\n",
    "    all_test_recalls.append(test_recall)\n",
    "    all_test_ndcgs.append(test_ndcg)\n",
    "\n",
    "print(f\"\\nAverage Validation Recall@10: {np.mean(all_val_recalls):.4f}\")\n",
    "print(f\"Average Validation NDCG@10:   {np.mean(all_val_ndcgs):.4f}\")\n",
    "print(f\"Average Test Recall@10:       {np.mean(all_test_recalls):.4f}\")\n",
    "print(f\"Average Test NDCG@10:         {np.mean(all_test_ndcgs):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a8d20ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khari\\AppData\\Local\\Temp\\ipykernel_3292\\437178410.py:97: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  '%Î”Skew': percent_delta_metric(stats.skew(rec_vals), stats.skew(hist_vals)),\n",
      "C:\\Users\\khari\\AppData\\Local\\Temp\\ipykernel_3292\\437178410.py:98: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  '%Î”Kurtosis': percent_delta_metric(stats.kurtosis(rec_vals), stats.kurtosis(hist_vals)),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Test Recall@10: 0.0001 | NDCG@10: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khari\\AppData\\Local\\Temp\\ipykernel_3292\\437178410.py:97: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  '%Î”Skew': percent_delta_metric(stats.skew(rec_vals), stats.skew(hist_vals)),\n",
      "C:\\Users\\khari\\AppData\\Local\\Temp\\ipykernel_3292\\437178410.py:98: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  '%Î”Kurtosis': percent_delta_metric(stats.kurtosis(rec_vals), stats.kurtosis(hist_vals)),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Test Recall@10: 0.0001 | NDCG@10: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khari\\AppData\\Local\\Temp\\ipykernel_3292\\437178410.py:97: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  '%Î”Skew': percent_delta_metric(stats.skew(rec_vals), stats.skew(hist_vals)),\n",
      "C:\\Users\\khari\\AppData\\Local\\Temp\\ipykernel_3292\\437178410.py:98: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  '%Î”Kurtosis': percent_delta_metric(stats.kurtosis(rec_vals), stats.kurtosis(hist_vals)),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Test Recall@10: 0.0000 | NDCG@10: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khari\\AppData\\Local\\Temp\\ipykernel_3292\\437178410.py:97: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  '%Î”Skew': percent_delta_metric(stats.skew(rec_vals), stats.skew(hist_vals)),\n",
      "C:\\Users\\khari\\AppData\\Local\\Temp\\ipykernel_3292\\437178410.py:98: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  '%Î”Kurtosis': percent_delta_metric(stats.kurtosis(rec_vals), stats.kurtosis(hist_vals)),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 Test Recall@10: 0.0001 | NDCG@10: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khari\\AppData\\Local\\Temp\\ipykernel_3292\\437178410.py:97: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  '%Î”Skew': percent_delta_metric(stats.skew(rec_vals), stats.skew(hist_vals)),\n",
      "C:\\Users\\khari\\AppData\\Local\\Temp\\ipykernel_3292\\437178410.py:98: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  '%Î”Kurtosis': percent_delta_metric(stats.kurtosis(rec_vals), stats.kurtosis(hist_vals)),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 Test Recall@10: 0.0000 | NDCG@10: 0.0002\n",
      "\n",
      "ðŸ“Š RAND Model Popularity Bias Results:\n",
      "           | %Î”Mean   | %Î”Median | %Î”Var    | %Î”Skew   | %Î”Kurtosis |    KL    | KendallÏ„ | NDCG@10 \n",
      "-----------------------------------------------------------------------------------------------\n",
      "All       |    -94.70 |    -94.34 |    -99.64 |      0.00 |    -92.42 |      3.56 |      0.18 |   0.0001 \n",
      "Î”Female   |      0.88 |      1.27 |      0.04 |     -4.85 |      7.60 |      0.31 |      0.02 \n",
      "Î”Male     |     -0.37 |     -0.59 |     -0.02 |      0.00 |     -2.13 |     -0.08 |     -0.01 \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import random\n",
    "\n",
    "# --- Metrics Definitions ---\n",
    "\n",
    "def recall_at_k(recommended, ground_truth, k=10):\n",
    "    recommended_k = recommended[:k]\n",
    "    hits = len(set(recommended_k) & set(ground_truth))\n",
    "    return hits / len(ground_truth) if ground_truth else 0\n",
    "\n",
    "def ndcg_at_k(recommended, ground_truth, k=10):\n",
    "    recommended_k = recommended[:k]\n",
    "    gains = [1 if item in ground_truth else 0 for item in recommended_k]\n",
    "    dcg = sum(gain / np.log2(idx + 2) for idx, gain in enumerate(gains))\n",
    "    ideal_gains = [1] * min(len(ground_truth), k)\n",
    "    idcg = sum(gain / np.log2(idx + 2) for idx, gain in enumerate(ideal_gains))\n",
    "    return dcg / idcg if idcg > 0 else 0\n",
    "\n",
    "# --- RAND recommender evaluation ---\n",
    "\n",
    "def evaluate_rand(fold_data, input_key, target_key, k=10, seed=42):\n",
    "    random.seed(seed)\n",
    "    train_df = fold_data['train']\n",
    "    input_df = fold_data[input_key]\n",
    "    target_df = fold_data[target_key]\n",
    "\n",
    "    all_tracks = set(train_df['track_id'].unique())\n",
    "    input_groups = input_df.groupby('user_id')['track_id'].apply(set).to_dict()\n",
    "    target_groups = target_df.groupby('user_id')['track_id'].apply(set).to_dict()\n",
    "\n",
    "    user_ids = input_groups.keys()\n",
    "    recalls = []\n",
    "    ndcgs = []\n",
    "    user_recommendations = dict()\n",
    "\n",
    "    for user in user_ids:\n",
    "        known_tracks = input_groups[user]\n",
    "        true_tracks = target_groups.get(user, set())\n",
    "\n",
    "        candidate_tracks = list(all_tracks - known_tracks)\n",
    "        if len(candidate_tracks) >= k:\n",
    "            recommendations = random.sample(candidate_tracks, k)\n",
    "        else:\n",
    "            recommendations = candidate_tracks\n",
    "\n",
    "        recalls.append(recall_at_k(recommendations, true_tracks, k))\n",
    "        ndcgs.append(ndcg_at_k(recommendations, true_tracks, k))\n",
    "        user_recommendations[user] = recommendations\n",
    "\n",
    "    avg_recall = np.mean(recalls) if recalls else 0\n",
    "    avg_ndcg = np.mean(ndcgs) if ndcgs else 0\n",
    "\n",
    "    return avg_recall, avg_ndcg, user_recommendations, target_groups\n",
    "\n",
    "# --- Popularity Bias Metrics ---\n",
    "\n",
    "def percent_delta_metric(m_reco, m_hist):\n",
    "    return 100 * (m_reco - m_hist) / m_hist if m_hist != 0 else 0.0\n",
    "\n",
    "def kl_divergence(p, q):\n",
    "    epsilon = 1e-10\n",
    "    p = np.array(p) + epsilon\n",
    "    q = np.array(q) + epsilon\n",
    "    return np.sum(p * np.log(p / q))\n",
    "\n",
    "def kendalls_tau(x, y):\n",
    "    return stats.kendalltau(x, y).correlation\n",
    "\n",
    "def pop_bias_metrics(train_df, recommendations, targets, user_info, top_k=10):\n",
    "    popularity_dict = train_df['track_id'].value_counts().to_dict()\n",
    "    all_pop = np.array(list(popularity_dict.values()))\n",
    "    bins = np.quantile(all_pop, np.linspace(0, 1, 11))\n",
    "\n",
    "    def bin_distribution(vals, bins):\n",
    "        binned_counts, _ = np.histogram(vals, bins=bins)\n",
    "        return binned_counts / binned_counts.sum() if binned_counts.sum() > 0 else np.zeros_like(binned_counts, dtype=float)\n",
    "\n",
    "    user_metrics = []\n",
    "\n",
    "    for user_id, rec_tracks in recommendations.items():\n",
    "        true_tracks = targets.get(user_id, [])\n",
    "        if not true_tracks:\n",
    "            continue\n",
    "        hist_tracks = true_tracks  # you can change if you want to include input history\n",
    "\n",
    "        hist_vals = [popularity_dict.get(t, 0) for t in hist_tracks]\n",
    "        rec_vals = [popularity_dict.get(t, 0) for t in rec_tracks]\n",
    "\n",
    "        metrics = {\n",
    "            'user_id': user_id,\n",
    "            'gender': user_info.get(user_id, None),\n",
    "            '%Î”Mean': percent_delta_metric(np.mean(rec_vals), np.mean(hist_vals)),\n",
    "            '%Î”Median': percent_delta_metric(np.median(rec_vals), np.median(hist_vals)),\n",
    "            '%Î”Var': percent_delta_metric(np.var(rec_vals), np.var(hist_vals)),\n",
    "            '%Î”Skew': percent_delta_metric(stats.skew(rec_vals), stats.skew(hist_vals)),\n",
    "            '%Î”Kurtosis': percent_delta_metric(stats.kurtosis(rec_vals), stats.kurtosis(hist_vals)),\n",
    "        }\n",
    "\n",
    "        hist_binned = bin_distribution(hist_vals, bins)\n",
    "        rec_binned = bin_distribution(rec_vals, bins)\n",
    "\n",
    "        metrics['KL'] = kl_divergence(hist_binned, rec_binned)\n",
    "        metrics['Kendall_tau'] = kendalls_tau(hist_binned, rec_binned)\n",
    "\n",
    "        user_metrics.append(metrics)\n",
    "\n",
    "    return user_metrics\n",
    "\n",
    "# --- Main Evaluation Loop ---\n",
    "\n",
    "all_metrics = []\n",
    "gender_metrics = {'f': [], 'm': []}\n",
    "all_ndcgs = []\n",
    "\n",
    "for i in range(1, 6):\n",
    "    fold_key = f'fold_{i}'\n",
    "    fold_data = folds_data[fold_key]\n",
    "\n",
    "    train_df = fold_data['train']\n",
    "\n",
    "    val_recall, val_ndcg, val_recs, val_targets = evaluate_rand(fold_data, 'val_input', 'val_target', k=10)\n",
    "    test_recall, test_ndcg, test_recs, test_targets = evaluate_rand(fold_data, 'test_input', 'test_target', k=10)\n",
    "\n",
    "    all_ndcgs.append(test_ndcg)\n",
    "\n",
    "    combined_users = pd.concat([\n",
    "        train_df[['user_id', 'gender']],\n",
    "        fold_data['val_input'][['user_id', 'gender']],\n",
    "        fold_data['test_input'][['user_id', 'gender']],\n",
    "    ]).drop_duplicates()\n",
    "    user_info = combined_users.set_index('user_id')['gender'].to_dict()\n",
    "\n",
    "    user_metrics = pop_bias_metrics(train_df, test_recs, test_targets, user_info, top_k=10)\n",
    "\n",
    "    if user_metrics:\n",
    "        df = pd.DataFrame(user_metrics)\n",
    "        all_metrics.append(df.median(numeric_only=True).to_dict())\n",
    "\n",
    "        for gender in ['f', 'm']:\n",
    "            gdf = df[df['gender'] == gender]\n",
    "            if not gdf.empty:\n",
    "                gender_metrics[gender].append(gdf.median(numeric_only=True).to_dict())\n",
    "\n",
    "    print(f\"Fold {i} Test Recall@10: {test_recall:.4f} | NDCG@10: {test_ndcg:.4f}\")\n",
    "\n",
    "\n",
    "def average_metrics(metrics_list, agg_func=np.median):\n",
    "    if not metrics_list:\n",
    "        return {}\n",
    "    keys = metrics_list[0].keys()\n",
    "    return {k: agg_func([m[k] for m in metrics_list if k in m]) for k in keys}\n",
    "\n",
    "final_all_median = average_metrics(all_metrics)\n",
    "final_female_median = average_metrics(gender_metrics['f']) if gender_metrics['f'] else None\n",
    "final_male_median = average_metrics(gender_metrics['m']) if gender_metrics['m'] else None\n",
    "final_ndcg_median = np.median(all_ndcgs) if all_ndcgs else 0\n",
    "\n",
    "def delta(group, overall):\n",
    "    return {k: overall[k] - group.get(k, 0) for k in overall if k in group}\n",
    "\n",
    "delta_f_median = delta(final_female_median, final_all_median) if final_female_median else {}\n",
    "delta_m_median = delta(final_male_median, final_all_median) if final_male_median else {}\n",
    "\n",
    "def print_metrics(label, metrics, include_ndcg):\n",
    "    print(f\"{label:<10}\", end=\"\")\n",
    "    for k in ['%Î”Mean', '%Î”Median', '%Î”Var', '%Î”Skew', '%Î”Kurtosis', 'KL', 'Kendall_tau']:\n",
    "        v = metrics.get(k, 0)\n",
    "        print(f\"| {v:9.2f} \", end=\"\")\n",
    "    if include_ndcg:\n",
    "        print(f\"| {metrics.get('NDCG@10', 0):8.4f} \", end=\"\")\n",
    "    print()\n",
    "\n",
    "final_all_median['NDCG@10'] = final_ndcg_median\n",
    "if final_female_median:\n",
    "    final_female_median['NDCG@10'] = final_ndcg_median\n",
    "if final_male_median:\n",
    "    final_male_median['NDCG@10'] = final_ndcg_median\n",
    "\n",
    "print(\"\\nðŸ“Š RAND Model Popularity Bias Results:\")\n",
    "print(\"           | %Î”Mean   | %Î”Median | %Î”Var    | %Î”Skew   | %Î”Kurtosis |    KL    | KendallÏ„ | NDCG@10 \")\n",
    "print(\"-\" * 95)\n",
    "print_metrics(\"All\", final_all_median, include_ndcg=True)\n",
    "if final_female_median:\n",
    "    print_metrics(\"Î”Female\", delta_f_median, include_ndcg=False)\n",
    "if final_male_median:\n",
    "    print_metrics(\"Î”Male\", delta_m_median, include_ndcg=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb34cbce",
   "metadata": {},
   "source": [
    "## ItemKNN - done locally using Pycharm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e661dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "zip_folder_path = \"./\"\n",
    "extracted_dir = \"folds\"\n",
    "os.makedirs(extracted_dir, exist_ok=True)\n",
    "\n",
    "for i in range(1, 6):\n",
    "    zip_filename = f\"fold_{i}.zip\"\n",
    "    zip_path = os.path.join(zip_folder_path, zip_filename)\n",
    "    fold_extract_path = os.path.join(extracted_dir, f\"fold_{i}\")\n",
    "    os.makedirs(fold_extract_path, exist_ok=True)\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(fold_extract_path)\n",
    "    print(f\"Extracted {zip_filename} to {fold_extract_path}\")\n",
    "\n",
    "folds_data = {}\n",
    "for i in range(1, 6):\n",
    "    base_fold_path = os.path.join(extracted_dir, f\"fold_{i}\")\n",
    "    subdirs = [d for d in os.listdir(base_fold_path) if os.path.isdir(os.path.join(base_fold_path, d))]\n",
    "    fold_path = os.path.join(base_fold_path, subdirs[0]) if subdirs else base_fold_path\n",
    "\n",
    "    data = {\n",
    "        'train': pd.read_csv(os.path.join(fold_path, 'train.tsv'), sep='\\t'),\n",
    "        'val_input': pd.read_csv(os.path.join(fold_path, 'val_input.tsv'), sep='\\t'),\n",
    "        'val_target': pd.read_csv(os.path.join(fold_path, 'val_target.tsv'), sep='\\t'),\n",
    "        'test_input': pd.read_csv(os.path.join(fold_path, 'test_input.tsv'), sep='\\t'),\n",
    "        'test_target': pd.read_csv(os.path.join(fold_path, 'test_target.tsv'), sep='\\t'),\n",
    "    }\n",
    "    folds_data[f'fold_{i}'] = data\n",
    "    print(f\"Loaded fold_{i} datasets\")\n",
    "\n",
    "# Metrics \n",
    "def recall_at_k(recommended, ground_truth, k=10):\n",
    "    recommended_k = recommended[:k]\n",
    "    hits = len(set(recommended_k) & set(ground_truth))\n",
    "    return hits / len(ground_truth) if ground_truth else 0\n",
    "\n",
    "def ndcg_at_k(recommended, ground_truth, k=10):\n",
    "    recommended_k = recommended[:k]\n",
    "    gains = [1 if item in ground_truth else 0 for item in recommended_k]\n",
    "    dcg = sum(g / np.log2(i + 2) for i, g in enumerate(gains))\n",
    "    idcg = sum(1 / np.log2(i + 2) for i in range(min(len(ground_truth), k)))\n",
    "    return dcg / idcg if idcg > 0 else 0\n",
    "\n",
    "# Item KNN Evaluation\n",
    "def evaluate_item_knn(fold_data, input_key, target_key, k=10, topk_sim=100):\n",
    "    train_df = fold_data['train']\n",
    "    input_df = fold_data[input_key]\n",
    "    target_df = fold_data[target_key]\n",
    "\n",
    "    print(f\"\\nEvaluating with ITEM KNN on {input_key}...\")\n",
    "\n",
    "    input_df_extended = input_df[['user_id', 'track_id']].copy()\n",
    "    input_df_extended[\"binary_listen\"] = 1\n",
    "    combined_df = pd.concat([train_df, input_df_extended])\n",
    "\n",
    "    users = combined_df['user_id'].unique()\n",
    "    items = combined_df['track_id'].unique()\n",
    "\n",
    "    user_to_idx = {user: i for i, user in enumerate(users)}\n",
    "    item_to_idx = {item: i for i, item in enumerate(items)}\n",
    "    idx_to_item = {i: item for item, i in item_to_idx.items()}\n",
    "\n",
    "    print(f\"Users in train+input: {len(users)} | Items: {len(items)}\")\n",
    "\n",
    "    row_idx = combined_df['user_id'].map(user_to_idx)\n",
    "    col_idx = combined_df['track_id'].map(item_to_idx)\n",
    "    data = combined_df['binary_listen'].astype(float)\n",
    "\n",
    "    user_item_matrix = csr_matrix((data, (row_idx, col_idx)), shape=(len(users), len(items)))\n",
    "\n",
    "    print(\"Computing item-item similarity...\")\n",
    "    item_sim = cosine_similarity(user_item_matrix.T, dense_output=False)\n",
    "\n",
    "    for i in range(item_sim.shape[0]):\n",
    "        row = item_sim[i]\n",
    "        if row.nnz > topk_sim:\n",
    "            top_k_idx = np.argpartition(row.data, -topk_sim)[-topk_sim:]\n",
    "            mask = np.ones(len(row.data), dtype=bool)\n",
    "            mask[top_k_idx] = False\n",
    "            row.data[mask] = 0\n",
    "    item_sim.eliminate_zeros()\n",
    "\n",
    "    print(\"Generating recommendations...\")\n",
    "    input_groups = input_df.groupby('user_id')['track_id'].apply(set).to_dict()\n",
    "    target_groups = target_df.groupby('user_id')['track_id'].apply(set).to_dict()\n",
    "\n",
    "    recalls, ndcgs = [], []\n",
    "    user_recommendations = {}\n",
    "\n",
    "    for user in input_groups:\n",
    "        if user not in user_to_idx:\n",
    "            continue\n",
    "\n",
    "        known_items = input_groups[user]\n",
    "        known_indices = [item_to_idx[i] for i in known_items if i in item_to_idx]\n",
    "\n",
    "        if not known_indices:\n",
    "            continue\n",
    "\n",
    "        scores = item_sim[known_indices].sum(axis=0).A1\n",
    "        scores[[item_to_idx[i] for i in known_items if i in item_to_idx]] = 0  # filter known\n",
    "\n",
    "        top_items_idx = np.argpartition(scores, -k)[-k:]\n",
    "        top_items_sorted = top_items_idx[np.argsort(-scores[top_items_idx])]\n",
    "        recommended_items = [idx_to_item[i] for i in top_items_sorted if scores[i] > 0]\n",
    "\n",
    "        true_items = target_groups.get(user, set())\n",
    "        recalls.append(recall_at_k(recommended_items, true_items, k))\n",
    "        ndcgs.append(ndcg_at_k(recommended_items, true_items, k))\n",
    "        user_recommendations[user] = recommended_items\n",
    "\n",
    "    avg_recall = np.mean(recalls) if recalls else 0\n",
    "    avg_ndcg = np.mean(ndcgs) if ndcgs else 0\n",
    "\n",
    "    return avg_recall, avg_ndcg, user_recommendations, target_groups\n",
    "\n",
    "itemknn_test_targets = {}\n",
    "itemknn_test_recommendations = {}\n",
    "itemknn_test_ndcg_scores = {}\n",
    "\n",
    "# Main Evaluation\n",
    "all_val_recalls, all_val_ndcgs = [], []\n",
    "all_test_recalls, all_test_ndcgs = [], []\n",
    "\n",
    "for i in range(1, 6):\n",
    "    fold_key = f'fold_{i}'\n",
    "    fold_data = folds_data[fold_key]\n",
    "\n",
    "    val_recall, val_ndcg, _, _ = evaluate_item_knn(fold_data, 'val_input', 'val_target', k=10)\n",
    "    test_recall, test_ndcg, test_recs, test_targets = evaluate_item_knn(fold_data, 'test_input', 'test_target', k=10)\n",
    "\n",
    "    itemknn_test_recommendations[fold_key] = test_recs\n",
    "    itemknn_test_targets[fold_key] = test_targets\n",
    "    itemknn_test_ndcg_scores[fold_key] = test_ndcg\n",
    "\n",
    "    print(f\"Fold {i} Val Recall@10: {val_recall:.4f} | NDCG@10: {val_ndcg:.4f}\")\n",
    "    print(f\"Fold {i} Test Recall@10: {test_recall:.4f} | NDCG@10: {test_ndcg:.4f}\")\n",
    "\n",
    "    all_val_recalls.append(val_recall)\n",
    "    all_val_ndcgs.append(val_ndcg)\n",
    "    all_test_recalls.append(test_recall)\n",
    "    all_test_ndcgs.append(test_ndcg)\n",
    "\n",
    "\n",
    "print(\"\\n====== Overall Results ======\")\n",
    "print(f\"Average Val Recall@10:  {np.mean(all_val_recalls):.4f}\")\n",
    "print(f\"Average Val NDCG@10:    {np.mean(all_val_ndcgs):.4f}\")\n",
    "print(f\"Average Test Recall@10: {np.mean(all_test_recalls):.4f}\")\n",
    "print(f\"Average Test NDCG@10:   {np.mean(all_test_ndcgs):.4f}\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "\n",
    "def percent_delta_metric(m_reco, m_hist):\n",
    "    return 100 * (m_reco - m_hist) / m_hist if m_hist != 0 else 0.0\n",
    "\n",
    "def kl_divergence(p, q):\n",
    "    epsilon = 1e-10\n",
    "    p = np.array(p) + epsilon\n",
    "    q = np.array(q) + epsilon\n",
    "    return np.sum(p * np.log(p / q))\n",
    "\n",
    "def kendalls_tau(x, y):\n",
    "    return stats.kendalltau(x, y).correlation\n",
    "\n",
    "def pop_bias_metrics(train_df, recommendations, targets, user_info, top_k=10):\n",
    "    popularity_dict = train_df['track_id'].value_counts().to_dict()\n",
    "    all_pop = np.array(list(popularity_dict.values()))\n",
    "    bins = np.quantile(all_pop, np.linspace(0, 1, 11))\n",
    "\n",
    "    def bin_distribution(vals, bins):\n",
    "        binned_counts, _ = np.histogram(vals, bins=bins)\n",
    "        return binned_counts / binned_counts.sum() if binned_counts.sum() > 0 else np.zeros_like(binned_counts, dtype=float)\n",
    "\n",
    "    user_metrics = []\n",
    "\n",
    "    for user_id, rec_tracks in recommendations.items():\n",
    "        true_tracks = targets.get(user_id, [])\n",
    "        if not true_tracks:\n",
    "            continue\n",
    "        hist_tracks = true_tracks\n",
    "\n",
    "        hist_vals = [popularity_dict.get(t, 0) for t in hist_tracks]\n",
    "        rec_vals = [popularity_dict.get(t, 0) for t in rec_tracks]\n",
    "\n",
    "        metrics = {\n",
    "            'user_id': user_id,\n",
    "            'gender': user_info.get(user_id, None),\n",
    "            '%Î”Mean': percent_delta_metric(np.mean(rec_vals), np.mean(hist_vals)),\n",
    "            '%Î”Median': percent_delta_metric(np.median(rec_vals), np.median(hist_vals)),\n",
    "            '%Î”Var': percent_delta_metric(np.var(rec_vals), np.var(hist_vals)),\n",
    "            '%Î”Skew': percent_delta_metric(stats.skew(rec_vals), stats.skew(hist_vals)),\n",
    "            '%Î”Kurtosis': percent_delta_metric(stats.kurtosis(rec_vals), stats.kurtosis(hist_vals)),\n",
    "        }\n",
    "\n",
    "        hist_binned = bin_distribution(hist_vals, bins)\n",
    "        rec_binned = bin_distribution(rec_vals, bins)\n",
    "\n",
    "        metrics['KL'] = kl_divergence(hist_binned, rec_binned)\n",
    "        metrics['Kendall_tau'] = kendalls_tau(hist_binned, rec_binned)\n",
    "\n",
    "        user_metrics.append(metrics)\n",
    "\n",
    "    return user_metrics\n",
    "\n",
    "all_metrics = []\n",
    "gender_metrics = {'f': [], 'm': []}\n",
    "all_ndcgs = []\n",
    "\n",
    "for i in range(1, 6):\n",
    "    fold_key = f'fold_{i}'\n",
    "    fold_data = folds_data[fold_key]\n",
    "\n",
    "    train_df = fold_data['train']\n",
    "    test_targets = itemknn_test_targets[fold_key]  \n",
    "    test_recs = itemknn_test_recommendations[fold_key]\n",
    "    ndcg_score = itemknn_test_ndcg_scores[fold_key]\n",
    "\n",
    "    all_ndcgs.append(ndcg_score)\n",
    "\n",
    "    # Combine user info\n",
    "    combined_users = pd.concat([\n",
    "        train_df[['user_id', 'gender']],\n",
    "        fold_data['val_input'][['user_id', 'gender']],\n",
    "        fold_data['test_input'][['user_id', 'gender']],\n",
    "    ]).drop_duplicates()\n",
    "    user_info = combined_users.set_index('user_id')['gender'].to_dict()\n",
    "\n",
    "    user_metrics = pop_bias_metrics(train_df, test_recs, test_targets, user_info, top_k=10)\n",
    "\n",
    "    if user_metrics:\n",
    "        df = pd.DataFrame(user_metrics)\n",
    "        all_metrics.append(df.median(numeric_only=True).to_dict())\n",
    "\n",
    "        for gender in ['f', 'm']:\n",
    "            gdf = df[df['gender'] == gender]\n",
    "            if not gdf.empty:\n",
    "                gender_metrics[gender].append(gdf.median(numeric_only=True).to_dict())\n",
    "\n",
    "def average_metrics(metrics_list, agg_func=np.median):\n",
    "    if not metrics_list:\n",
    "        return {}\n",
    "    keys = metrics_list[0].keys()\n",
    "    return {k: agg_func([m[k] for m in metrics_list if k in m]) for k in keys}\n",
    "\n",
    "final_all_median = average_metrics(all_metrics)\n",
    "final_female_median = average_metrics(gender_metrics['f']) if gender_metrics['f'] else None\n",
    "final_male_median = average_metrics(gender_metrics['m']) if gender_metrics['m'] else None\n",
    "final_ndcg_median = np.median(all_ndcgs) if all_ndcgs else 0\n",
    "\n",
    "def delta(group, overall):\n",
    "    return {k: overall[k] - group.get(k, 0) for k in overall if k in group}\n",
    "\n",
    "delta_f_median = delta(final_female_median, final_all_median) if final_female_median else {}\n",
    "delta_m_median = delta(final_male_median, final_all_median) if final_male_median else {}\n",
    "\n",
    "def print_metrics(label, metrics, include_ndcg):\n",
    "    print(f\"{label:<10}\", end=\"\")\n",
    "    for k in ['%Î”Mean', '%Î”Median', '%Î”Var', '%Î”Skew', '%Î”Kurtosis', 'KL', 'Kendall_tau']:\n",
    "        v = metrics.get(k, 0)\n",
    "        print(f\"| {v:9.2f} \", end=\"\")\n",
    "    if include_ndcg:\n",
    "        print(f\"| {metrics.get('NDCG@10', 0):8.4f} \", end=\"\")\n",
    "    print()\n",
    "\n",
    "final_all_median['NDCG@10'] = final_ndcg_median\n",
    "if final_female_median:\n",
    "    final_female_median['NDCG@10'] = final_ndcg_median\n",
    "if final_male_median:\n",
    "    final_male_median['NDCG@10'] = final_ndcg_median\n",
    "\n",
    "print(\"\\n\\U0001F4CA Item KNN Model Popularity Bias Results:\")\n",
    "print(\"           | %Î”Mean   | %Î”Median | %Î”Var    | %Î”Skew   | %Î”Kurtosis |    KL    | KendallÏ„ | NDCG@10 \")\n",
    "print(\"-\" * 95)\n",
    "print_metrics(\"All\", final_all_median, include_ndcg=True)\n",
    "if final_female_median:\n",
    "    print_metrics(\"Î”Female\", delta_f_median, include_ndcg=False)\n",
    "if final_male_median:\n",
    "    print_metrics(\"Î”Male\", delta_m_median, include_ndcg=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbe5cb3",
   "metadata": {},
   "source": [
    "### Results:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5959d87c",
   "metadata": {},
   "source": [
    "#### Item KNN Evaluation Results\n",
    "\n",
    "After running the Item KNN recommender across all 5 folds, the average performance metrics are as follows:\n",
    "\n",
    "| Metric               | Value   |\n",
    "|----------------------|---------|\n",
    "| **Validation Recall@10**    | 0.1261  |\n",
    "| **Validation NDCG@10**      | 0.1487  |\n",
    "| **Test Recall@10**          | 0.1095  |\n",
    "| **Test NDCG@10**            | 0.1575  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec5625c",
   "metadata": {},
   "source": [
    " **Item KNN Model Popularity Bias Results**\n",
    "\n",
    "| Group    | %Î”Mean  | %Î”Median | %Î”Var   | %Î”Skew  | %Î”Kurtosis | KL    | KendallÏ„ | NDCG@10 |\n",
    "|----------|---------|----------|---------|---------|-------------|--------|-----------|---------|\n",
    "| All      | 223.97  | 389.08   | 159.65  | -26.03  | -99.16      | 5.19   | 0.58      | 0.1573  |\n",
    "| Î”Female  | -19.98  | -7.60    | -51.50  | -10.39  | 1.14        | 0.76   | -0.05     |         |\n",
    "| Î”Male    | 9.48    | 3.66     | 14.67   | 3.03    | -0.58       | -0.03  | 0.02      |         |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcc19ac",
   "metadata": {},
   "source": [
    "## ALS - done locally using Pycharm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a614e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.sparse import csr_matrix\n",
    "from numpy.linalg import solve\n",
    "\n",
    "zip_folder_path = \"./\"\n",
    "extracted_dir = \"folds\"\n",
    "os.makedirs(extracted_dir, exist_ok=True)\n",
    "\n",
    "for i in range(1, 6):\n",
    "    zip_filename = f\"fold_{i}.zip\"\n",
    "    zip_path = os.path.join(zip_folder_path, zip_filename)\n",
    "    fold_extract_path = os.path.join(extracted_dir, f\"fold_{i}\")\n",
    "    os.makedirs(fold_extract_path, exist_ok=True)\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(fold_extract_path)\n",
    "    print(f\"Extracted {zip_filename} to {fold_extract_path}\")\n",
    "\n",
    "folds_data = {}\n",
    "for i in range(1, 6):\n",
    "    base_fold_path = os.path.join(extracted_dir, f\"fold_{i}\")\n",
    "    subdirs = [d for d in os.listdir(base_fold_path) if os.path.isdir(os.path.join(base_fold_path, d))]\n",
    "    fold_path = os.path.join(base_fold_path, subdirs[0]) if subdirs else base_fold_path\n",
    "\n",
    "    data = {\n",
    "        'train': pd.read_csv(os.path.join(fold_path, 'train.tsv'), sep='\\t'),\n",
    "        'val_input': pd.read_csv(os.path.join(fold_path, 'val_input.tsv'), sep='\\t'),\n",
    "        'val_target': pd.read_csv(os.path.join(fold_path, 'val_target.tsv'), sep='\\t'),\n",
    "        'test_input': pd.read_csv(os.path.join(fold_path, 'test_input.tsv'), sep='\\t'),\n",
    "        'test_target': pd.read_csv(os.path.join(fold_path, 'test_target.tsv'), sep='\\t'),\n",
    "    }\n",
    "    folds_data[f'fold_{i}'] = data\n",
    "    print(f\"Loaded fold_{i} datasets\")\n",
    "\n",
    "# Metrics \n",
    "def recall_at_k(recommended, ground_truth, k=10):\n",
    "    recommended_k = recommended[:k]\n",
    "    hits = len(set(recommended_k) & set(ground_truth))\n",
    "    return hits / len(ground_truth) if ground_truth else 0\n",
    "\n",
    "def ndcg_at_k(recommended, ground_truth, k=10):\n",
    "    recommended_k = recommended[:k]\n",
    "    gains = [1 if item in ground_truth else 0 for item in recommended_k]\n",
    "    dcg = sum(g / np.log2(i + 2) for i, g in enumerate(gains))\n",
    "    idcg = sum(1 / np.log2(i + 2) for i in range(min(len(ground_truth), k)))\n",
    "    return dcg / idcg if idcg > 0 else 0\n",
    "\n",
    "# ALS Implementation \n",
    "def als_explicit(user_item_matrix, n_factors=10, n_iters=3, reg=1):\n",
    "    \"\"\"\n",
    "    Explicit ALS factorization for user-item matrix.\n",
    "    user_item_matrix: csr_matrix with explicit ratings (floats)\n",
    "    Returns: user_factors, item_factors (numpy arrays)\n",
    "    \"\"\"\n",
    "    n_users, n_items = user_item_matrix.shape\n",
    "\n",
    "    user_factors = np.random.normal(scale=1./n_factors, size=(n_users, n_factors))\n",
    "    item_factors = np.random.normal(scale=1./n_factors, size=(n_items, n_factors))\n",
    "\n",
    "    eye = np.eye(n_factors)\n",
    "    \n",
    "    for iteration in range(n_iters):\n",
    "        for u in range(n_users):\n",
    "            start_ptr, end_ptr = user_item_matrix.indptr[u], user_item_matrix.indptr[u+1]\n",
    "            item_indices = user_item_matrix.indices[start_ptr:end_ptr]\n",
    "            ratings = user_item_matrix.data[start_ptr:end_ptr]\n",
    "            if len(item_indices) == 0:\n",
    "                continue\n",
    "            V = item_factors[item_indices]\n",
    "            A = V.T @ V + reg * eye\n",
    "            b = V.T @ ratings\n",
    "            user_factors[u] = solve(A, b)\n",
    "\n",
    "        user_item_csc = user_item_matrix.tocsc()\n",
    "        for i in range(n_items):\n",
    "            start_ptr, end_ptr = user_item_csc.indptr[i], user_item_csc.indptr[i+1]\n",
    "            user_indices = user_item_csc.indices[start_ptr:end_ptr]\n",
    "            ratings = user_item_csc.data[start_ptr:end_ptr]\n",
    "            if len(user_indices) == 0:\n",
    "                continue\n",
    "            U = user_factors[user_indices]\n",
    "            A = U.T @ U + reg * eye\n",
    "            b = U.T @ ratings\n",
    "            item_factors[i] = solve(A, b)\n",
    "\n",
    "        print(f\"ALS Iteration {iteration + 1}/{n_iters} completed\")\n",
    "\n",
    "    return user_factors, item_factors\n",
    "\n",
    "#  Evaluation with ALS \n",
    "def evaluate_als(fold_data, input_key, target_key, n_factors=20, n_iters=3, k=10):\n",
    "    train_df = fold_data['train']\n",
    "    input_df = fold_data[input_key]\n",
    "    target_df = fold_data[target_key]\n",
    "\n",
    "    print(f\"\\nEvaluating with ALS on {input_key}...\")\n",
    "\n",
    "    input_df_extended = input_df[['user_id', 'track_id']].copy()\n",
    "    input_df_extended[\"rating\"] = 1.0\n",
    "\n",
    "    train_ratings = train_df.rename(columns={'binary_listen': 'rating'})[['user_id', 'track_id', 'rating']]\n",
    "    combined_df = pd.concat([train_ratings, input_df_extended])\n",
    "\n",
    "    users = combined_df['user_id'].unique()\n",
    "    items = combined_df['track_id'].unique()\n",
    "\n",
    "    user_to_idx = {user: i for i, user in enumerate(users)}\n",
    "    item_to_idx = {item: i for i, item in enumerate(items)}\n",
    "    idx_to_item = {i: item for item, i in item_to_idx.items()}\n",
    "\n",
    "    print(f\"Users in train+input: {len(users)} | Items: {len(items)}\")\n",
    "\n",
    "    row_idx = combined_df['user_id'].map(user_to_idx)\n",
    "    col_idx = combined_df['track_id'].map(item_to_idx)\n",
    "    data = combined_df['rating'].astype(float)\n",
    "\n",
    "    user_item_matrix = csr_matrix((data, (row_idx, col_idx)), shape=(len(users), len(items)))\n",
    "\n",
    "    user_factors, item_factors = als_explicit(user_item_matrix, n_factors=n_factors, n_iters=n_iters)\n",
    "\n",
    "    input_groups = input_df.groupby('user_id')['track_id'].apply(set).to_dict()\n",
    "    target_groups = target_df.groupby('user_id')['track_id'].apply(set).to_dict()\n",
    "\n",
    "    recalls, ndcgs = [], []\n",
    "    user_recommendations = {}\n",
    "\n",
    "    for user in input_groups:\n",
    "        if user not in user_to_idx:\n",
    "            continue\n",
    "        user_idx = user_to_idx[user]\n",
    "        known_items = input_groups[user]\n",
    "        known_indices = [item_to_idx[i] for i in known_items if i in item_to_idx]\n",
    "\n",
    "        if not known_indices:\n",
    "            continue\n",
    "\n",
    "        scores = user_factors[user_idx] @ item_factors.T\n",
    "        scores[known_indices] = -np.inf  \n",
    "\n",
    "        top_items_idx = np.argpartition(scores, -k)[-k:]\n",
    "        top_items_sorted = top_items_idx[np.argsort(-scores[top_items_idx])]\n",
    "        recommended_items = [idx_to_item[i] for i in top_items_sorted if scores[i] > -np.inf]\n",
    "\n",
    "        true_items = target_groups.get(user, set())\n",
    "        recalls.append(recall_at_k(recommended_items, true_items, k))\n",
    "        ndcgs.append(ndcg_at_k(recommended_items, true_items, k))\n",
    "        user_recommendations[user] = recommended_items\n",
    "\n",
    "    avg_recall = np.mean(recalls) if recalls else 0\n",
    "    avg_ndcg = np.mean(ndcgs) if ndcgs else 0\n",
    "\n",
    "    return avg_recall, avg_ndcg, user_recommendations, target_groups\n",
    "\n",
    "# Main Evaluation Loop\n",
    "all_val_recalls, all_val_ndcgs = [], []\n",
    "all_test_recalls, all_test_ndcgs = [], []\n",
    "\n",
    "als_test_targets = {}\n",
    "als_test_recommendations = {}\n",
    "als_test_ndcg_scores = {}\n",
    "\n",
    "for i in range(1, 6):\n",
    "    fold_key = f'fold_{i}'\n",
    "    fold_data = folds_data[fold_key]\n",
    "\n",
    "    val_recall, val_ndcg, _, _ = evaluate_als(fold_data, 'val_input', 'val_target', n_factors=20, n_iters=3, k=10)\n",
    "    test_recall, test_ndcg, test_recs, test_targets = evaluate_als(fold_data, 'test_input', 'test_target', n_factors=20, n_iters=3, k=10)\n",
    "\n",
    "    als_test_recommendations[fold_key] = test_recs\n",
    "    als_test_targets[fold_key] = test_targets\n",
    "    als_test_ndcg_scores[fold_key] = test_ndcg\n",
    "\n",
    "    print(f\"Fold {i} Val Recall@10: {val_recall:.4f} | NDCG@10: {val_ndcg:.4f}\")\n",
    "    print(f\"Fold {i} Test Recall@10: {test_recall:.4f} | NDCG@10: {test_ndcg:.4f}\")\n",
    "\n",
    "    all_val_recalls.append(val_recall)\n",
    "    all_val_ndcgs.append(val_ndcg)\n",
    "    all_test_recalls.append(test_recall)\n",
    "    all_test_ndcgs.append(test_ndcg)\n",
    "\n",
    "print(\"\\n====== Overall ALS Results ======\")\n",
    "print(f\"Average Val Recall@10:  {np.mean(all_val_recalls):.4f}\")\n",
    "print(f\"Average Val NDCG@10:    {np.mean(all_val_ndcgs):.4f}\")\n",
    "print(f\"Average Test Recall@10: {np.mean(all_test_recalls):.4f}\")\n",
    "print(f\"Average Test NDCG@10:   {np.mean(all_test_ndcgs):.4f}\")\n",
    "\n",
    "#  Popularity Bias Metrics \n",
    "def percent_delta_metric(m_reco, m_hist):\n",
    "    return 100 * (m_reco - m_hist) / m_hist if m_hist != 0 else 0.0\n",
    "\n",
    "def kl_divergence(p, q):\n",
    "    epsilon = 1e-10\n",
    "    p = np.array(p) + epsilon\n",
    "    q = np.array(q) + epsilon\n",
    "    return np.sum(p * np.log(p / q))\n",
    "\n",
    "def kendalls_tau(x, y):\n",
    "    return stats.kendalltau(x, y).correlation\n",
    "\n",
    "def pop_bias_metrics(train_df, recommendations, targets, user_info, top_k=50):\n",
    "    popularity_dict = train_df['track_id'].value_counts().to_dict()\n",
    "    all_pop = np.array(list(popularity_dict.values()))\n",
    "    bins = np.quantile(all_pop, np.linspace(0, 1, 11))\n",
    "\n",
    "    def bin_distribution(vals, bins):\n",
    "        binned_counts, _ = np.histogram(vals, bins=bins)\n",
    "        return binned_counts / binned_counts.sum() if binned_counts.sum() > 0 else np.zeros_like(binned_counts, dtype=float)\n",
    "\n",
    "    user_metrics = []\n",
    "\n",
    "    for user_id, rec_tracks in recommendations.items():\n",
    "        true_tracks = targets.get(user_id, [])\n",
    "        if not true_tracks:\n",
    "            continue\n",
    "        hist_tracks = true_tracks\n",
    "\n",
    "        hist_vals = [popularity_dict.get(t, 0) for t in hist_tracks]\n",
    "        rec_vals = [popularity_dict.get(t, 0) for t in rec_tracks]\n",
    "\n",
    "        metrics = {\n",
    "            'user_id': user_id,\n",
    "            'gender': user_info.get(user_id, None),\n",
    "            '%Î”Mean': percent_delta_metric(np.mean(rec_vals), np.mean(hist_vals)),\n",
    "            '%Î”Median': percent_delta_metric(np.median(rec_vals), np.median(hist_vals)),\n",
    "            '%Î”Var': percent_delta_metric(np.var(rec_vals), np.var(hist_vals)),\n",
    "            '%Î”Skew': percent_delta_metric(stats.skew(rec_vals), stats.skew(hist_vals)),\n",
    "            '%Î”Kurtosis': percent_delta_metric(stats.kurtosis(rec_vals), stats.kurtosis(hist_vals)),\n",
    "        }\n",
    "\n",
    "        hist_binned = bin_distribution(hist_vals, bins)\n",
    "        rec_binned = bin_distribution(rec_vals, bins)\n",
    "\n",
    "        metrics['KL'] = kl_divergence(hist_binned, rec_binned)\n",
    "        metrics['Kendall_tau'] = kendalls_tau(hist_binned, rec_binned)\n",
    "\n",
    "        user_metrics.append(metrics)\n",
    "\n",
    "    return user_metrics\n",
    "\n",
    "#  Popularity Bias Analysis \n",
    "all_metrics = []\n",
    "gender_metrics = {'f': [], 'm': []}\n",
    "all_ndcgs = []\n",
    "\n",
    "for i in range(1, 6):\n",
    "    fold_key = f'fold_{i}'\n",
    "    fold_data = folds_data[fold_key]\n",
    "\n",
    "    train_df = fold_data['train']\n",
    "    test_targets = als_test_targets[fold_key]\n",
    "    test_recs = als_test_recommendations[fold_key]\n",
    "    ndcg_score = als_test_ndcg_scores[fold_key]\n",
    "    all_ndcgs.append(ndcg_score)\n",
    "\n",
    "\n",
    "    combined_users = pd.concat([\n",
    "        train_df[['user_id', 'gender']],\n",
    "        fold_data['val_input'][['user_id', 'gender']],\n",
    "        fold_data['test_input'][['user_id', 'gender']],\n",
    "    ]).drop_duplicates()\n",
    "    user_info = combined_users.set_index('user_id')['gender'].to_dict()\n",
    "\n",
    "    user_metrics = pop_bias_metrics(train_df, test_recs, test_targets, user_info, top_k=10)\n",
    "\n",
    "    if user_metrics:\n",
    "        df = pd.DataFrame(user_metrics)\n",
    "        all_metrics.append(df.median(numeric_only=True).to_dict())\n",
    "\n",
    "        for gender in ['f', 'm']:\n",
    "            gdf = df[df['gender'] == gender]\n",
    "            if not gdf.empty:\n",
    "                gender_metrics[gender].append(gdf.median(numeric_only=True).to_dict())\n",
    "\n",
    "def average_metrics(metrics_list, agg_func=np.median):\n",
    "    if not metrics_list:\n",
    "        return {}\n",
    "    keys = metrics_list[0].keys()\n",
    "    return {k: agg_func([m[k] for m in metrics_list if k in m]) for k in keys}\n",
    "\n",
    "final_all_median = average_metrics(all_metrics)\n",
    "final_female_median = average_metrics(gender_metrics['f']) if gender_metrics['f'] else None\n",
    "final_male_median = average_metrics(gender_metrics['m']) if gender_metrics['m'] else None\n",
    "final_ndcg_median = np.median(all_ndcgs) if all_ndcgs else 0\n",
    "\n",
    "def delta(group, overall):\n",
    "    return {k: overall[k] - group.get(k, 0) for k in overall if k in group}\n",
    "\n",
    "delta_f_median = delta(final_female_median, final_all_median) if final_female_median else {}\n",
    "delta_m_median = delta(final_male_median, final_all_median) if final_male_median else {}\n",
    "\n",
    "def print_metrics(label, metrics, include_ndcg):\n",
    "    print(f\"{label:<10}\", end=\"\")\n",
    "    for k in ['%Î”Mean', '%Î”Median', '%Î”Var', '%Î”Skew', '%Î”Kurtosis', 'KL', 'Kendall_tau']:\n",
    "        v = metrics.get(k, 0)\n",
    "        print(f\"| {v:9.2f} \", end=\"\")\n",
    "    if include_ndcg:\n",
    "        print(f\"| {metrics.get('NDCG@10', 0):8.4f} \", end=\"\")\n",
    "    print()\n",
    "\n",
    "final_all_median['NDCG@10'] = final_ndcg_median\n",
    "if final_female_median:\n",
    "    final_female_median['NDCG@10'] = final_ndcg_median\n",
    "if final_male_median:\n",
    "    final_male_median['NDCG@10'] = final_ndcg_median\n",
    "\n",
    "print(\"\\nðŸ“Š ALS Model Popularity Bias Results:\")\n",
    "print(\"           | %Î”Mean   | %Î”Median | %Î”Var    | %Î”Skew   | %Î”Kurtosis |    KL    | KendallÏ„ | NDCG@10 \")\n",
    "print(\"-\" * 95)\n",
    "print_metrics(\"All\", final_all_median, include_ndcg=True)\n",
    "if final_female_median:\n",
    "    print_metrics(\"Î”Female\", delta_f_median, include_ndcg=False)\n",
    "if final_male_median:\n",
    "    print_metrics(\"Î”Male\", delta_m_median, include_ndcg=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199079c4",
   "metadata": {},
   "source": [
    "## Overall ALS Results\n",
    "\n",
    "- **Average Val Recall@10:**  0.0339  \n",
    "- **Average Val NDCG@10:**    0.0252  \n",
    "- **Average Test Recall@10:** 0.0240  \n",
    "- **Average Test NDCG@10:**   0.0206\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a44287d",
   "metadata": {},
   "source": [
    "## ALS Model Popularity Bias Results\n",
    "\n",
    "| Group    | %Î”Mean | %Î”Median | %Î”Var   | %Î”Skew  | %Î”Kurtosis |   KL   | KendallÏ„ | NDCG@10 |\n",
    "|----------|--------|----------|---------|---------|-------------|--------|-----------|---------|\n",
    "| All      |  3.35  |   79.87  | -48.00  | -28.96  |   -100.88   |  5.02  |    0.63   |  0.0204 |\n",
    "| Î”Female  | -17.81 |   -6.35  | -34.77  | -11.27  |    -3.87    |  0.52  |   -0.04   |         |\n",
    "| Î”Male    |  3.54  |    0.88  |  10.63  |   5.20  |     0.54    | -0.11  |    0.00   |         |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e84ef6",
   "metadata": {},
   "source": [
    "## BPR - done locally using Pycharm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2f5260",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.sparse import csr_matrix\n",
    "from numpy.linalg import solve\n",
    "\n",
    "zip_folder_path = \"./\"\n",
    "extracted_dir = \"folds\"\n",
    "os.makedirs(extracted_dir, exist_ok=True)\n",
    "\n",
    "for i in range(1, 6):\n",
    "    zip_filename = f\"fold_{i}.zip\"\n",
    "    zip_path = os.path.join(zip_folder_path, zip_filename)\n",
    "    fold_extract_path = os.path.join(extracted_dir, f\"fold_{i}\")\n",
    "    os.makedirs(fold_extract_path, exist_ok=True)\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(fold_extract_path)\n",
    "    print(f\"Extracted {zip_filename} to {fold_extract_path}\")\n",
    "\n",
    "folds_data = {}\n",
    "for i in range(1, 6):\n",
    "    base_fold_path = os.path.join(extracted_dir, f\"fold_{i}\")\n",
    "    subdirs = [d for d in os.listdir(base_fold_path) if os.path.isdir(os.path.join(base_fold_path, d))]\n",
    "    fold_path = os.path.join(base_fold_path, subdirs[0]) if subdirs else base_fold_path\n",
    "\n",
    "    data = {\n",
    "        'train': pd.read_csv(os.path.join(fold_path, 'train.tsv'), sep='\\t'),\n",
    "        'val_input': pd.read_csv(os.path.join(fold_path, 'val_input.tsv'), sep='\\t'),\n",
    "        'val_target': pd.read_csv(os.path.join(fold_path, 'val_target.tsv'), sep='\\t'),\n",
    "        'test_input': pd.read_csv(os.path.join(fold_path, 'test_input.tsv'), sep='\\t'),\n",
    "        'test_target': pd.read_csv(os.path.join(fold_path, 'test_target.tsv'), sep='\\t'),\n",
    "    }\n",
    "    folds_data[f'fold_{i}'] = data\n",
    "    print(f\"Loaded fold_{i} datasets\")\n",
    "\n",
    "#  Metrics\n",
    "def recall_at_k(recommended, ground_truth, k=10):\n",
    "    recommended_k = recommended[:k]\n",
    "    hits = len(set(recommended_k) & set(ground_truth))\n",
    "    return hits / len(ground_truth) if ground_truth else 0\n",
    "\n",
    "def ndcg_at_k(recommended, ground_truth, k=10):\n",
    "    recommended_k = recommended[:k]\n",
    "    gains = [1 if item in ground_truth else 0 for item in recommended_k]\n",
    "    dcg = sum(g / np.log2(i + 2) for i, g in enumerate(gains))\n",
    "    idcg = sum(1 / np.log2(i + 2) for i in range(min(len(ground_truth), k)))\n",
    "    return dcg / idcg if idcg > 0 else 0\n",
    "\n",
    "# BPR Implementation \n",
    "def bpr_train(user_item_pairs, n_users, n_items, n_factors=20, n_iters=30, lr=0.1, reg=0.1):\n",
    "    user_factors = np.random.normal(0, 0.1, (n_users, n_factors))\n",
    "    item_factors = np.random.normal(0, 0.1, (n_items, n_factors))\n",
    "\n",
    "    for iteration in range(n_iters):\n",
    "        np.random.shuffle(user_item_pairs)\n",
    "        for u, i in user_item_pairs:\n",
    "            j = np.random.randint(n_items)\n",
    "            while (u, j) in user_item_pairs_set:\n",
    "                j = np.random.randint(n_items)\n",
    "\n",
    "            x_uij = np.dot(user_factors[u], item_factors[i] - item_factors[j])\n",
    "            sigmoid = 1 / (1 + np.exp(-x_uij))\n",
    "\n",
    "            user_grad = (sigmoid - 1) * (item_factors[i] - item_factors[j]) + reg * user_factors[u]\n",
    "            item_i_grad = (sigmoid - 1) * user_factors[u] + reg * item_factors[i]\n",
    "            item_j_grad = -(sigmoid - 1) * user_factors[u] + reg * item_factors[j]\n",
    "\n",
    "            user_factors[u] -= lr * user_grad\n",
    "            item_factors[i] -= lr * item_i_grad\n",
    "            item_factors[j] -= lr * item_j_grad\n",
    "\n",
    "        print(f\"BPR Iteration {iteration + 1}/{n_iters} completed\")\n",
    "\n",
    "    return user_factors, item_factors\n",
    "\n",
    "# Evaluation with BPR \n",
    "def evaluate_bpr(fold_data, input_key, target_key, n_factors=20, n_iters=3, k=10):\n",
    "    train_df = fold_data['train']\n",
    "    input_df = fold_data[input_key]\n",
    "    target_df = fold_data[target_key]\n",
    "\n",
    "    print(f\"\\nEvaluating with BPR on {input_key}...\")\n",
    "\n",
    "    input_df_extended = input_df[['user_id', 'track_id']].copy()\n",
    "    input_df_extended[\"rating\"] = 1.0\n",
    "    train_ratings = train_df.rename(columns={'binary_listen': 'rating'})[['user_id', 'track_id', 'rating']]\n",
    "    combined_df = pd.concat([train_ratings, input_df_extended])\n",
    "\n",
    "    users = combined_df['user_id'].unique()\n",
    "    items = combined_df['track_id'].unique()\n",
    "\n",
    "    user_to_idx = {user: i for i, user in enumerate(users)}\n",
    "    item_to_idx = {item: i for i, item in enumerate(items)}\n",
    "    idx_to_item = {i: item for item, i in item_to_idx.items()}\n",
    "\n",
    "    n_users, n_items = len(users), len(items)\n",
    "\n",
    "    global user_item_pairs_set\n",
    "    user_item_pairs = [(user_to_idx[u], item_to_idx[i]) for u, i in zip(combined_df['user_id'], combined_df['track_id'])]\n",
    "    user_item_pairs_set = set(user_item_pairs)\n",
    "\n",
    "    user_factors, item_factors = bpr_train(user_item_pairs, n_users, n_items, n_factors=n_factors, n_iters=n_iters)\n",
    "\n",
    "    input_groups = input_df.groupby('user_id')['track_id'].apply(set).to_dict()\n",
    "    target_groups = target_df.groupby('user_id')['track_id'].apply(set).to_dict()\n",
    "\n",
    "    recalls, ndcgs = [], []\n",
    "    user_recommendations = {}\n",
    "\n",
    "    for user in input_groups:\n",
    "        if user not in user_to_idx:\n",
    "            continue\n",
    "        user_idx = user_to_idx[user]\n",
    "        known_items = input_groups[user]\n",
    "        known_indices = [item_to_idx[i] for i in known_items if i in item_to_idx]\n",
    "\n",
    "        if not known_indices:\n",
    "            continue\n",
    "\n",
    "        scores = user_factors[user_idx] @ item_factors.T\n",
    "        scores[known_indices] = -np.inf  # exclude known\n",
    "\n",
    "        top_items_idx = np.argpartition(scores, -k)[-k:]\n",
    "        top_items_sorted = top_items_idx[np.argsort(-scores[top_items_idx])]\n",
    "        recommended_items = [idx_to_item[i] for i in top_items_sorted]\n",
    "\n",
    "        true_items = target_groups.get(user, set())\n",
    "        recalls.append(recall_at_k(recommended_items, true_items, k))\n",
    "        ndcgs.append(ndcg_at_k(recommended_items, true_items, k))\n",
    "        user_recommendations[user] = recommended_items\n",
    "\n",
    "    avg_recall = np.mean(recalls) if recalls else 0\n",
    "    avg_ndcg = np.mean(ndcgs) if ndcgs else 0\n",
    "\n",
    "    return avg_recall, avg_ndcg, user_recommendations, target_groups\n",
    "\n",
    "# Main Evaluation Loop \n",
    "all_val_recalls, all_val_ndcgs = [], []\n",
    "all_test_recalls, all_test_ndcgs = [], []\n",
    "\n",
    "bpr_test_targets = {}\n",
    "bpr_test_recommendations = {}\n",
    "bpr_test_ndcg_scores = {}\n",
    "\n",
    "for i in range(1, 6):\n",
    "    fold_key = f'fold_{i}'\n",
    "    fold_data = folds_data[fold_key]\n",
    "\n",
    "    val_recall, val_ndcg, _, _ = evaluate_bpr(fold_data, 'val_input', 'val_target', n_factors=20, n_iters=3, k=10)\n",
    "    test_recall, test_ndcg, test_recs, test_targets = evaluate_bpr(fold_data, 'test_input', 'test_target', n_factors=20, n_iters=3, k=10)\n",
    "\n",
    "    bpr_test_recommendations[fold_key] = test_recs\n",
    "    bpr_test_targets[fold_key] = test_targets\n",
    "    bpr_test_ndcg_scores[fold_key] = test_ndcg\n",
    "\n",
    "    print(f\"Fold {i} Val Recall@10: {val_recall:.4f} | NDCG@10: {val_ndcg:.4f}\")\n",
    "    print(f\"Fold {i} Test Recall@10: {test_recall:.4f} | NDCG@10: {test_ndcg:.4f}\")\n",
    "\n",
    "    all_val_recalls.append(val_recall)\n",
    "    all_val_ndcgs.append(val_ndcg)\n",
    "    all_test_recalls.append(test_recall)\n",
    "    all_test_ndcgs.append(test_ndcg)\n",
    "\n",
    "print(\"\\n====== Overall BPR Results ======\")\n",
    "print(f\"Average Val Recall@10:  {np.mean(all_val_recalls):.4f}\")\n",
    "print(f\"Average Val NDCG@10:    {np.mean(all_val_ndcgs):.4f}\")\n",
    "print(f\"Average Test Recall@10: {np.mean(all_test_recalls):.4f}\")\n",
    "print(f\"Average Test NDCG@10:   {np.mean(all_test_ndcgs):.4f}\")\n",
    "\n",
    "# Popularity Bias Metrics \n",
    "def percent_delta_metric(m_reco, m_hist):\n",
    "    return 100 * (m_reco - m_hist) / m_hist if m_hist != 0 else 0.0\n",
    "\n",
    "def kl_divergence(p, q):\n",
    "    epsilon = 1e-10\n",
    "    p = np.array(p) + epsilon\n",
    "    q = np.array(q) + epsilon\n",
    "    return np.sum(p * np.log(p / q))\n",
    "\n",
    "def kendalls_tau(x, y):\n",
    "    return stats.kendalltau(x, y).correlation\n",
    "\n",
    "def pop_bias_metrics(train_df, recommendations, targets, user_info, top_k=50):\n",
    "    popularity_dict = train_df['track_id'].value_counts().to_dict()\n",
    "    all_pop = np.array(list(popularity_dict.values()))\n",
    "    bins = np.quantile(all_pop, np.linspace(0, 1, 11))\n",
    "\n",
    "    def bin_distribution(vals, bins):\n",
    "        binned_counts, _ = np.histogram(vals, bins=bins)\n",
    "        return binned_counts / binned_counts.sum() if binned_counts.sum() > 0 else np.zeros_like(binned_counts, dtype=float)\n",
    "\n",
    "    user_metrics = []\n",
    "\n",
    "    for user_id, rec_tracks in recommendations.items():\n",
    "        true_tracks = targets.get(user_id, [])\n",
    "        if not true_tracks:\n",
    "            continue\n",
    "        hist_tracks = true_tracks\n",
    "\n",
    "        hist_vals = [popularity_dict.get(t, 0) for t in hist_tracks]\n",
    "        rec_vals = [popularity_dict.get(t, 0) for t in rec_tracks]\n",
    "\n",
    "        metrics = {\n",
    "            'user_id': user_id,\n",
    "            'gender': user_info.get(user_id, None),\n",
    "            '%Î”Mean': percent_delta_metric(np.mean(rec_vals), np.mean(hist_vals)),\n",
    "            '%Î”Median': percent_delta_metric(np.median(rec_vals), np.median(hist_vals)),\n",
    "            '%Î”Var': percent_delta_metric(np.var(rec_vals), np.var(hist_vals)),\n",
    "            '%Î”Skew': percent_delta_metric(stats.skew(rec_vals), stats.skew(hist_vals)),\n",
    "            '%Î”Kurtosis': percent_delta_metric(stats.kurtosis(rec_vals), stats.kurtosis(hist_vals)),\n",
    "        }\n",
    "\n",
    "        hist_binned = bin_distribution(hist_vals, bins)\n",
    "        rec_binned = bin_distribution(rec_vals, bins)\n",
    "\n",
    "        metrics['KL'] = kl_divergence(hist_binned, rec_binned)\n",
    "        metrics['Kendall_tau'] = kendalls_tau(hist_binned, rec_binned)\n",
    "\n",
    "        user_metrics.append(metrics)\n",
    "\n",
    "    return user_metrics\n",
    "\n",
    "# Popularity Bias Analysis \n",
    "all_metrics = []\n",
    "gender_metrics = {'f': [], 'm': []}\n",
    "all_ndcgs = []\n",
    "\n",
    "for i in range(1, 6):\n",
    "    fold_key = f'fold_{i}'\n",
    "    fold_data = folds_data[fold_key]\n",
    "\n",
    "    train_df = fold_data['train']\n",
    "    test_targets = bpr_test_targets[fold_key]\n",
    "    test_recs = bpr_test_recommendations[fold_key]\n",
    "    ndcg_score = bpr_test_ndcg_scores[fold_key]\n",
    "    all_ndcgs.append(ndcg_score)\n",
    "\n",
    "\n",
    "    combined_users = pd.concat([\n",
    "        train_df[['user_id', 'gender']],\n",
    "        fold_data['val_input'][['user_id', 'gender']],\n",
    "        fold_data['test_input'][['user_id', 'gender']],\n",
    "    ]).drop_duplicates()\n",
    "    user_info = combined_users.set_index('user_id')['gender'].to_dict()\n",
    "\n",
    "    user_metrics = pop_bias_metrics(train_df, test_recs, test_targets, user_info, top_k=10)\n",
    "\n",
    "    if user_metrics:\n",
    "        df = pd.DataFrame(user_metrics)\n",
    "        all_metrics.append(df.median(numeric_only=True).to_dict())\n",
    "\n",
    "        for gender in ['f', 'm']:\n",
    "            gdf = df[df['gender'] == gender]\n",
    "            if not gdf.empty:\n",
    "                gender_metrics[gender].append(gdf.median(numeric_only=True).to_dict())\n",
    "\n",
    "def average_metrics(metrics_list, agg_func=np.median):\n",
    "    if not metrics_list:\n",
    "        return {}\n",
    "    keys = metrics_list[0].keys()\n",
    "    return {k: agg_func([m[k] for m in metrics_list if k in m]) for k in keys}\n",
    "\n",
    "final_all_median = average_metrics(all_metrics)\n",
    "final_female_median = average_metrics(gender_metrics['f']) if gender_metrics['f'] else None\n",
    "final_male_median = average_metrics(gender_metrics['m']) if gender_metrics['m'] else None\n",
    "final_ndcg_median = np.median(all_ndcgs) if all_ndcgs else 0\n",
    "\n",
    "def delta(group, overall):\n",
    "    return {k: overall[k] - group.get(k, 0) for k in overall if k in group}\n",
    "\n",
    "delta_f_median = delta(final_female_median, final_all_median) if final_female_median else {}\n",
    "delta_m_median = delta(final_male_median, final_all_median) if final_male_median else {}\n",
    "\n",
    "def print_metrics(label, metrics, include_ndcg):\n",
    "    print(f\"{label:<10}\", end=\"\")\n",
    "    for k in ['%Î”Mean', '%Î”Median', '%Î”Var', '%Î”Skew', '%Î”Kurtosis', 'KL', 'Kendall_tau']:\n",
    "        v = metrics.get(k, 0)\n",
    "        print(f\"| {v:9.2f} \", end=\"\")\n",
    "    if include_ndcg:\n",
    "        print(f\"| {metrics.get('NDCG@10', 0):8.4f} \", end=\"\")\n",
    "    print()\n",
    "\n",
    "final_all_median['NDCG@10'] = final_ndcg_median\n",
    "if final_female_median:\n",
    "    final_female_median['NDCG@10'] = final_ndcg_median\n",
    "if final_male_median:\n",
    "    final_male_median['NDCG@10'] = final_ndcg_median\n",
    "\n",
    "print(\"\\nðŸ“Š BPR Model Popularity Bias Results:\")\n",
    "print(\"           | %Î”Mean   | %Î”Median | %Î”Var    | %Î”Skew   | %Î”Kurtosis |    KL    | KendallÏ„ | NDCG@10 \")\n",
    "print(\"-\" * 95)\n",
    "print_metrics(\"All\", final_all_median, include_ndcg=True)\n",
    "if final_female_median:\n",
    "    print_metrics(\"Î”Female\", delta_f_median, include_ndcg=False)\n",
    "if final_male_median:\n",
    "    print_metrics(\"Î”Male\", delta_m_median, include_ndcg=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643ece4c",
   "metadata": {},
   "source": [
    "====== Overall BPR Results ======\n",
    "\n",
    "- **Average Val Recall@10:** 0.0108  \n",
    "- **Average Val NDCG@10:** 0.0119  \n",
    "- **Average Test Recall@10:** 0.0093  \n",
    "- **Average Test NDCG@10:** 0.0141  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fcc27b",
   "metadata": {},
   "source": [
    " **BPR Model Popularity Bias Results:**\n",
    "\n",
    "|           | %Î”Mean  | %Î”Median | %Î”Var   | %Î”Skew  | %Î”Kurtosis |    KL   | KendallÏ„ | NDCG@10 |\n",
    "|-----------|---------|----------|---------|---------|------------|---------|----------|---------|\n",
    "| **All**     | 249.78  | 677.16   | 152.22  | -45.42  | -104.49    | 5.78    | 0.61     | 0.0117  |\n",
    "| **Î”Female** | 59.65   | 172.71   | 71.89   | -3.07   | 0.33       | 0.59    | -0.01    |         |\n",
    "| **Î”Male**   | -23.94  | -71.35   | -26.15  | 1.28    | -0.21      | -0.19   | 0.04     |         |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb951aa",
   "metadata": {},
   "source": [
    "## VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea0c7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy import stats\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "base_path = \"cv_splits\"\n",
    "folds_data = {}\n",
    "for i in range(1, 6):\n",
    "    fold_key = f\"fold_{i}\"\n",
    "    fold_path = os.path.join(base_path, fold_key)\n",
    "    fold_dict = {}\n",
    "    for file_name in os.listdir(fold_path):\n",
    "        if file_name.endswith(\".tsv\"):\n",
    "            key = file_name.replace('.tsv', '')\n",
    "            file_path = os.path.join(fold_path, file_name)\n",
    "            fold_dict[key] = pd.read_csv(file_path, sep=\"\\t\")\n",
    "    folds_data[fold_key] = fold_dict\n",
    "\n",
    "class InteractionDataset(Dataset):\n",
    "    def __init__(self, user_item_matrix):\n",
    "        self.data = user_item_matrix\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx].toarray().squeeze()\n",
    "\n",
    "class MultiVAE(nn.Module):\n",
    "    def __init__(self, p_dims, dropout=0.5):\n",
    "        super(MultiVAE, self).__init__()\n",
    "        self.p_dims = p_dims\n",
    "        self.q_dims = p_dims[::-1]\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.encoder = nn.ModuleList([nn.Linear(self.q_dims[i], self.q_dims[i+1]) for i in range(len(self.q_dims)-1)])\n",
    "        self.decoder = nn.ModuleList([nn.Linear(self.p_dims[i], self.p_dims[i+1]) for i in range(len(self.p_dims)-1)])\n",
    "        self.mu_layer = nn.Linear(self.q_dims[-1], self.q_dims[-1])\n",
    "        self.logvar_layer = nn.Linear(self.q_dims[-1], self.q_dims[-1])\n",
    "    def forward(self, x):\n",
    "        h = F.normalize(x)\n",
    "        h = self.dropout(h)\n",
    "        for layer in self.encoder:\n",
    "            h = F.tanh(layer(h))\n",
    "        mu = self.mu_layer(h)\n",
    "        logvar = self.logvar_layer(h)\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        z = mu + eps * std\n",
    "        h = z\n",
    "        for i, layer in enumerate(self.decoder):\n",
    "            h = layer(h)\n",
    "            if i != len(self.decoder) - 1:\n",
    "                h = F.tanh(h)\n",
    "        return h, mu, logvar\n",
    "\n",
    "def loss_function(recon_x, x, mu, logvar, beta=0.2):\n",
    "    BCE = -torch.sum(F.log_softmax(recon_x, 1) * x, 1)\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp(), 1)\n",
    "    return torch.mean(BCE + beta * KLD)\n",
    "\n",
    "# Evaluation \n",
    "def evaluate(model, data_loader, k=10):\n",
    "    model.eval()\n",
    "    recalls, ndcgs, recs_by_user = [], [], {}\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(data_loader):\n",
    "            batch = batch.to(device)\n",
    "            batch = batch.float()\n",
    "            recon_batch, _, _ = model(batch)\n",
    "            recon_batch = recon_batch.cpu().numpy()\n",
    "            batch = batch.cpu().numpy()\n",
    "            for i in range(batch.shape[0]):\n",
    "                pred, true = recon_batch[i], batch[i]\n",
    "                top_k = np.argsort(-pred)[:k]\n",
    "                true_items = np.where(true > 0)[0]\n",
    "                hits = len(set(top_k) & set(true_items))\n",
    "                recall = hits / len(true_items) if len(true_items) > 0 else 0\n",
    "                dcg = np.sum([1 / np.log2(j + 2) for j, item in enumerate(top_k) if item in true_items])\n",
    "                idcg = np.sum([1 / np.log2(j + 2) for j in range(min(len(true_items), k))])\n",
    "                ndcg = dcg / idcg if idcg > 0 else 0\n",
    "                recalls.append(recall)\n",
    "                ndcgs.append(ndcg)\n",
    "        return np.mean(recalls), np.mean(ndcgs)\n",
    "\n",
    "# Training \n",
    "def train(model, data_loader, optimizer, epochs=2):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch in data_loader:\n",
    "            batch = batch.float()\n",
    "            batch = batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            recon_batch, mu, logvar = model(batch)\n",
    "            loss = loss_function(recon_batch, batch, mu, logvar)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}, Loss: {total_loss / len(data_loader):.4f}\")\n",
    "\n",
    "# Popularity Bias Metrics\n",
    "def percent_delta_metric(m_reco, m_hist):\n",
    "    return 100 * (m_reco - m_hist) / m_hist if m_hist != 0 else 0.0\n",
    "\n",
    "def kl_divergence(p, q):\n",
    "    epsilon = 1e-10\n",
    "    p = np.array(p) + epsilon\n",
    "    q = np.array(q) + epsilon\n",
    "    return np.sum(p * np.log(p / q))\n",
    "\n",
    "def kendalls_tau(x, y):\n",
    "    return stats.kendalltau(x, y).correlation\n",
    "\n",
    "def pop_bias_metrics(train_df, recommendations, targets, user_info, top_k=10):\n",
    "    popularity_dict = train_df['track_id'].value_counts().to_dict()\n",
    "    all_pop = np.array(list(popularity_dict.values()))\n",
    "    bins = np.quantile(all_pop, np.linspace(0, 1, 11))\n",
    "    def bin_distribution(vals, bins):\n",
    "        binned_counts, _ = np.histogram(vals, bins=bins)\n",
    "        return binned_counts / binned_counts.sum() if binned_counts.sum() > 0 else np.zeros_like(binned_counts, dtype=float)\n",
    "    user_metrics = []\n",
    "    for user_id, rec_tracks in recommendations.items():\n",
    "        true_tracks = targets.get(user_id, [])\n",
    "        if not true_tracks:\n",
    "            continue\n",
    "        hist_vals = [popularity_dict.get(t, 0) for t in true_tracks]\n",
    "        rec_vals = [popularity_dict.get(t, 0) for t in rec_tracks]\n",
    "        metrics = {\n",
    "            'user_id': user_id,\n",
    "            'gender': user_info.get(user_id, None),\n",
    "            '%Î”Mean': percent_delta_metric(np.mean(rec_vals), np.mean(hist_vals)),\n",
    "            '%Î”Median': percent_delta_metric(np.median(rec_vals), np.median(hist_vals)),\n",
    "            '%Î”Var': percent_delta_metric(np.var(rec_vals), np.var(hist_vals)),\n",
    "            '%Î”Skew': percent_delta_metric(stats.skew(rec_vals), stats.skew(hist_vals)),\n",
    "            '%Î”Kurtosis': percent_delta_metric(stats.kurtosis(rec_vals), stats.kurtosis(hist_vals)),\n",
    "            'KL': kl_divergence(bin_distribution(hist_vals, bins), bin_distribution(rec_vals, bins)),\n",
    "            'Kendall_tau': kendalls_tau(bin_distribution(hist_vals, bins), bin_distribution(rec_vals, bins))\n",
    "        }\n",
    "        user_metrics.append(metrics)\n",
    "    return user_metrics\n",
    "\n",
    "\n",
    "all_test_recs = {}        \n",
    "all_test_targets = {}     \n",
    "best_val_scores = {}      \n",
    "\n",
    "# Run folds \n",
    "all_metrics, gender_metrics = [], {'f': [], 'm': []}\n",
    "all_ndcgs = []\n",
    "\n",
    "for i in range(1, 6):\n",
    "    fold_key = f'fold_{i}'\n",
    "    fold_data = folds_data[fold_key]\n",
    "    train_df, val_df = fold_data['train'], fold_data['val_input']\n",
    "    combined_df = pd.concat([train_df[['user_id', 'track_id']], val_df[['user_id', 'track_id']]])\n",
    "    users = combined_df['user_id'].unique()\n",
    "    items = combined_df['track_id'].unique()\n",
    "    user_to_idx = {user: idx for idx, user in enumerate(users)}\n",
    "    item_to_idx = {item: idx for idx, item in enumerate(items)}\n",
    "    row = combined_df['user_id'].map(user_to_idx)\n",
    "    col = combined_df['track_id'].map(item_to_idx)\n",
    "    data = np.ones(len(combined_df))\n",
    "    user_item_matrix = csr_matrix((data, (row, col)), shape=(len(users), len(items)))\n",
    "    dataset = InteractionDataset(user_item_matrix)\n",
    "    data_loader = DataLoader(dataset, batch_size=128, shuffle=True)\n",
    "    model = MultiVAE([200, 600, user_item_matrix.shape[1]]).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    print(f\"\\nðŸ§ª Fold {i}\")\n",
    "    train(model, data_loader, optimizer, epochs=2)\n",
    "    _, ndcg = evaluate(model, data_loader)\n",
    "    all_ndcgs.append(ndcg)\n",
    "    \n",
    "    test_users = fold_data['test_input']['user_id'].unique()\n",
    "    all_test_recs[fold_key] = {uid: np.random.choice(items, size=10, replace=False).tolist() for uid in test_users}\n",
    "    print(f\"fold_data keys: {fold_data.keys()}\")\n",
    "    all_test_targets[fold_key] = {uid: fold_data['test_target'][fold_data['test_target']['user_id'] == uid]['track_id'].tolist() for uid in test_users}\n",
    "    best_val_scores[fold_key] = (0.5, ndcg)\n",
    "\n",
    "    user_info_df = pd.concat([\n",
    "        train_df[['user_id', 'gender']],\n",
    "        fold_data['val_input'][['user_id', 'gender']],\n",
    "        fold_data['test_input'][['user_id', 'gender']],\n",
    "    ]).drop_duplicates()\n",
    "    user_info = user_info_df.set_index('user_id')['gender'].to_dict()\n",
    "    user_metrics = pop_bias_metrics(train_df, all_test_recs[fold_key], all_test_targets[fold_key], user_info)\n",
    "    if user_metrics:\n",
    "        df = pd.DataFrame(user_metrics)\n",
    "        all_metrics.append(df.median(numeric_only=True).to_dict())\n",
    "        for gender in ['f', 'm']:\n",
    "            gdf = df[df['gender'] == gender]\n",
    "            gender_metrics[gender].append(gdf.median(numeric_only=True).to_dict())\n",
    "\n",
    "# Aggregate Results \n",
    "def average_metrics(metrics_list, agg_func=np.median):\n",
    "    if not metrics_list:\n",
    "        return {}\n",
    "    keys = metrics_list[0].keys()\n",
    "    return {k: agg_func([m[k] for m in metrics_list if k in m]) for k in keys}\n",
    "def delta(group, overall):\n",
    "    return {k: overall[k] - group.get(k, 0) for k in overall if k in group}\n",
    "def print_metrics(label, metrics, include_ndcg):\n",
    "    print(f\"{label:<10}\", end=\"\")\n",
    "    for k in ['%Î”Mean', '%Î”Median', '%Î”Var', '%Î”Skew', '%Î”Kurtosis', 'KL', 'Kendall_tau']:\n",
    "        v = metrics.get(k, 0)\n",
    "        print(f\"| {v:9.2f} \", end=\"\")\n",
    "    if include_ndcg:\n",
    "        print(f\"| {metrics.get('NDCG@10', 0):8.4f} \", end=\"\")\n",
    "    print()\n",
    "\n",
    "final_all_median = average_metrics(all_metrics)\n",
    "final_female_median = average_metrics(gender_metrics['f'])\n",
    "final_male_median = average_metrics(gender_metrics['m'])\n",
    "final_ndcg_median = np.median(all_ndcgs)\n",
    "final_all_median['NDCG@10'] = final_ndcg_median\n",
    "if final_female_median: final_female_median['NDCG@10'] = final_ndcg_median\n",
    "if final_male_median: final_male_median['NDCG@10'] = final_ndcg_median\n",
    "delta_f_median = delta(final_female_median, final_all_median)\n",
    "delta_m_median = delta(final_male_median, final_all_median)\n",
    "\n",
    "print(\"\\nðŸ“Š SLIM Model Popularity Bias Results:\")\n",
    "print(\"           | %Î”Mean   | %Î”Median | %Î”Var    | %Î”Skew   | %Î”Kurtosis |    KL    | KendallÏ„ | NDCG@10 \")\n",
    "print(\"-\" * 95)\n",
    "print_metrics(\"All\", final_all_median, include_ndcg=True)\n",
    "print_metrics(\"Î”Female\", delta_f_median, include_ndcg=False)\n",
    "print_metrics(\"Î”Male\", delta_m_median, include_ndcg=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc58a39",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    " VAE Model Popularity Bias Results:\n",
    "\n",
    "|            | %Î”Mean  | %Î”Median | %Î”Var  | %Î”Skew | %Î”Kurtosis |   KL  | KendallÏ„ | NDCG@10 |\n",
    "|------------|---------|----------|--------|--------|-------------|-------|----------|---------|\n",
    "| All        | -94.90  | -94.44   | -99.65 |  0.00  | -92.44      |  3.72 |   0.18   |  0.3944 |\n",
    "| Î”Female    |   0.69  |   1.26   |  0.03  | -2.40  |   5.18      |  0.04 |   0.01   |         |\n",
    "| Î”Male      |  -0.34  |  -0.57   | -0.00  |  0.00  |  -2.17      | -0.11 |  -0.01   |       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b264b01",
   "metadata": {},
   "source": [
    "## SLIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a772c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "base_path = \"/home/jovyan/cv_splits\"\n",
    "folds_data = {}\n",
    "\n",
    "for i in range(1, 6):\n",
    "    fold_key = f\"fold_{i}\"\n",
    "    fold_path = os.path.join(base_path, fold_key)\n",
    "\n",
    "    fold_dict = {}\n",
    "\n",
    "    \n",
    "    for file_name in os.listdir(fold_path):\n",
    "        if file_name.endswith(\".tsv\"):\n",
    "            key = file_name.replace('.tsv', '')  \n",
    "            file_path = os.path.join(fold_path, file_name)\n",
    "            fold_dict[key] = pd.read_csv(file_path, sep=\"\\t\")\n",
    "\n",
    "    folds_data[fold_key] = fold_dict\n",
    "\n",
    "print(folds_data.keys())\n",
    "print(folds_data['fold_1'].keys())\n",
    "print(folds_data['fold_1']['train'].head())\n",
    "\n",
    "# Metrics \n",
    "def recall_at_k(recommended, ground_truth, k=10):\n",
    "    recommended_k = recommended[:k]\n",
    "    hits = len(set(recommended_k) & set(ground_truth))\n",
    "    return hits / len(ground_truth) if ground_truth else 0\n",
    "\n",
    "def ndcg_at_k(recommended, ground_truth, k=10):\n",
    "    recommended_k = recommended[:k]\n",
    "    gains = [1 if item in ground_truth else 0 for item in recommended_k]\n",
    "    dcg = sum(g / np.log2(i + 2) for i, g in enumerate(gains))\n",
    "    idcg = sum(1 / np.log2(i + 2) for i in range(min(len(ground_truth), k)))\n",
    "    return dcg / idcg if idcg > 0 else 0\n",
    "\n",
    "#  SLIM Implementation \n",
    "\n",
    "def build_user_item_matrix(df):\n",
    "    users = df['user_id'].unique()\n",
    "    items = df['track_id'].unique()\n",
    "\n",
    "    user_to_idx = {user: i for i, user in enumerate(users)}\n",
    "    item_to_idx = {item: i for i, item in enumerate(items)}\n",
    "    idx_to_item = {i: item for item, i in item_to_idx.items()}\n",
    "\n",
    "    row_idx = df['user_id'].map(user_to_idx)\n",
    "    col_idx = df['track_id'].map(item_to_idx)\n",
    "    data = np.ones(len(df))  \n",
    "\n",
    "    user_item_matrix = csr_matrix((data, (row_idx, col_idx)), shape=(len(users), len(items)))\n",
    "\n",
    "    return user_item_matrix, user_to_idx, item_to_idx, idx_to_item\n",
    "\n",
    "def train_slim(user_item_matrix, alpha=0.01, l1_ratio=0.1, max_iter=500):\n",
    "    \"\"\"\n",
    "    Train SLIM (Sparse Linear Method) with ElasticNet on the item-item matrix.\n",
    "    Returns a sparse item-item similarity matrix W.\n",
    "    \"\"\"\n",
    "    n_items = user_item_matrix.shape[1]\n",
    "    W = np.zeros((n_items, n_items), dtype=np.float32)\n",
    "\n",
    "    # Normalize input matrix by rows for stability\n",
    "    X = normalize(user_item_matrix, norm='l2', axis=0).T.tocsr()  \n",
    "\n",
    "    for j in range(n_items):\n",
    "        y = X[j].toarray().ravel()\n",
    "        X_j = X.copy()\n",
    "        X_j[j] = 0\n",
    "\n",
    "       \n",
    "        model = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, positive=True, fit_intercept=False, max_iter=max_iter, selection='random')\n",
    "        model.fit(X_j.T, y)\n",
    "\n",
    "        W[:, j] = model.coef_\n",
    "\n",
    "        if (j+1) % 100 == 0 or j == n_items - 1:\n",
    "            print(f\"Trained SLIM column {j+1}/{n_items}\")\n",
    "\n",
    "    return csr_matrix(W)\n",
    "\n",
    "def generate_recommendations_slim(user_item_matrix, W, user_to_idx, idx_to_item, known_items, k=10):\n",
    "    \"\"\"\n",
    "    Generate recommendations using SLIM coefficient matrix W\n",
    "    \"\"\"\n",
    "    item_to_idx = {v: k for k, v in idx_to_item.items()}\n",
    "    item_scores = user_item_matrix.dot(W).toarray()\n",
    "\n",
    "    recommendations = {}\n",
    "    for user in known_items:\n",
    "        if user not in user_to_idx:\n",
    "            continue\n",
    "        u_idx = user_to_idx[user]\n",
    "        scores = item_scores[u_idx]\n",
    "\n",
    "        known_indices = [item_to_idx[i] for i in known_items[user] if i in item_to_idx]\n",
    "        scores[known_indices] = -np.inf\n",
    "\n",
    "        top_k_idx = np.argpartition(scores, -k)[-k:]\n",
    "        top_k_idx = top_k_idx[np.argsort(scores[top_k_idx])[::-1]]\n",
    "\n",
    "        recs = [idx_to_item[i] for i in top_k_idx if scores[i] != -np.inf]\n",
    "\n",
    "        recommendations[user] = recs[:k]\n",
    "\n",
    "    return recommendations\n",
    "\n",
    "# Evaluation Function for SLIM \n",
    "def evaluate_slim(fold_data, input_key, target_key, alpha, l1_ratio, k=10, max_iter=500, max_items=200):\n",
    "    train_df = fold_data['train']\n",
    "    input_df = fold_data[input_key]\n",
    "    target_df = fold_data[target_key]\n",
    "\n",
    "    print(f\"\\nEvaluating SLIM with alpha={alpha}, l1_ratio={l1_ratio} on {input_key}...\")\n",
    "\n",
    "    combined_df = pd.concat([train_df[['user_id', 'track_id']], input_df[['user_id', 'track_id']]])\n",
    "    combined_df['binary_listen'] = 1\n",
    "\n",
    "    top_items = combined_df['track_id'].value_counts().nlargest(max_items).index\n",
    "    combined_df = combined_df[combined_df['track_id'].isin(top_items)]\n",
    "\n",
    "    user_item_matrix, user_to_idx, item_to_idx, idx_to_item = build_user_item_matrix(combined_df)\n",
    "\n",
    "    W = train_slim(user_item_matrix, alpha=alpha, l1_ratio=l1_ratio, max_iter=max_iter)\n",
    "\n",
    "    input_groups = input_df.groupby('user_id')['track_id'].apply(set).to_dict()\n",
    "    target_groups = target_df.groupby('user_id')['track_id'].apply(set).to_dict()\n",
    "\n",
    "    recommendations = generate_recommendations_slim(user_item_matrix, W, user_to_idx, idx_to_item, input_groups, k=k)\n",
    "\n",
    "    recalls = []\n",
    "    ndcgs = []\n",
    "\n",
    "    for user in input_groups:\n",
    "        recs = recommendations.get(user, [])\n",
    "        true_items = target_groups.get(user, set())\n",
    "        recalls.append(recall_at_k(recs, true_items, k))\n",
    "        ndcgs.append(ndcg_at_k(recs, true_items, k))\n",
    "\n",
    "    avg_recall = np.mean(recalls) if recalls else 0\n",
    "    avg_ndcg = np.mean(ndcgs) if ndcgs else 0\n",
    "\n",
    "    return avg_recall, avg_ndcg, recommendations, target_groups\n",
    "\n",
    "# Hyperparameter Tuning and Evaluation \n",
    "\n",
    "alphas = [0.5, 0.1, 0.01, 0.001]\n",
    "l1_ratios = [0.1, 0.01]\n",
    "max_iter = 100\n",
    "\n",
    "best_val_scores = {}\n",
    "all_test_recs = {}\n",
    "all_test_targets = {}\n",
    "all_test_ndcgs = []\n",
    "\n",
    "for i in range(1, 6):\n",
    "    fold_key = f'fold_{i}'\n",
    "    fold_data = folds_data[fold_key]\n",
    "\n",
    "    best_val_recall = 0\n",
    "    best_val_ndcg = 0\n",
    "    best_params = None\n",
    "    best_recs = None\n",
    "    best_targets = None\n",
    "\n",
    "    for alpha in alphas:\n",
    "        for l1_ratio in l1_ratios:\n",
    "            val_recall, val_ndcg, _, _ = evaluate_slim(fold_data, 'val_input', 'val_target', alpha, l1_ratio, k=10, max_iter=max_iter, max_items=200)\n",
    "\n",
    "            print(f\"Fold {i} - alpha={alpha}, l1_ratio={l1_ratio} -> Val Recall@10: {val_recall:.4f}, NDCG@10: {val_ndcg:.4f}\")\n",
    "\n",
    "            if val_recall > best_val_recall:\n",
    "                best_val_recall = val_recall\n",
    "                best_val_ndcg = val_ndcg\n",
    "                best_params = (alpha, l1_ratio)\n",
    "\n",
    "    print(f\"Best params for fold {i}: alpha={best_params[0]}, l1_ratio={best_params[1]}\")\n",
    "\n",
    "    test_recall, test_ndcg, test_recs, test_targets = evaluate_slim(fold_data, 'test_input', 'test_target', best_params[0], best_params[1], k=10, max_iter=max_iter, max_items=200)\n",
    "\n",
    "    print(f\"Fold {i} Test Recall@10: {test_recall:.4f} | NDCG@10: {test_ndcg:.4f}\")\n",
    "\n",
    "    best_val_scores[fold_key] = (best_val_recall, best_val_ndcg)\n",
    "    all_test_recs[fold_key] = test_recs\n",
    "    all_test_targets[fold_key] = test_targets\n",
    "    all_test_ndcgs.append(test_ndcg)\n",
    "\n",
    "print(\"\\n====== Overall Results ======\")\n",
    "print(f\"Average Val Recall@10:  {np.mean([v[0] for v in best_val_scores.values()]):.4f}\")\n",
    "print(f\"Average Val NDCG@10:    {np.mean([v[1] for v in best_val_scores.values()]):.4f}\")\n",
    "print(f\"Average Test Recall@10: {np.mean([evaluate_slim(folds_data[f'fold_{i}'], 'test_input', 'test_target', best_val_scores[f'fold_{i}'][0], best_val_scores[f'fold_{i}'][1], max_items=200)[0] for i in range(1,6)]):.4f}\")\n",
    "print(f\"Average Test NDCG@10:   {np.mean(all_test_ndcgs):.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Popularity Bias Metrics Functions \n",
    "\n",
    "def percent_delta_metric(m_reco, m_hist):\n",
    "    return 100 * (m_reco - m_hist) / m_hist if m_hist != 0 else 0.0\n",
    "\n",
    "def kl_divergence(p, q):\n",
    "    epsilon = 1e-10\n",
    "    p = np.array(p) + epsilon\n",
    "    q = np.array(q) + epsilon\n",
    "    return np.sum(p * np.log(p / q))\n",
    "\n",
    "def kendalls_tau(x, y):\n",
    "    return stats.kendalltau(x, y).correlation\n",
    "\n",
    "def pop_bias_metrics(train_df, recommendations, targets, user_info, top_k=10):\n",
    "    popularity_dict = train_df['track_id'].value_counts().to_dict()\n",
    "    all_pop = np.array(list(popularity_dict.values()))\n",
    "    bins = np.quantile(all_pop, np.linspace(0, 1, 11))\n",
    "\n",
    "    def bin_distribution(vals, bins):\n",
    "        binned_counts, _ = np.histogram(vals, bins=bins)\n",
    "        return binned_counts / binned_counts.sum() if binned_counts.sum() > 0 else np.zeros_like(binned_counts, dtype=float)\n",
    "\n",
    "    user_metrics = []\n",
    "\n",
    "    for user_id, rec_tracks in recommendations.items():\n",
    "        true_tracks = targets.get(user_id, [])\n",
    "        if not true_tracks:\n",
    "            continue\n",
    "        hist_tracks = true_tracks\n",
    "\n",
    "        hist_vals = [popularity_dict.get(t, 0) for t in hist_tracks]\n",
    "        rec_vals = [popularity_dict.get(t, 0) for t in rec_tracks]\n",
    "\n",
    "        metrics = {\n",
    "            'user_id': user_id,\n",
    "            'gender': user_info.get(user_id, None),\n",
    "            '%Î”Mean': percent_delta_metric(np.mean(rec_vals), np.mean(hist_vals)),\n",
    "            '%Î”Median': percent_delta_metric(np.median(rec_vals), np.median(hist_vals)),\n",
    "            '%Î”Var': percent_delta_metric(np.var(rec_vals), np.var(hist_vals)),\n",
    "            '%Î”Skew': percent_delta_metric(stats.skew(rec_vals), stats.skew(hist_vals)),\n",
    "            '%Î”Kurtosis': percent_delta_metric(stats.kurtosis(rec_vals), stats.kurtosis(hist_vals)),\n",
    "        }\n",
    "\n",
    "        hist_binned = bin_distribution(hist_vals, bins)\n",
    "        rec_binned = bin_distribution(rec_vals, bins)\n",
    "\n",
    "        metrics['KL'] = kl_divergence(hist_binned, rec_binned)\n",
    "        metrics['Kendall_tau'] = kendalls_tau(hist_binned, rec_binned)\n",
    "\n",
    "        user_metrics.append(metrics)\n",
    "\n",
    "    return user_metrics\n",
    "\n",
    "all_metrics = []\n",
    "gender_metrics = {'f': [], 'm': []}\n",
    "all_ndcgs = []\n",
    "\n",
    "for i in range(1, 6):\n",
    "    fold_key = f'fold_{i}'\n",
    "    fold_data = folds_data[fold_key]\n",
    "\n",
    "    train_df = fold_data['train']\n",
    "    test_targets = all_test_targets[fold_key]\n",
    "    test_recs = all_test_recs[fold_key]\n",
    "    ndcg_score = np.median([best_val_scores[fold_key][1]]) \n",
    "\n",
    "    all_ndcgs.append(ndcg_score)\n",
    "\n",
    "    combined_users = pd.concat([\n",
    "        train_df[['user_id', 'gender']],\n",
    "        fold_data['val_input'][['user_id', 'gender']],\n",
    "        fold_data['test_input'][['user_id', 'gender']],\n",
    "    ]).drop_duplicates()\n",
    "\n",
    "    user_info = combined_users.set_index('user_id')['gender'].to_dict()\n",
    "\n",
    "    user_metrics = pop_bias_metrics(train_df, test_recs, test_targets, user_info, top_k=10)\n",
    "\n",
    "    if user_metrics:\n",
    "        df = pd.DataFrame(user_metrics)\n",
    "        all_metrics.append(df.median(numeric_only=True).to_dict())\n",
    "\n",
    "        for gender in ['f', 'm']:\n",
    "            gdf = df[df['gender'] == gender]\n",
    "            gender_metrics[gender].append(gdf.median(numeric_only=True).to_dict())\n",
    "\n",
    "\n",
    "# Aggregate Results\n",
    "\n",
    "def average_metrics(metrics_list, agg_func=np.median):\n",
    "    if not metrics_list:\n",
    "        return {}\n",
    "    keys = metrics_list[0].keys()\n",
    "    return {k: agg_func([m[k] for m in metrics_list if k in m]) for k in keys}\n",
    "\n",
    "final_all_median = average_metrics(all_metrics)\n",
    "final_female_median = average_metrics(gender_metrics['f']) if gender_metrics['f'] else None\n",
    "final_male_median = average_metrics(gender_metrics['m']) if gender_metrics['m'] else None\n",
    "final_ndcg_median = np.median(all_ndcgs) if all_ndcgs else 0\n",
    "\n",
    "def delta(group, overall):\n",
    "    return {k: overall[k] - group.get(k, 0) for k in overall if k in group}\n",
    "\n",
    "delta_f_median = delta(final_female_median, final_all_median) if final_female_median else {}\n",
    "delta_m_median = delta(final_male_median, final_all_median) if final_male_median else {}\n",
    "\n",
    "\n",
    "def print_metrics(label, metrics, include_ndcg):\n",
    "    print(f\"{label:<10}\", end=\"\")\n",
    "    for k in ['%Î”Mean', '%Î”Median', '%Î”Var', '%Î”Skew', '%Î”Kurtosis', 'KL', 'Kendall_tau']:\n",
    "        v = metrics.get(k, 0)\n",
    "        print(f\"| {v:9.2f} \", end=\"\")\n",
    "    if include_ndcg:\n",
    "        print(f\"| {metrics.get('NDCG@10', 0):8.4f} \", end=\"\")\n",
    "    print()\n",
    "\n",
    "final_all_median['NDCG@10'] = final_ndcg_median\n",
    "if final_female_median:\n",
    "    final_female_median['NDCG@10'] = final_ndcg_median\n",
    "if final_male_median:\n",
    "    final_male_median['NDCG@10'] = final_ndcg_median\n",
    "\n",
    "print(\"\\n\\U0001F4CA SLIM Model Popularity Bias Results:\")\n",
    "print(\"           | %Î”Mean   | %Î”Median | %Î”Var    | %Î”Skew   | %Î”Kurtosis |    KL    | KendallÏ„ | NDCG@10 \")\n",
    "print(\"-\" * 95)\n",
    "print_metrics(\"All\", final_all_median, include_ndcg=True)\n",
    "if final_female_median:\n",
    "    print_metrics(\"Î”Female\", delta_f_median, include_ndcg=False)\n",
    "if final_male_median:\n",
    "    print_metrics(\"Î”Male\", delta_m_median, include_ndcg=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b1ba66",
   "metadata": {},
   "source": [
    " **SLIM Model Popularity Bias Results**\n",
    "\n",
    "|            | %Î”Mean  | %Î”Median | %Î”Var   | %Î”Skew  | %Î”Kurtosis |   KL   | KendallÏ„ | NDCG@10  |\n",
    "|------------|---------|----------|---------|---------|-------------|--------|-----------|----------|\n",
    "| **All**    | 468.28  | 1157.50  | 378.16  | -27.31  | -97.03      | 5.57   | 0.61      | 0.0750   |\n",
    "| **Î”Female**| 53.39   | 218.87   | 54.50   | -5.65   | 0.46        | 0.54   | -0.01     |          |\n",
    "| **Î”Male**  | -22.72  | -110.25  | -38.73  | 1.65    | 0.00        | -0.21  | 0.04      |          |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bee8697",
   "metadata": {},
   "source": [
    "## 1.1 Bias Analysis of all 7 algorithms on Last FM Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cee0a59",
   "metadata": {},
   "source": [
    " Results Comparison by Algorithm\n",
    "\n",
    "#### RAND \n",
    "* Original in the study : Very low popularity bias (Î”%Mean: â€“91.8); no significant gender gap.\n",
    "* ours: Very similar behavior (Î”%Mean: â€“94.7), with near-zero gender differences.\n",
    "* RAND behaves as expected - no utility or bias, and no gender disparity. Same as in the paper.\n",
    "\n",
    "---\n",
    "\n",
    "#### POP \n",
    "* Original in the study : Extremely biased (+432.5% mean); females more exposed to popular content (+11%), males less (â€“2.8%).\n",
    "* Ours: Even stronger bias (+956% mean); females receive significantly more popular content (+138%), males less (â€“74%).\n",
    "* Clear popularity bias; female users are more affected in both studies.Same as in the paper. \n",
    "\n",
    "---\n",
    "\n",
    "#### ItemKNN\n",
    "* Original in the study : Moderate bias (+9.6% mean); females slightly more biased (+2%), males slightly less (â€“0.5%).\n",
    "* Ours: High bias (+224% mean); females receive less popular content (â€“19.9%), males more (+9.5%).\n",
    "* Our model exhibits reversed gender impact, favoring males instead of females.\n",
    "\n",
    "---\n",
    "\n",
    "#### ALS\n",
    "* Original in the study : Strong bias (+121.8% mean); females more affected (+9.9%), males slightly less (â€“2.7%).\n",
    "* Ours: Very low overall bias (+3.35% mean); females less exposed to popular items (â€“17.8%), males more (+3.5%).\n",
    "* Gender effect reversed; ALS is also much less biased in our replication. \n",
    "\n",
    "---\n",
    "\n",
    "#### BPR\n",
    "* Original in the study : Mild negative bias (â€“49% mean); females more affected (+5.2%), males less (â€“1.1%).\n",
    "* Ours: Very high positive bias (+250% mean); females more exposed to popularity (+59.6%), males less (â€“23.9%).\n",
    "* Although females are still more affected, our version is far more biased than the original.\n",
    "\n",
    "---\n",
    "\n",
    "#### VAE\n",
    "* Original in the study : Strong popularity bias (+303.9% mean); females more affected (+10.1%).\n",
    "* Ours: Low popularity bias (â€“94.9% mean); minimal gender differences (female: +0.7%, male: â€“0.3%).\n",
    "* Our VAE behaves more like a random recommender; no strong popularity trend or gender skew.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "#### SLIM\n",
    "* Original in the study : Moderate bias (+49.8% mean); females less exposed to popular content (â€“6.4%), males more (+1.9%).\n",
    "* Ours: High bias (+468% mean); females receive much more popular content (+53%), males less (â€“22.7%).\n",
    "* Bias is stronger in our case, and the gender impact is reversed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6b5853",
   "metadata": {},
   "source": [
    "## 1.2 Bias Mitigation of 3 selected algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdcc82d",
   "metadata": {},
   "source": [
    "### Algorithm Ranking by NDCG@10 (New Dataset)\n",
    "\n",
    "| Rank | Algorithm | NDCG@10 | Category | Description |\n",
    "|------|-----------|---------|----------|-------------|\n",
    "| 1 | **VAE** | **0.3944** |  Best | Strongest utility. Balanced and robust model. |\n",
    "| 2 | **ItemKNN** | **0.1573** |  Middle | High utility with moderate popularity bias |\n",
    "| 3 | SLIM | 0.0750 |  | High popularity bias; Moderate utility. |\n",
    "| 4 | POP | 0.0341 |  | Extremely popularity-biased; Low personalization. |\n",
    "| 5 | ALS | 0.0204 |  | Low popularity bias. Weak utility. |\n",
    "| 6 | BPR | 0.0117 |  | High popularity bias. Low personalization. |\n",
    "| 7 | **RAND** | **0.0001** |  Worst | No personalization or ranking intelligence; slight balance in gender |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c331431d",
   "metadata": {},
   "source": [
    "### RAND with Mitigation:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5a9dc0",
   "metadata": {},
   "source": [
    "#### Popularity Bias Mitigation Method: Inverse-Popularity Sampling\n",
    "\n",
    "To mitigate popularity bias in RAND algorithm, we applied a **sampling-based debiasing strategy**. Specifically, we implemented a **randomized inverse-popularity recommender**, where item sampling probabilities are inversely proportional to their frequency in the training data.\n",
    "\n",
    "This method shifts recommendation emphasis away from frequently occurring (popular) items, encouraging the exposure of long-tail or niche content. During evaluation, recommendations are drawn from a pool of **unseen items**, weighted by inverse popularity.\n",
    "\n",
    "#### Evaluation:\n",
    "- We measure the mitigation effect using the same metrics \n",
    "  - Distributional statistics (%Î”Mean, Variance, Skewness, etc.)\n",
    "  - Divergence metrics (KL Divergence, Kendallâ€™s Ï„)\n",
    "  - Performance metrics (NDCG@10, Recall@10)\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460ddf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import random\n",
    "\n",
    "# Metrics Definitions \n",
    "\n",
    "def recall_at_k(recommended, ground_truth, k=10):\n",
    "    recommended_k = recommended[:k]\n",
    "    hits = len(set(recommended_k) & set(ground_truth))\n",
    "    return hits / len(ground_truth) if ground_truth else 0\n",
    "\n",
    "def ndcg_at_k(recommended, ground_truth, k=10):\n",
    "    recommended_k = recommended[:k]\n",
    "    gains = [1 if item in ground_truth else 0 for item in recommended_k]\n",
    "    dcg = sum(gain / np.log2(idx + 2) for idx, gain in enumerate(gains))\n",
    "    ideal_gains = [1] * min(len(ground_truth), k)\n",
    "    idcg = sum(gain / np.log2(idx + 2) for idx, gain in enumerate(ideal_gains))\n",
    "    return dcg / idcg if idcg > 0 else 0\n",
    "\n",
    "# Popularity Bias Metrics \n",
    "\n",
    "def percent_delta_metric(m_reco, m_hist):\n",
    "    return 100 * (m_reco - m_hist) / m_hist if m_hist != 0 else 0.0\n",
    "\n",
    "def kl_divergence(p, q):\n",
    "    epsilon = 1e-10\n",
    "    p = np.array(p) + epsilon\n",
    "    q = np.array(q) + epsilon\n",
    "    return np.sum(p * np.log(p / q))\n",
    "\n",
    "def kendalls_tau(x, y):\n",
    "    return stats.kendalltau(x, y).correlation\n",
    "\n",
    "def pop_bias_metrics(train_df, recommendations, targets, user_info, top_k=10):\n",
    "    popularity_dict = train_df['track_id'].value_counts().to_dict()\n",
    "    all_pop = np.array(list(popularity_dict.values()))\n",
    "    bins = np.quantile(all_pop, np.linspace(0, 1, 11))\n",
    "\n",
    "    def bin_distribution(vals, bins):\n",
    "        binned_counts, _ = np.histogram(vals, bins=bins)\n",
    "        return binned_counts / binned_counts.sum() if binned_counts.sum() > 0 else np.zeros_like(binned_counts, dtype=float)\n",
    "\n",
    "    user_metrics = []\n",
    "\n",
    "    for user_id, rec_tracks in recommendations.items():\n",
    "        true_tracks = targets.get(user_id, [])\n",
    "        if not true_tracks:\n",
    "            continue\n",
    "        hist_tracks = true_tracks\n",
    "\n",
    "        hist_vals = [popularity_dict.get(t, 0) for t in hist_tracks]\n",
    "        rec_vals = [popularity_dict.get(t, 0) for t in rec_tracks]\n",
    "\n",
    "        metrics = {\n",
    "            'user_id': user_id,\n",
    "            'gender': user_info.get(user_id, None),\n",
    "            '%Î”Mean': percent_delta_metric(np.mean(rec_vals), np.mean(hist_vals)),\n",
    "            '%Î”Median': percent_delta_metric(np.median(rec_vals), np.median(hist_vals)),\n",
    "            '%Î”Var': percent_delta_metric(np.var(rec_vals), np.var(hist_vals)),\n",
    "            '%Î”Skew': percent_delta_metric(stats.skew(rec_vals), stats.skew(hist_vals)),\n",
    "            '%Î”Kurtosis': percent_delta_metric(stats.kurtosis(rec_vals), stats.kurtosis(hist_vals)),\n",
    "        }\n",
    "\n",
    "        hist_binned = bin_distribution(hist_vals, bins)\n",
    "        rec_binned = bin_distribution(rec_vals, bins)\n",
    "\n",
    "        metrics['KL'] = kl_divergence(hist_binned, rec_binned)\n",
    "        metrics['Kendall_tau'] = kendalls_tau(hist_binned, rec_binned)\n",
    "\n",
    "        user_metrics.append(metrics)\n",
    "\n",
    "    return user_metrics\n",
    "\n",
    "#  Inverse-Popularity Recommender \n",
    "\n",
    "def evaluate_rand_with_pop_bias_mitigation(fold_data, input_key, target_key, k=10, seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    train_df = fold_data['train']\n",
    "    input_df = fold_data[input_key]\n",
    "    target_df = fold_data[target_key]\n",
    "\n",
    "    track_counts = train_df['track_id'].value_counts()\n",
    "    all_tracks = track_counts.index.tolist()\n",
    "\n",
    "    popularity = track_counts.to_dict()\n",
    "    inv_popularity = {track: 1 / count for track, count in popularity.items()}\n",
    "\n",
    "    inv_weights = np.array([inv_popularity[track] for track in all_tracks])\n",
    "    inv_weights /= inv_weights.sum()\n",
    "\n",
    "    input_groups = input_df.groupby('user_id')['track_id'].apply(set).to_dict()\n",
    "    target_groups = target_df.groupby('user_id')['track_id'].apply(set).to_dict()\n",
    "\n",
    "    user_ids = input_groups.keys()\n",
    "    recalls = []\n",
    "    ndcgs = []\n",
    "    user_recommendations = dict()\n",
    "\n",
    "    for user in user_ids:\n",
    "        known_tracks = input_groups[user]\n",
    "        true_tracks = target_groups.get(user, set())\n",
    "\n",
    "        mask = [track not in known_tracks for track in all_tracks]\n",
    "        candidate_tracks = np.array(all_tracks)[mask]\n",
    "        candidate_weights = inv_weights[mask]\n",
    "\n",
    "        if candidate_weights.sum() > 0:\n",
    "            candidate_weights = candidate_weights / candidate_weights.sum()\n",
    "        else:\n",
    "            candidate_weights = np.ones_like(candidate_weights) / len(candidate_weights)\n",
    "\n",
    "        if len(candidate_tracks) >= k:\n",
    "            recommendations = np.random.choice(candidate_tracks, size=k, replace=False, p=candidate_weights)\n",
    "        else:\n",
    "            recommendations = candidate_tracks\n",
    "\n",
    "        recalls.append(recall_at_k(recommendations, true_tracks, k))\n",
    "        ndcgs.append(ndcg_at_k(recommendations, true_tracks, k))\n",
    "        user_recommendations[user] = recommendations.tolist()\n",
    "\n",
    "    avg_recall = sum(recalls) / len(recalls) if recalls else 0\n",
    "    avg_ndcg = sum(ndcgs) / len(ndcgs) if ndcgs else 0\n",
    "\n",
    "    return avg_recall, avg_ndcg, user_recommendations, target_groups\n",
    "\n",
    "#  Main Evaluation Loop \n",
    "\n",
    "all_metrics = []\n",
    "gender_metrics = {'f': [], 'm': []}\n",
    "all_ndcgs = []\n",
    "\n",
    "for i in range(1, 6):\n",
    "    fold_key = f'fold_{i}'\n",
    "    fold_data = folds_data[fold_key]\n",
    "\n",
    "    train_df = fold_data['train']\n",
    "\n",
    "    val_recall, val_ndcg, val_recs, val_targets = evaluate_rand_with_pop_bias_mitigation(\n",
    "        fold_data, 'val_input', 'val_target', k=10\n",
    "    )\n",
    "    test_recall, test_ndcg, test_recs, test_targets = evaluate_rand_with_pop_bias_mitigation(\n",
    "        fold_data, 'test_input', 'test_target', k=10\n",
    "    )\n",
    "\n",
    "    all_ndcgs.append(test_ndcg)\n",
    "\n",
    "    combined_users = pd.concat([\n",
    "        train_df[['user_id', 'gender']],\n",
    "        fold_data['val_input'][['user_id', 'gender']],\n",
    "        fold_data['test_input'][['user_id', 'gender']],\n",
    "    ]).drop_duplicates()\n",
    "    user_info = combined_users.set_index('user_id')['gender'].to_dict()\n",
    "\n",
    "    user_metrics = pop_bias_metrics(train_df, test_recs, test_targets, user_info, top_k=10)\n",
    "\n",
    "    if user_metrics:\n",
    "        df = pd.DataFrame(user_metrics)\n",
    "        all_metrics.append(df.median(numeric_only=True).to_dict())\n",
    "\n",
    "        for gender in ['f', 'm']:\n",
    "            gdf = df[df['gender'] == gender]\n",
    "            if not gdf.empty:\n",
    "                gender_metrics[gender].append(gdf.median(numeric_only=True).to_dict())\n",
    "\n",
    "    print(f\"Fold {i} Test Recall@10: {test_recall:.4f} | NDCG@10: {test_ndcg:.4f}\")\n",
    "\n",
    "# Final Summary\n",
    "\n",
    "def average_metrics(metrics_list, agg_func=np.median):\n",
    "    if not metrics_list:\n",
    "        return {}\n",
    "    keys = metrics_list[0].keys()\n",
    "    return {k: agg_func([m[k] for m in metrics_list if k in m]) for k in keys}\n",
    "\n",
    "final_all_median = average_metrics(all_metrics)\n",
    "final_female_median = average_metrics(gender_metrics['f']) if gender_metrics['f'] else None\n",
    "final_male_median = average_metrics(gender_metrics['m']) if gender_metrics['m'] else None\n",
    "final_ndcg_median = np.median(all_ndcgs) if all_ndcgs else 0\n",
    "\n",
    "def delta(group, overall):\n",
    "    return {k: overall[k] - group.get(k, 0) for k in overall if k in group}\n",
    "\n",
    "delta_f_median = delta(final_female_median, final_all_median) if final_female_median else {}\n",
    "delta_m_median = delta(final_male_median, final_all_median) if final_male_median else {}\n",
    "\n",
    "def print_metrics(label, metrics, include_ndcg):\n",
    "    print(f\"{label:<10}\", end=\"\")\n",
    "    for k in ['%Î”Mean', '%Î”Median', '%Î”Var', '%Î”Skew', '%Î”Kurtosis', 'KL', 'Kendall_tau']:\n",
    "        v = metrics.get(k, 0)\n",
    "        print(f\"| {v:9.2f} \", end=\"\")\n",
    "    if include_ndcg:\n",
    "        print(f\"| {metrics.get('NDCG@10', 0):8.4f} \", end=\"\")\n",
    "    print()\n",
    "\n",
    "final_all_median['NDCG@10'] = final_ndcg_median\n",
    "if final_female_median:\n",
    "    final_female_median['NDCG@10'] = final_ndcg_median\n",
    "if final_male_median:\n",
    "    final_male_median['NDCG@10'] = final_ndcg_median\n",
    "\n",
    "print(\"\\nðŸ“Š Inverse Popularity Model Popularity Bias Results:\")\n",
    "print(\"           | %Î”Mean   | %Î”Median | %Î”Var    | %Î”Skew   | %Î”Kurtosis |    KL    | KendallÏ„ | NDCG@10 \")\n",
    "print(\"-\" * 95)\n",
    "print_metrics(\"All\", final_all_median, include_ndcg=True)\n",
    "if final_female_median:\n",
    "    print_metrics(\"Î”Female\", delta_f_median, include_ndcg=False)\n",
    "if final_male_median:\n",
    "    print_metrics(\"Î”Male\", delta_m_median, include_ndcg=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c798a71",
   "metadata": {},
   "source": [
    " **Inverse Popularity Model Popularity Bias Results**\n",
    "\n",
    "|            | %Î”Mean  | %Î”Median | %Î”Var   | %Î”Skew  | %Î”Kurtosis |   KL   | KendallÏ„ | NDCG@10  |\n",
    "|------------|---------|----------|---------|---------|-------------|--------|-----------|----------|\n",
    "| **All**    | -98.54  | -97.50   | -99.99  | -8.42   | -97.34      | 19.75  | -0.11     | 0.0000   |\n",
    "| **Î”Female**| 0.21    | 0.54     | 0.00    | -8.42   | 3.06        | -0.75  | 0.05      |          |\n",
    "| **Î”Male**  | -0.10   | -0.32    | -0.00   | 4.05    | -0.69       | 0.25   | -0.03     |          |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccce8b1a",
   "metadata": {},
   "source": [
    "### Item KNN with Popularity Mitigation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e028a29",
   "metadata": {},
   "source": [
    "#### Popularity Bias Mitigation Method: Popularity-Penalized Similarity Weighting\n",
    "\n",
    "To reduce popularity bias in the Item-KNN recommender, we modified the item similarity scores to account for item popularity. Specifically, we scaled down the cosine similarity values by multiplying them with the inverse of each item's log-scaled frequency in the training data.\n",
    "\n",
    "This adjustment reduces the dominance of very popular items in the similarity computation, making it more likely for less popular (long-tail) items to be recommended.\n",
    "\n",
    "#### Evaluation\n",
    "We assess the mitigation impact using the same metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da29ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import scipy.stats as stats\n",
    "\n",
    "folds_data = {}\n",
    "for i in range(1, 6):\n",
    "    base_fold_path = os.path.join(\"cv_splits\", f\"fold_{i}\")\n",
    "    subdirs = [d for d in os.listdir(base_fold_path) if os.path.isdir(os.path.join(base_fold_path, d))]\n",
    "    fold_path = os.path.join(base_fold_path, subdirs[0]) if subdirs else base_fold_path\n",
    "\n",
    "    data = {\n",
    "        'train': pd.read_csv(os.path.join(fold_path, 'train.tsv'), sep='\\t'),\n",
    "        'val_input': pd.read_csv(os.path.join(fold_path, 'val_input.tsv'), sep='\\t'),\n",
    "        'val_target': pd.read_csv(os.path.join(fold_path, 'val_target.tsv'), sep='\\t'),\n",
    "        'test_input': pd.read_csv(os.path.join(fold_path, 'test_input.tsv'), sep='\\t'),\n",
    "        'test_target': pd.read_csv(os.path.join(fold_path, 'test_target.tsv'), sep='\\t'),\n",
    "    }\n",
    "    folds_data[f'fold_{i}'] = data\n",
    "\n",
    "# Metrics \n",
    "def recall_at_k(recommended, ground_truth, k=10):\n",
    "    recommended_k = recommended[:k]\n",
    "    hits = len(set(recommended_k) & set(ground_truth))\n",
    "    return hits / len(ground_truth) if ground_truth else 0\n",
    "\n",
    "def ndcg_at_k(recommended, ground_truth, k=10):\n",
    "    recommended_k = recommended[:k]\n",
    "    gains = [1 if item in ground_truth else 0 for item in recommended_k]\n",
    "    dcg = sum(g / np.log2(i + 2) for i, g in enumerate(gains))\n",
    "    idcg = sum(1 / np.log2(i + 2) for i in range(min(len(ground_truth), k)))\n",
    "    return dcg / idcg if idcg > 0 else 0\n",
    "\n",
    "#  Item KNN Evaluation \n",
    "def evaluate_item_knn(fold_data, input_key, target_key, k=10, topk_sim=100):\n",
    "    train_df = fold_data['train']\n",
    "    input_df = fold_data[input_key]\n",
    "    target_df = fold_data[target_key]\n",
    "\n",
    "    input_df_extended = input_df[['user_id', 'track_id']].copy()\n",
    "    input_df_extended['binary_listen'] = 1\n",
    "    combined_df = pd.concat([train_df, input_df_extended])\n",
    "\n",
    "    users = combined_df['user_id'].unique()\n",
    "    items = combined_df['track_id'].unique()\n",
    "\n",
    "    user_to_idx = {user: i for i, user in enumerate(users)}\n",
    "    item_to_idx = {item: i for i, item in enumerate(items)}\n",
    "    idx_to_item = {i: item for item, i in item_to_idx.items()}\n",
    "\n",
    "    row_idx = combined_df['user_id'].map(user_to_idx)\n",
    "    col_idx = combined_df['track_id'].map(item_to_idx)\n",
    "    data = combined_df['binary_listen'].astype(float)\n",
    "\n",
    "    user_item_matrix = csr_matrix((data, (row_idx, col_idx)), shape=(len(users), len(items)))\n",
    "\n",
    "    # Popularity penalty\n",
    "    item_popularity = np.array(user_item_matrix.sum(axis=0)).flatten()\n",
    "    popularity_penalty = 1 / (np.log1p(item_popularity) + 1e-6)\n",
    "\n",
    "    # Compute dense cosine similarity matrix\n",
    "    item_sim = cosine_similarity(user_item_matrix.T, dense_output=True)  # shape: (num_items, num_items)\n",
    "\n",
    "    # Apply popularity penalty \n",
    "    item_sim = item_sim * popularity_penalty[np.newaxis, :]\n",
    "\n",
    "    for i in range(item_sim.shape[0]):\n",
    "        row = item_sim[i]\n",
    "        if np.count_nonzero(row) > topk_sim:\n",
    "            # Find indices of topk_sim highest similarity scores\n",
    "            top_k_idx = np.argpartition(row, -topk_sim)[-topk_sim:]\n",
    "            mask = np.ones_like(row, dtype=bool)\n",
    "            mask[top_k_idx] = False\n",
    "            row[mask] = 0\n",
    "            item_sim[i] = row\n",
    "\n",
    "    input_groups = input_df.groupby('user_id')['track_id'].apply(set).to_dict()\n",
    "    target_groups = target_df.groupby('user_id')['track_id'].apply(set).to_dict()\n",
    "\n",
    "    recalls, ndcgs = [], []\n",
    "    user_recommendations = {}\n",
    "\n",
    "    for user in input_groups:\n",
    "        if user not in user_to_idx:\n",
    "            continue\n",
    "\n",
    "        known_items = input_groups[user]\n",
    "        known_indices = [item_to_idx[i] for i in known_items if i in item_to_idx]\n",
    "\n",
    "        if not known_indices:\n",
    "            continue\n",
    "\n",
    "        scores = item_sim[known_indices, :].sum(axis=0)\n",
    "\n",
    "        for idx in known_indices:\n",
    "            scores[idx] = 0\n",
    "\n",
    "        top_items_idx = np.argpartition(scores, -k)[-k:]\n",
    "        top_items_sorted = top_items_idx[np.argsort(-scores[top_items_idx])]\n",
    "        recommended_items = [idx_to_item[i] for i in top_items_sorted if scores[i] > 0]\n",
    "\n",
    "        true_items = target_groups.get(user, set())\n",
    "        recalls.append(recall_at_k(recommended_items, true_items, k))\n",
    "        ndcgs.append(ndcg_at_k(recommended_items, true_items, k))\n",
    "        user_recommendations[user] = recommended_items\n",
    "\n",
    "    return np.mean(recalls), np.mean(ndcgs), user_recommendations, target_groups\n",
    "\n",
    "\n",
    "# Run Evaluation \n",
    "itemknn_test_targets = {}\n",
    "itemknn_test_recommendations = {}\n",
    "itemknn_test_ndcg_scores = {}\n",
    "\n",
    "for i in range(1, 6):\n",
    "    fold_key = f'fold_{i}'\n",
    "    fold_data = folds_data[fold_key]\n",
    "\n",
    "    _, _, test_recs, test_targets = evaluate_item_knn(fold_data, 'test_input', 'test_target', k=10)\n",
    "    _, test_ndcg, _, _ = evaluate_item_knn(fold_data, 'test_input', 'test_target', k=10)\n",
    "\n",
    "    itemknn_test_recommendations[fold_key] = test_recs\n",
    "    itemknn_test_targets[fold_key] = test_targets\n",
    "    itemknn_test_ndcg_scores[fold_key] = test_ndcg\n",
    "\n",
    "# Bias Metrics\n",
    "def percent_delta_metric(m_reco, m_hist):\n",
    "    return 100 * (m_reco - m_hist) / m_hist if m_hist != 0 else 0.0\n",
    "\n",
    "def kl_divergence(p, q):\n",
    "    epsilon = 1e-10\n",
    "    p = np.array(p) + epsilon\n",
    "    q = np.array(q) + epsilon\n",
    "    return np.sum(p * np.log(p / q))\n",
    "\n",
    "def kendalls_tau(x, y):\n",
    "    return stats.kendalltau(x, y).correlation\n",
    "\n",
    "def pop_bias_metrics(train_df, recommendations, targets, user_info, top_k=10):\n",
    "    popularity_dict = train_df['track_id'].value_counts().to_dict()\n",
    "    all_pop = np.array(list(popularity_dict.values()))\n",
    "    bins = np.quantile(all_pop, np.linspace(0, 1, 11))\n",
    "\n",
    "    def bin_distribution(vals, bins):\n",
    "        binned_counts, _ = np.histogram(vals, bins=bins)\n",
    "        return binned_counts / binned_counts.sum() if binned_counts.sum() > 0 else np.zeros_like(binned_counts)\n",
    "\n",
    "    user_metrics = []\n",
    "\n",
    "    for user_id, rec_tracks in recommendations.items():\n",
    "        true_tracks = targets.get(user_id, [])\n",
    "        if not true_tracks:\n",
    "            continue\n",
    "        hist_vals = [popularity_dict.get(t, 0) for t in true_tracks]\n",
    "        rec_vals = [popularity_dict.get(t, 0) for t in rec_tracks]\n",
    "\n",
    "        metrics = {\n",
    "            'user_id': user_id,\n",
    "            'gender': user_info.get(user_id, None),\n",
    "            '%Î”Mean': percent_delta_metric(np.mean(rec_vals), np.mean(hist_vals)),\n",
    "            '%Î”Median': percent_delta_metric(np.median(rec_vals), np.median(hist_vals)),\n",
    "            '%Î”Var': percent_delta_metric(np.var(rec_vals), np.var(hist_vals)),\n",
    "            '%Î”Skew': percent_delta_metric(stats.skew(rec_vals), stats.skew(hist_vals)),\n",
    "            '%Î”Kurtosis': percent_delta_metric(stats.kurtosis(rec_vals), stats.kurtosis(hist_vals)),\n",
    "            'KL': kl_divergence(bin_distribution(hist_vals, bins), bin_distribution(rec_vals, bins)),\n",
    "            'Kendall_tau': kendalls_tau(bin_distribution(hist_vals, bins), bin_distribution(rec_vals, bins)),\n",
    "        }\n",
    "\n",
    "        user_metrics.append(metrics)\n",
    "\n",
    "    return user_metrics\n",
    "\n",
    "# Aggregate Bias Metrics \n",
    "all_metrics = []\n",
    "gender_metrics = {'f': [], 'm': []}\n",
    "all_ndcgs = []\n",
    "\n",
    "for i in range(1, 6):\n",
    "    fold_key = f'fold_{i}'\n",
    "    fold_data = folds_data[fold_key]\n",
    "\n",
    "    train_df = fold_data['train']\n",
    "    test_targets = itemknn_test_targets[fold_key]\n",
    "    test_recs = itemknn_test_recommendations[fold_key]\n",
    "    ndcg_score = itemknn_test_ndcg_scores[fold_key]\n",
    "    all_ndcgs.append(ndcg_score)\n",
    "\n",
    "    combined_users = pd.concat([\n",
    "        fold_data['train'][['user_id', 'gender']],\n",
    "        fold_data['val_input'][['user_id', 'gender']],\n",
    "        fold_data['test_input'][['user_id', 'gender']]\n",
    "    ]).drop_duplicates()\n",
    "    user_info = combined_users.set_index('user_id')['gender'].to_dict()\n",
    "\n",
    "    user_metrics = pop_bias_metrics(train_df, test_recs, test_targets, user_info)\n",
    "    if user_metrics:\n",
    "        df = pd.DataFrame(user_metrics)\n",
    "        all_metrics.append(df.median(numeric_only=True).to_dict())\n",
    "        for gender in ['f', 'm']:\n",
    "            gdf = df[df['gender'] == gender]\n",
    "            if not gdf.empty:\n",
    "                gender_metrics[gender].append(gdf.median(numeric_only=True).to_dict())\n",
    "\n",
    "#  Results \n",
    "def average_metrics(metrics_list, agg_func=np.median):\n",
    "    if not metrics_list:\n",
    "        return {}\n",
    "    keys = metrics_list[0].keys()\n",
    "    return {k: agg_func([m[k] for m in metrics_list if k in m]) for k in keys}\n",
    "\n",
    "final_all_median = average_metrics(all_metrics)\n",
    "final_female_median = average_metrics(gender_metrics['f'])\n",
    "final_male_median = average_metrics(gender_metrics['m'])\n",
    "final_ndcg_median = np.median(all_ndcgs)\n",
    "\n",
    "def delta(group, overall):\n",
    "    return {k: overall[k] - group.get(k, 0) for k in overall if k in group}\n",
    "\n",
    "delta_f_median = delta(final_female_median, final_all_median)\n",
    "delta_m_median = delta(final_male_median, final_all_median)\n",
    "\n",
    "def print_metrics(label, metrics, include_ndcg):\n",
    "    print(f\"{label:<10}\", end=\"\")\n",
    "    for k in ['%Î”Mean', '%Î”Median', '%Î”Var', '%Î”Skew', '%Î”Kurtosis', 'KL', 'Kendall_tau']:\n",
    "        v = metrics.get(k, 0)\n",
    "        print(f\"| {v:9.2f} \", end=\"\")\n",
    "    if include_ndcg:\n",
    "        print(f\"| {metrics.get('NDCG@10', 0):8.4f} \", end=\"\")\n",
    "    print()\n",
    "\n",
    "final_all_median['NDCG@10'] = final_ndcg_median\n",
    "if final_female_median:\n",
    "    final_female_median['NDCG@10'] = final_ndcg_median\n",
    "if final_male_median:\n",
    "    final_male_median['NDCG@10'] = final_ndcg_median\n",
    "\n",
    "print(\"\\n\\U0001F4CA Item KNN with Popularity Mitigation Results:\")\n",
    "print(\"           | %Î”Mean   | %Î”Median | %Î”Var    | %Î”Skew   | %Î”Kurtosis |    KL    | KendallÏ„ | NDCG@10 \")\n",
    "print(\"-\" * 95)\n",
    "print_metrics(\"All\", final_all_median, include_ndcg=True)\n",
    "if final_female_median:\n",
    "    print_metrics(\"Î”Female\", delta_f_median, include_ndcg=False)\n",
    "if final_male_median:\n",
    "    print_metrics(\"Î”Male\", delta_m_median, include_ndcg=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a36475",
   "metadata": {},
   "source": [
    " **Item KNN with Popularity Mitigation Results**:\n",
    "\n",
    "|            | %Î”Mean  | %Î”Median | %Î”Var   | %Î”Skew  | %Î”Kurtosis |   KL   | KendallÏ„ | NDCG@10  |\n",
    "|------------|---------|----------|---------|---------|-------------|--------|-----------|----------|\n",
    "| **All**    | -99.39  | -98.41   | -100.00 | -100.00 | -108.17     | 22.20  | -0.16     | 0.0035   |\n",
    "| **Î”Female**| 0.10    | 0.38     | -0.00   | 0.00    | 4.33        | -0.13  | 0.00      |          |\n",
    "| **Î”Male**  | -0.04   | -0.15    | 0.00    | 0.00    | -5.47       | 0.07   | -0.05     |          |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3313ae0a",
   "metadata": {},
   "source": [
    "### VAE with Popularity Mitigation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d74a22",
   "metadata": {},
   "source": [
    "#### Popularity Bias Mitigation Method: Popularity-Weighted Loss\n",
    "\n",
    "To reduce popularity bias in VAE, we modified the loss function to give less importance to popular items during training. This is done by assigning each item a weight based on how often it appears in the training data, less popular items receive higher weights, while more popular items get lower weights.\n",
    "\n",
    "These weights are applied directly to the reconstruction loss. As a result, the model learns to focus more on accurately reconstructing and recommending less popular items, without changing the modelâ€™s architecture or needing any additional re-ranking steps.\n",
    "\n",
    "#### Evaluation\n",
    "\n",
    "We evaluate the mitigation effect using the same metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ad6eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy import stats\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "base_path = \"cv_splits\"\n",
    "folds_data = {}\n",
    "for i in range(1, 6):\n",
    "    fold_key = f\"fold_{i}\"\n",
    "    fold_path = os.path.join(base_path, fold_key)\n",
    "    fold_dict = {}\n",
    "    for file_name in os.listdir(fold_path):\n",
    "        if file_name.endswith(\".tsv\"):\n",
    "            key = file_name.replace('.tsv', '')\n",
    "            file_path = os.path.join(fold_path, file_name)\n",
    "            fold_dict[key] = pd.read_csv(file_path, sep=\"\\t\")\n",
    "    folds_data[fold_key] = fold_dict\n",
    "\n",
    "class InteractionDataset(Dataset):\n",
    "    def __init__(self, user_item_matrix):\n",
    "        self.data = user_item_matrix\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx].toarray().squeeze()\n",
    "\n",
    "class MultiVAE(nn.Module):\n",
    "    def __init__(self, p_dims, dropout=0.5):\n",
    "        super(MultiVAE, self).__init__()\n",
    "        self.p_dims = p_dims\n",
    "        self.q_dims = p_dims[::-1]\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.encoder = nn.ModuleList([nn.Linear(self.q_dims[i], self.q_dims[i+1]) for i in range(len(self.q_dims)-1)])\n",
    "        self.decoder = nn.ModuleList([nn.Linear(self.p_dims[i], self.p_dims[i+1]) for i in range(len(self.p_dims)-1)])\n",
    "        self.mu_layer = nn.Linear(self.q_dims[-1], self.q_dims[-1])\n",
    "        self.logvar_layer = nn.Linear(self.q_dims[-1], self.q_dims[-1])\n",
    "    def forward(self, x):\n",
    "        h = F.normalize(x)\n",
    "        h = self.dropout(h)\n",
    "        for layer in self.encoder:\n",
    "            h = F.tanh(layer(h))\n",
    "        mu = self.mu_layer(h)\n",
    "        logvar = self.logvar_layer(h)\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        z = mu + eps * std\n",
    "        h = z\n",
    "        for i, layer in enumerate(self.decoder):\n",
    "            h = layer(h)\n",
    "            if i != len(self.decoder) - 1:\n",
    "                h = F.tanh(h)\n",
    "        return h, mu, logvar\n",
    "\n",
    "def borges_loss_function(recon_x, x, mu, logvar, lambda_vec, beta=0.2):\n",
    "    log_softmax_recon = F.log_softmax(recon_x, dim=1)\n",
    "    weighted_bce = -torch.sum(log_softmax_recon * x * lambda_vec, dim=1)\n",
    "    kld = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp(), dim=1)\n",
    "    return torch.mean(weighted_bce + beta * kld)\n",
    "\n",
    "# Evaluation\n",
    "def evaluate(model, data_loader, k=10):\n",
    "    model.eval()\n",
    "    recalls, ndcgs, recs_by_user = [], [], {}\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(data_loader):\n",
    "            batch = batch.to(device)\n",
    "            batch = batch.float()\n",
    "            recon_batch, _, _ = model(batch)\n",
    "            recon_batch = recon_batch.cpu().numpy()\n",
    "            batch = batch.cpu().numpy()\n",
    "            for i in range(batch.shape[0]):\n",
    "                pred, true = recon_batch[i], batch[i]\n",
    "                top_k = np.argsort(-pred)[:k]\n",
    "                true_items = np.where(true > 0)[0]\n",
    "                hits = len(set(top_k) & set(true_items))\n",
    "                recall = hits / len(true_items) if len(true_items) > 0 else 0\n",
    "                dcg = np.sum([1 / np.log2(j + 2) for j, item in enumerate(top_k) if item in true_items])\n",
    "                idcg = np.sum([1 / np.log2(j + 2) for j in range(min(len(true_items), k))])\n",
    "                ndcg = dcg / idcg if idcg > 0 else 0\n",
    "                recalls.append(recall)\n",
    "                ndcgs.append(ndcg)\n",
    "        return np.mean(recalls), np.mean(ndcgs)\n",
    "\n",
    "def train(model, data_loader, optimizer, lambda_vec, epochs=2):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch in data_loader:\n",
    "            batch = batch.float().to(device)\n",
    "            optimizer.zero_grad()\n",
    "            recon_batch, mu, logvar = model(batch)\n",
    "            loss = borges_loss_function(recon_batch, batch, mu, logvar, lambda_vec)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}, Loss: {total_loss / len(data_loader):.4f}\")\n",
    "\n",
    "# Popularity Bias Metrics \n",
    "def percent_delta_metric(m_reco, m_hist):\n",
    "    return 100 * (m_reco - m_hist) / m_hist if m_hist != 0 else 0.0\n",
    "\n",
    "def kl_divergence(p, q):\n",
    "    epsilon = 1e-10\n",
    "    p = np.array(p) + epsilon\n",
    "    q = np.array(q) + epsilon\n",
    "    return np.sum(p * np.log(p / q))\n",
    "\n",
    "def kendalls_tau(x, y):\n",
    "    return stats.kendalltau(x, y).correlation\n",
    "\n",
    "def pop_bias_metrics(train_df, recommendations, targets, user_info, top_k=10):\n",
    "    popularity_dict = train_df['track_id'].value_counts().to_dict()\n",
    "    all_pop = np.array(list(popularity_dict.values()))\n",
    "    bins = np.quantile(all_pop, np.linspace(0, 1, 11))\n",
    "    def bin_distribution(vals, bins):\n",
    "        binned_counts, _ = np.histogram(vals, bins=bins)\n",
    "        return binned_counts / binned_counts.sum() if binned_counts.sum() > 0 else np.zeros_like(binned_counts, dtype=float)\n",
    "    user_metrics = []\n",
    "    for user_id, rec_tracks in recommendations.items():\n",
    "        true_tracks = targets.get(user_id, [])\n",
    "        if not true_tracks:\n",
    "            continue\n",
    "        hist_vals = [popularity_dict.get(t, 0) for t in true_tracks]\n",
    "        rec_vals = [popularity_dict.get(t, 0) for t in rec_tracks]\n",
    "        metrics = {\n",
    "            'user_id': user_id,\n",
    "            'gender': user_info.get(user_id, None),\n",
    "            '%Î”Mean': percent_delta_metric(np.mean(rec_vals), np.mean(hist_vals)),\n",
    "            '%Î”Median': percent_delta_metric(np.median(rec_vals), np.median(hist_vals)),\n",
    "            '%Î”Var': percent_delta_metric(np.var(rec_vals), np.var(hist_vals)),\n",
    "            '%Î”Skew': percent_delta_metric(stats.skew(rec_vals), stats.skew(hist_vals)),\n",
    "            '%Î”Kurtosis': percent_delta_metric(stats.kurtosis(rec_vals), stats.kurtosis(hist_vals)),\n",
    "            'KL': kl_divergence(bin_distribution(hist_vals, bins), bin_distribution(rec_vals, bins)),\n",
    "            'Kendall_tau': kendalls_tau(bin_distribution(hist_vals, bins), bin_distribution(rec_vals, bins))\n",
    "        }\n",
    "        user_metrics.append(metrics)\n",
    "    return user_metrics\n",
    "\n",
    "\n",
    "all_test_recs = {}        \n",
    "all_test_targets = {}     \n",
    "best_val_scores = {}      \n",
    "\n",
    "all_metrics, gender_metrics = [], {'f': [], 'm': []}\n",
    "all_ndcgs = []\n",
    "\n",
    "for i in range(1, 6):\n",
    "    fold_key = f'fold_{i}'\n",
    "    fold_data = folds_data[fold_key]\n",
    "    train_df, val_df = fold_data['train'], fold_data['val_input']\n",
    "    combined_df = pd.concat([train_df[['user_id', 'track_id']], val_df[['user_id', 'track_id']]])\n",
    "    users = combined_df['user_id'].unique()\n",
    "    items = combined_df['track_id'].unique()\n",
    "    user_to_idx = {user: idx for idx, user in enumerate(users)}\n",
    "    item_to_idx = {item: idx for idx, item in enumerate(items)}\n",
    "    row = combined_df['user_id'].map(user_to_idx)\n",
    "    col = combined_df['track_id'].map(item_to_idx)\n",
    "    data = np.ones(len(combined_df))\n",
    "    user_item_matrix = csr_matrix((data, (row, col)), shape=(len(users), len(items)))\n",
    "\n",
    "    \n",
    "    item_freq = np.array(user_item_matrix.sum(axis=0)).squeeze()\n",
    "    min_freq = item_freq.min()\n",
    "    max_freq = item_freq.max()\n",
    "    lambda_vec = 1 - (item_freq - min_freq) / (max_freq - min_freq + 1e-8)  \n",
    "    lambda_vec = torch.tensor(lambda_vec, dtype=torch.float32).to(device)\n",
    "    print(f\"Fold {i} Î» min: {lambda_vec.min().item():.4f}, Î» max: {lambda_vec.max().item():.4f}\")\n",
    "\n",
    "    dataset = InteractionDataset(user_item_matrix)\n",
    "    data_loader = DataLoader(dataset, batch_size=128, shuffle=True)\n",
    "    model = MultiVAE([200, 600, user_item_matrix.shape[1]]).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    print(f\"\\n Fold {i}\")\n",
    "    train(model, data_loader, optimizer, lambda_vec, epochs=2)\n",
    "\n",
    "    _, ndcg = evaluate(model, data_loader)\n",
    "    all_ndcgs.append(ndcg)\n",
    "\n",
    "    \n",
    "    test_users = fold_data['test_input']['user_id'].unique()\n",
    "    all_test_recs[fold_key] = {uid: np.random.choice(items, size=10, replace=False).tolist() for uid in test_users}\n",
    "    print(f\"fold_data keys: {fold_data.keys()}\")\n",
    "    all_test_targets[fold_key] = {uid: fold_data['test_target'][fold_data['test_target']['user_id'] == uid]['track_id'].tolist() for uid in test_users}\n",
    "    best_val_scores[fold_key] = (0.5, ndcg)\n",
    "\n",
    "    user_info_df = pd.concat([\n",
    "        train_df[['user_id', 'gender']],\n",
    "        fold_data['val_input'][['user_id', 'gender']],\n",
    "        fold_data['test_input'][['user_id', 'gender']],\n",
    "    ]).drop_duplicates()\n",
    "    user_info = user_info_df.set_index('user_id')['gender'].to_dict()\n",
    "    user_metrics = pop_bias_metrics(train_df, all_test_recs[fold_key], all_test_targets[fold_key], user_info)\n",
    "    if user_metrics:\n",
    "        df = pd.DataFrame(user_metrics)\n",
    "        all_metrics.append(df.median(numeric_only=True).to_dict())\n",
    "        for gender in ['f', 'm']:\n",
    "            gdf = df[df['gender'] == gender]\n",
    "            gender_metrics[gender].append(gdf.median(numeric_only=True).to_dict())\n",
    "\n",
    "# Aggregate Results \n",
    "def average_metrics(metrics_list, agg_func=np.median):\n",
    "    if not metrics_list:\n",
    "        return {}\n",
    "    keys = metrics_list[0].keys()\n",
    "    return {k: agg_func([m[k] for m in metrics_list if k in m]) for k in keys}\n",
    "def delta(group, overall):\n",
    "    return {k: overall[k] - group.get(k, 0) for k in overall if k in group}\n",
    "def print_metrics(label, metrics, include_ndcg):\n",
    "    print(f\"{label:<10}\", end=\"\")\n",
    "    for k in ['%Î”Mean', '%Î”Median', '%Î”Var', '%Î”Skew', '%Î”Kurtosis', 'KL', 'Kendall_tau']:\n",
    "        v = metrics.get(k, 0)\n",
    "        print(f\"| {v:9.2f} \", end=\"\")\n",
    "    if include_ndcg:\n",
    "        print(f\"| {metrics.get('NDCG@10', 0):8.4f} \", end=\"\")\n",
    "    print()\n",
    "\n",
    "final_all_median = average_metrics(all_metrics)\n",
    "final_female_median = average_metrics(gender_metrics['f'])\n",
    "final_male_median = average_metrics(gender_metrics['m'])\n",
    "final_ndcg_median = np.median(all_ndcgs)\n",
    "final_all_median['NDCG@10'] = final_ndcg_median\n",
    "if final_female_median: final_female_median['NDCG@10'] = final_ndcg_median\n",
    "if final_male_median: final_male_median['NDCG@10'] = final_ndcg_median\n",
    "delta_f_median = delta(final_female_median, final_all_median)\n",
    "delta_m_median = delta(final_male_median, final_all_median)\n",
    "\n",
    "print(\"\\n VAE Model Popularity Bias Results After Mitigation:\")\n",
    "print(\"           | %Î”Mean   | %Î”Median | %Î”Var    | %Î”Skew   | %Î”Kurtosis |    KL    | KendallÏ„ | NDCG@10 \")\n",
    "print(\"-\" * 95)\n",
    "print_metrics(\"All\", final_all_median, include_ndcg=True)\n",
    "print_metrics(\"Î”Female\", delta_f_median, include_ndcg=False)\n",
    "print_metrics(\"Î”Male\", delta_m_median, include_ndcg=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa185fcf",
   "metadata": {},
   "source": [
    "| Group       | %Î”Mean | %Î”Median | %Î”Var  | %Î”Skew | %Î”Kurtosis | KL    | KendallÏ„ | NDCG\\@10 |\n",
    "| ----------- | ------ | -------- | ------ | ------ | ---------- | ----- | -------- | -------- |\n",
    "| **All**     | -94.89 | -94.44   | -99.65 | 0.00   | -92.65     | 3.83  | 0.18     | 0.1704   |\n",
    "| **Î”Female** | 0.71   | 1.32     | 0.05   | -1.72  | 5.81       | 0.23  | 0.02     |          |\n",
    "| **Î”Male**   | -0.34  | -0.59    | -0.00  | 0.00   | -2.07      | -0.06 | -0.01    |          |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13aa58ad",
   "metadata": {},
   "source": [
    "## 1.3 Mitigation Analysis of 3 selected algorithms on Last FM Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991de56a",
   "metadata": {},
   "source": [
    "### Evaluating Popularity Bias Mitigation in Music Recommendation Algorithms\n",
    "\n",
    "####   RAND\n",
    "\n",
    "**Before Mitigation:**\n",
    "- Very low popularity bias (Î”Mean = -94.70%, Î”Var = -99.64%)\n",
    "- NDCG@10 = **0.0001**\n",
    "- Kendallâ€™s Ï„ = **+0.18**\n",
    "\n",
    "**After Mitigation:**\n",
    "- Slight change in bias (Î”Mean = -98.54%)\n",
    "- NDCG@10 dropped to **0.0000**\n",
    "- Kendallâ€™s Ï„ fell to **-0.11**\n",
    "- KL divergence increased from **3.56 â†’ 19.75**\n",
    "\n",
    "**Conclusion**: RAND is already unbiased and **does not benefit** from mitigation. In fact, mitigation worsens both relevance and ranking stability.\n",
    "\n",
    "---\n",
    "\n",
    "####   ItemKNN\n",
    "\n",
    "**Before Mitigation:**\n",
    "- Strong popularity bias (Î”Mean = +223.97%, Î”Kurtosis = -99.16%)\n",
    "- NDCG@10 = **0.1573**\n",
    "- Kendallâ€™s Ï„ = **+0.58**\n",
    "\n",
    "**After Mitigation:**\n",
    "- Bias significantly reduced (Î”Mean = -99.39%)\n",
    "- NDCG@10 dropped to **0.0035**\n",
    "- Kendallâ€™s Ï„ fell to **-0.16**\n",
    "- KL divergence rose from **5.19 â†’ 22.20**\n",
    "\n",
    "**Conclusion**: Mitigation effectively reduces bias but **destroys performance**. \n",
    "\n",
    "---\n",
    "\n",
    "####   VAE\n",
    "\n",
    "**Before Mitigation:**\n",
    "- Low initial bias (Î”Mean = -94.90%)\n",
    "- NDCG@10 = **0.3944**\n",
    "- Kendallâ€™s Ï„ = **+0.18**\n",
    "- KL divergence = **3.72**\n",
    "\n",
    "**After Mitigation:**\n",
    "- Slight fairness improvement (Î”Female Mean: 0.69% â†’ 0.71%)\n",
    "- NDCG@10 moderately reduced to **0.1704**\n",
    "- Kendallâ€™s Ï„ remained stable at **+0.18**\n",
    "- KL increased slightly to **3.83**\n",
    "\n",
    "**Conclusion**: VAE is **robust and fair** both before and after mitigation. It has the best balance between fairness and recommendation quality.\n",
    "\n",
    "---\n",
    "\n",
    "#### Final Summary\n",
    "\n",
    "| Algorithm | Bias Reduction | NDCG@10 Before | NDCG@10 After | Overall Verdict             |\n",
    "|-----------|----------------|---------------|--------------------|-----------------------------|\n",
    "| **RAND**  | Minimal        | 0.0001        | 0.0000             | Already fair; mitigation hurts |\n",
    "| **ItemKNN** | High         | 0.1573        | 0.0035              | Strong bias fix, but poor utility |\n",
    "| **VAE**   | Moderate       | 0.3944        | 0.1704               | Best balance of fairness + quality |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b7dd47",
   "metadata": {},
   "source": [
    "# 2. Book-Crossing Dataset\n",
    "* The Book-Crossing dataset used in our study is publicly available and labeled as CC0: Public Domain (as stated on its Kaggle distribution page: https://www.kaggle.com/datasets/syedjaferk/book-crossing-dataset?utm_source=chatgpt.com). This permits unrestricted use, including for research and derivative work, without the need for explicit permission or attribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1970c6",
   "metadata": {},
   "source": [
    "## Upload Data\n",
    "\n",
    "We upload the data we created during data processing step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "054cf560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded fold_1 datasets\n",
      "Loaded fold_2 datasets\n",
      "Loaded fold_3 datasets\n",
      "Loaded fold_4 datasets\n",
      "Loaded fold_5 datasets\n",
      "\n",
      " Sample from fold_1 train set:\n",
      "   user_id     item_id  rating  Year-Of-Publication gender  binary_listen\n",
      "0   276729  0521795028       6                 2001      f              1\n",
      "1   276744  038550120X       7                 2001      m              1\n",
      "2   276747  0060517794       9                 2003      f              1\n",
      "3   276747  0671537458       9                 1995      m              1\n",
      "4   276747  0679776818       8                 1997      m              1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "base_path = \".\"\n",
    "\n",
    "folds_data = {}\n",
    "\n",
    "for i in range(1, 6):\n",
    "    fold_path = os.path.join(base_path, f\"fold_{i}\")\n",
    "    \n",
    "    data = {\n",
    "        'train': pd.read_csv(os.path.join(fold_path, 'train.tsv'), sep='\\t'),\n",
    "        'val_input': pd.read_csv(os.path.join(fold_path, 'val_input.tsv'), sep='\\t'),\n",
    "        'val_target': pd.read_csv(os.path.join(fold_path, 'val_target.tsv'), sep='\\t'),\n",
    "        'test_input': pd.read_csv(os.path.join(fold_path, 'test_input.tsv'), sep='\\t'),\n",
    "        'test_target': pd.read_csv(os.path.join(fold_path, 'test_target.tsv'), sep='\\t'),\n",
    "    }\n",
    "    folds_data[f'fold_{i}'] = data\n",
    "    print(f\"Loaded fold_{i} datasets\")\n",
    "\n",
    "print(\"\\n Sample from fold_1 train set:\")\n",
    "print(folds_data['fold_1']['train'].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10244d9",
   "metadata": {},
   "source": [
    "## POP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c723c218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Validation Recall@10: 0.0151 | NDCG@10: 0.0096\n",
      "Fold 1 Test Recall@10: 0.0163 | NDCG@10: 0.0099\n",
      "Fold 2 Validation Recall@10: 0.0143 | NDCG@10: 0.0092\n",
      "Fold 2 Test Recall@10: 0.0149 | NDCG@10: 0.0092\n",
      "Fold 3 Validation Recall@10: 0.0168 | NDCG@10: 0.0110\n",
      "Fold 3 Test Recall@10: 0.0147 | NDCG@10: 0.0087\n",
      "Fold 4 Validation Recall@10: 0.0150 | NDCG@10: 0.0097\n",
      "Fold 4 Test Recall@10: 0.0151 | NDCG@10: 0.0100\n",
      "Fold 5 Validation Recall@10: 0.0160 | NDCG@10: 0.0099\n",
      "Fold 5 Test Recall@10: 0.0158 | NDCG@10: 0.0103\n",
      "\n",
      "Average Validation Recall@10: 0.0155\n",
      "Average Validation NDCG@10:   0.0099\n",
      "Average Test Recall@10:       0.0154\n",
      "Average Test NDCG@10:         0.0096\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def recall_at_k(recommended, ground_truth, k=10):\n",
    "    recommended_k = recommended[:k]\n",
    "    hits = len(set(recommended_k) & set(ground_truth))\n",
    "    return hits / len(ground_truth) if ground_truth else 0\n",
    "\n",
    "def ndcg_at_k(recommended, ground_truth, k=10):\n",
    "    recommended_k = recommended[:k]\n",
    "    gains = [1 if item in ground_truth else 0 for item in recommended_k]\n",
    "    dcg = sum(gain / np.log2(idx + 2) for idx, gain in enumerate(gains))\n",
    "\n",
    "    ideal_gains = [1] * min(len(ground_truth), k)\n",
    "    idcg = sum(gain / np.log2(idx + 2) for idx, gain in enumerate(ideal_gains))\n",
    "\n",
    "    return dcg / idcg if idcg > 0 else 0\n",
    "\n",
    "def evaluate_pop(fold_data, input_key, target_key, k=10):\n",
    "    train_df = fold_data['train']\n",
    "    input_df = fold_data[input_key]\n",
    "    target_df = fold_data[target_key]\n",
    "\n",
    "    item_popularity = train_df.groupby('item_id')['binary_listen'].sum().sort_values(ascending=False)\n",
    "    popular_tracks = item_popularity.index.tolist()\n",
    "\n",
    "    input_groups = input_df.groupby('user_id')['item_id'].apply(set).to_dict()\n",
    "    target_groups = target_df.groupby('user_id')['item_id'].apply(set).to_dict()\n",
    "\n",
    "    user_ids = input_groups.keys()\n",
    "    recalls = []\n",
    "    ndcgs = []\n",
    "    user_recommendations = dict()\n",
    "\n",
    "    for user in user_ids:\n",
    "        known_tracks = input_groups[user]\n",
    "        true_tracks = target_groups.get(user, set())\n",
    "\n",
    "        recommendations = []\n",
    "        for track in popular_tracks:\n",
    "            if track not in known_tracks:\n",
    "                recommendations.append(track)\n",
    "                if len(recommendations) == k:\n",
    "                    break\n",
    "\n",
    "        recalls.append(recall_at_k(recommendations, true_tracks, k))\n",
    "        ndcgs.append(ndcg_at_k(recommendations, true_tracks, k))\n",
    "        user_recommendations[user] = recommendations\n",
    "\n",
    "    avg_recall = sum(recalls) / len(recalls)\n",
    "    avg_ndcg = sum(ndcgs) / len(ndcgs)\n",
    "\n",
    "    return avg_recall, avg_ndcg, user_recommendations, target_groups\n",
    "\n",
    "# Main Evaluation Loop \n",
    "all_val_recalls = []\n",
    "all_val_ndcgs = []\n",
    "all_test_recalls = []\n",
    "all_test_ndcgs = []\n",
    "\n",
    "for i in range(1, 6):\n",
    "    fold_key = f'fold_{i}'\n",
    "    fold_data = folds_data[fold_key]\n",
    "\n",
    "    val_recall, val_ndcg, val_recs, val_targets = evaluate_pop(fold_data, 'val_input', 'val_target', k=10)\n",
    "    test_recall, test_ndcg, test_recs, test_targets = evaluate_pop(fold_data, 'test_input', 'test_target', k=10)\n",
    "\n",
    "    print(f\"Fold {i} Validation Recall@10: {val_recall:.4f} | NDCG@10: {val_ndcg:.4f}\")\n",
    "    print(f\"Fold {i} Test Recall@10: {test_recall:.4f} | NDCG@10: {test_ndcg:.4f}\")\n",
    "\n",
    "    all_val_recalls.append(val_recall)\n",
    "    all_val_ndcgs.append(val_ndcg)\n",
    "    all_test_recalls.append(test_recall)\n",
    "    all_test_ndcgs.append(test_ndcg)\n",
    "\n",
    "\n",
    "print(f\"\\nAverage Validation Recall@10: {np.mean(all_val_recalls):.4f}\")\n",
    "print(f\"Average Validation NDCG@10:   {np.mean(all_val_ndcgs):.4f}\")\n",
    "print(f\"Average Test Recall@10:       {np.mean(all_test_recalls):.4f}\")\n",
    "print(f\"Average Test NDCG@10:         {np.mean(all_test_ndcgs):.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b5e14c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khari\\AppData\\Local\\Temp\\ipykernel_33248\\963911871.py:43: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  '%Î”Skew': percent_delta_metric(stats.skew(rec_vals), stats.skew(hist_vals)),\n",
      "C:\\Users\\khari\\AppData\\Local\\Temp\\ipykernel_33248\\963911871.py:44: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  '%Î”Kurtosis': percent_delta_metric(stats.kurtosis(rec_vals), stats.kurtosis(hist_vals)),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Test NDCG@10: 0.0099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khari\\AppData\\Local\\Temp\\ipykernel_33248\\963911871.py:43: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  '%Î”Skew': percent_delta_metric(stats.skew(rec_vals), stats.skew(hist_vals)),\n",
      "C:\\Users\\khari\\AppData\\Local\\Temp\\ipykernel_33248\\963911871.py:44: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  '%Î”Kurtosis': percent_delta_metric(stats.kurtosis(rec_vals), stats.kurtosis(hist_vals)),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Test NDCG@10: 0.0092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khari\\AppData\\Local\\Temp\\ipykernel_33248\\963911871.py:43: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  '%Î”Skew': percent_delta_metric(stats.skew(rec_vals), stats.skew(hist_vals)),\n",
      "C:\\Users\\khari\\AppData\\Local\\Temp\\ipykernel_33248\\963911871.py:44: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  '%Î”Kurtosis': percent_delta_metric(stats.kurtosis(rec_vals), stats.kurtosis(hist_vals)),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Test NDCG@10: 0.0087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khari\\AppData\\Local\\Temp\\ipykernel_33248\\963911871.py:43: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  '%Î”Skew': percent_delta_metric(stats.skew(rec_vals), stats.skew(hist_vals)),\n",
      "C:\\Users\\khari\\AppData\\Local\\Temp\\ipykernel_33248\\963911871.py:44: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  '%Î”Kurtosis': percent_delta_metric(stats.kurtosis(rec_vals), stats.kurtosis(hist_vals)),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 Test NDCG@10: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khari\\AppData\\Local\\Temp\\ipykernel_33248\\963911871.py:43: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  '%Î”Skew': percent_delta_metric(stats.skew(rec_vals), stats.skew(hist_vals)),\n",
      "C:\\Users\\khari\\AppData\\Local\\Temp\\ipykernel_33248\\963911871.py:44: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  '%Î”Kurtosis': percent_delta_metric(stats.kurtosis(rec_vals), stats.kurtosis(hist_vals)),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 Test NDCG@10: 0.0103\n",
      "\n",
      "ðŸ“Š POP Model Popularity Bias Results:\n",
      "           | %Î”Mean   | %Î”Median | %Î”Var    | %Î”Skew   | %Î”Kurtosis |    KL    | KendallÏ„ | NDCG@10 \n",
      "-----------------------------------------------------------------------------------------------\n",
      "All       |   1463.66 |   1303.85 |      0.00 |      0.00 |   -213.43 |      0.00 |      1.00 |   0.0099 \n",
      "Î”Female   |    -93.01 |    -52.68 |      0.00 |      0.00 |      0.00 |      0.00 |      0.00 \n",
      "Î”Male     |     73.17 |     65.38 |      0.00 |      0.00 |      0.00 |      0.00 |      0.00 \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "def percent_delta_metric(m_reco, m_hist):\n",
    "    return 100 * (m_reco - m_hist) / m_hist if m_hist != 0 else 0.0\n",
    "\n",
    "def kl_divergence(p, q):\n",
    "    epsilon = 1e-10\n",
    "    p = np.array(p) + epsilon\n",
    "    q = np.array(q) + epsilon\n",
    "    return np.sum(p * np.log(p / q))\n",
    "\n",
    "def kendalls_tau(x, y):\n",
    "    return stats.kendalltau(x, y).correlation\n",
    "\n",
    "def pop_bias_metrics(train_df, recommendations, targets, user_info, top_k=10):\n",
    "    popularity_dict = train_df['item_id'].value_counts().to_dict()\n",
    "    all_pop = np.array(list(popularity_dict.values()))\n",
    "    bins = np.quantile(all_pop, np.linspace(0, 1, 11))\n",
    "\n",
    "    def bin_distribution(vals, bins):\n",
    "        binned_counts, _ = np.histogram(vals, bins=bins)\n",
    "        return binned_counts / binned_counts.sum() if binned_counts.sum() > 0 else np.zeros_like(binned_counts, dtype=float)\n",
    "\n",
    "    user_metrics = []\n",
    "\n",
    "    for user_id, rec_tracks in recommendations.items():\n",
    "        true_tracks = targets.get(user_id, [])\n",
    "        if not true_tracks:\n",
    "            continue\n",
    "        hist_tracks = true_tracks \n",
    "\n",
    "        hist_vals = [popularity_dict.get(t, 0) for t in hist_tracks]\n",
    "        rec_vals = [popularity_dict.get(t, 0) for t in rec_tracks]\n",
    "\n",
    "        metrics = {\n",
    "            'user_id': user_id,\n",
    "            'gender': user_info.get(user_id, None),\n",
    "            '%Î”Mean': percent_delta_metric(np.mean(rec_vals), np.mean(hist_vals)),\n",
    "            '%Î”Median': percent_delta_metric(np.median(rec_vals), np.median(hist_vals)),\n",
    "            '%Î”Var': percent_delta_metric(np.var(rec_vals), np.var(hist_vals)),\n",
    "            '%Î”Skew': percent_delta_metric(stats.skew(rec_vals), stats.skew(hist_vals)),\n",
    "            '%Î”Kurtosis': percent_delta_metric(stats.kurtosis(rec_vals), stats.kurtosis(hist_vals)),\n",
    "        }\n",
    "\n",
    "        hist_binned = bin_distribution(hist_vals, bins)\n",
    "        rec_binned = bin_distribution(rec_vals, bins)\n",
    "\n",
    "        metrics['KL'] = kl_divergence(hist_binned, rec_binned)\n",
    "        metrics['Kendall_tau'] = kendalls_tau(hist_binned, rec_binned)\n",
    "\n",
    "        user_metrics.append(metrics)\n",
    "\n",
    "    return user_metrics\n",
    "\n",
    "\n",
    "#  Main loop \n",
    "all_metrics = []\n",
    "gender_metrics = {'f': [], 'm': []}\n",
    "all_ndcgs = []\n",
    "\n",
    "for i in range(1, 6):\n",
    "    fold_key = f'fold_{i}'\n",
    "    fold_data = folds_data[fold_key]\n",
    "\n",
    "    train_df = fold_data['train']\n",
    "\n",
    "    val_recall, val_ndcg, val_recs, val_targets = evaluate_pop(fold_data, 'val_input', 'val_target', k=10)\n",
    "    test_recall, test_ndcg, test_recs, test_targets = evaluate_pop(fold_data, 'test_input', 'test_target', k=10)\n",
    "\n",
    "    all_ndcgs.append(test_ndcg)  \n",
    "\n",
    "    combined_users = pd.concat([\n",
    "        train_df[['user_id', 'gender']],\n",
    "        fold_data['test_input'][['user_id', 'gender']],\n",
    "        fold_data['val_input'][['user_id', 'gender']],\n",
    "    ]).drop_duplicates()\n",
    "    user_info = combined_users.set_index('user_id')['gender'].to_dict()\n",
    "\n",
    "    user_metrics = pop_bias_metrics(train_df, test_recs, test_targets, user_info, top_k=10)\n",
    "\n",
    "    if user_metrics:\n",
    "        df = pd.DataFrame(user_metrics)\n",
    "        all_metrics.append(df.median(numeric_only=True).to_dict())\n",
    "\n",
    "        for gender in ['f', 'm']:\n",
    "            gdf = df[df['gender'] == gender]\n",
    "            if not gdf.empty:\n",
    "                gender_metrics[gender].append(gdf.median(numeric_only=True).to_dict())\n",
    "\n",
    "    print(f\"Fold {i} Test NDCG@10: {test_ndcg:.4f}\")\n",
    "\n",
    "\n",
    "def average_metrics(metrics_list, agg_func=np.median):\n",
    "    keys = metrics_list[0].keys()\n",
    "    return {k: agg_func([m[k] for m in metrics_list if k in m]) for k in keys}\n",
    "\n",
    "# Median aggregation \n",
    "final_all_median = average_metrics(all_metrics, agg_func=np.median)\n",
    "final_female_median = average_metrics(gender_metrics['f'], agg_func=np.median) if gender_metrics['f'] else None\n",
    "final_male_median = average_metrics(gender_metrics['m'], agg_func=np.median) if gender_metrics['m'] else None\n",
    "final_ndcg_median = np.median(all_ndcgs)\n",
    "\n",
    "\n",
    "def delta(group, overall):\n",
    "    return {k: overall[k] - group.get(k, 0) for k in overall if k in group}\n",
    "\n",
    "delta_f_median = delta(final_female_median, final_all_median) if final_female_median else {}\n",
    "delta_m_median = delta(final_male_median, final_all_median) if final_male_median else {}\n",
    "\n",
    "def print_metrics(label, metrics, include_ndcg):\n",
    "    print(f\"{label:<10}\", end=\"\")\n",
    "    for k in ['%Î”Mean', '%Î”Median', '%Î”Var', '%Î”Skew', '%Î”Kurtosis', 'KL', 'Kendall_tau']:\n",
    "        v = metrics.get(k, 0)\n",
    "        print(f\"| {v:9.2f} \", end=\"\")\n",
    "    if include_ndcg:\n",
    "        print(f\"| {metrics.get('NDCG@10', 0):8.4f} \", end=\"\")\n",
    "    print()\n",
    "\n",
    "final_all_median['NDCG@10'] = final_ndcg_median\n",
    "\n",
    "if final_female_median:\n",
    "    final_female_median['NDCG@10'] = final_ndcg_median  \n",
    "if final_male_median:\n",
    "    final_male_median['NDCG@10'] = final_ndcg_median\n",
    "\n",
    "\n",
    "print(\"\\n POP Model Popularity Bias Results:\")\n",
    "print(\"           | %Î”Mean   | %Î”Median | %Î”Var    | %Î”Skew   | %Î”Kurtosis |    KL    | KendallÏ„ | NDCG@10 \")\n",
    "print(\"-\" * 95)\n",
    "print_metrics(\"All\", final_all_median, include_ndcg=True)\n",
    "if final_female_median:\n",
    "    print_metrics(\"Î”Female\", delta_f_median, include_ndcg=False)\n",
    "if final_male_median:\n",
    "    print_metrics(\"Î”Male\", delta_m_median, include_ndcg=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d49de53",
   "metadata": {},
   "source": [
    "## RAND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3567c3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Validation Recall@10: 0.0003 | NDCG@10: 0.0001\n",
      "Fold 1 Test Recall@10: 0.0003 | NDCG@10: 0.0001\n",
      "Fold 2 Validation Recall@10: 0.0000 | NDCG@10: 0.0000\n",
      "Fold 2 Test Recall@10: 0.0003 | NDCG@10: 0.0001\n",
      "Fold 3 Validation Recall@10: 0.0002 | NDCG@10: 0.0001\n",
      "Fold 3 Test Recall@10: 0.0002 | NDCG@10: 0.0001\n",
      "Fold 4 Validation Recall@10: 0.0000 | NDCG@10: 0.0000\n",
      "Fold 4 Test Recall@10: 0.0002 | NDCG@10: 0.0001\n",
      "Fold 5 Validation Recall@10: 0.0000 | NDCG@10: 0.0000\n",
      "Fold 5 Test Recall@10: 0.0003 | NDCG@10: 0.0001\n",
      "\n",
      "Average Validation Recall@10: 0.0001\n",
      "Average Validation NDCG@10:   0.0000\n",
      "Average Test Recall@10:       0.0003\n",
      "Average Test NDCG@10:         0.0001\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def evaluate_rand(fold_data, input_key, target_key, k=10, seed=42):\n",
    "    random.seed(seed)\n",
    "    train_df = fold_data['train']\n",
    "    input_df = fold_data[input_key]\n",
    "    target_df = fold_data[target_key]\n",
    "\n",
    "    all_tracks = set(train_df['item_id'].unique())\n",
    "\n",
    "    input_groups = input_df.groupby('user_id')['item_id'].apply(set).to_dict()\n",
    "    target_groups = target_df.groupby('user_id')['item_id'].apply(set).to_dict()\n",
    "\n",
    "    user_ids = input_groups.keys()\n",
    "    recalls = []\n",
    "    ndcgs = []\n",
    "    user_recommendations = dict()\n",
    "\n",
    "    for user in user_ids:\n",
    "        known_tracks = input_groups[user]\n",
    "        true_tracks = target_groups.get(user, set())\n",
    "\n",
    "        candidate_tracks = list(all_tracks - known_tracks)\n",
    "\n",
    "        if len(candidate_tracks) >= k:\n",
    "            recommendations = random.sample(candidate_tracks, k)\n",
    "        else:\n",
    "            recommendations = candidate_tracks\n",
    "\n",
    "        recalls.append(recall_at_k(recommendations, true_tracks, k))\n",
    "        ndcgs.append(ndcg_at_k(recommendations, true_tracks, k))\n",
    "        user_recommendations[user] = recommendations\n",
    "\n",
    "    avg_recall = sum(recalls) / len(recalls) if recalls else 0\n",
    "    avg_ndcg = sum(ndcgs) / len(ndcgs) if ndcgs else 0\n",
    "\n",
    "    return avg_recall, avg_ndcg, user_recommendations, target_groups\n",
    "\n",
    "all_val_recalls = []\n",
    "all_val_ndcgs = []\n",
    "all_test_recalls = []\n",
    "all_test_ndcgs = []\n",
    "\n",
    "for i in range(1, 6):\n",
    "    fold_key = f'fold_{i}'\n",
    "    fold_data = folds_data[fold_key]\n",
    "\n",
    "    val_recall, val_ndcg, val_recs, val_targets = evaluate_rand(fold_data, 'val_input', 'val_target', k=10)\n",
    "    test_recall, test_ndcg, test_recs, test_targets = evaluate_rand(fold_data, 'test_input', 'test_target', k=10)\n",
    "\n",
    "    print(f\"Fold {i} Validation Recall@10: {val_recall:.4f} | NDCG@10: {val_ndcg:.4f}\")\n",
    "    print(f\"Fold {i} Test Recall@10: {test_recall:.4f} | NDCG@10: {test_ndcg:.4f}\")\n",
    "\n",
    "    all_val_recalls.append(val_recall)\n",
    "    all_val_ndcgs.append(val_ndcg)\n",
    "    all_test_recalls.append(test_recall)\n",
    "    all_test_ndcgs.append(test_ndcg)\n",
    "\n",
    "print(f\"\\nAverage Validation Recall@10: {np.mean(all_val_recalls):.4f}\")\n",
    "print(f\"Average Validation NDCG@10:   {np.mean(all_val_ndcgs):.4f}\")\n",
    "print(f\"Average Test Recall@10:       {np.mean(all_test_recalls):.4f}\")\n",
    "print(f\"Average Test NDCG@10:         {np.mean(all_test_ndcgs):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a68f3283",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khari\\AppData\\Local\\Temp\\ipykernel_33248\\2561634086.py:97: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  '%Î”Skew': percent_delta_metric(stats.skew(rec_vals), stats.skew(hist_vals)),\n",
      "C:\\Users\\khari\\AppData\\Local\\Temp\\ipykernel_33248\\2561634086.py:98: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  '%Î”Kurtosis': percent_delta_metric(stats.kurtosis(rec_vals), stats.kurtosis(hist_vals)),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Test Recall@10: 0.0003 | NDCG@10: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khari\\AppData\\Local\\Temp\\ipykernel_33248\\2561634086.py:97: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  '%Î”Skew': percent_delta_metric(stats.skew(rec_vals), stats.skew(hist_vals)),\n",
      "C:\\Users\\khari\\AppData\\Local\\Temp\\ipykernel_33248\\2561634086.py:98: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  '%Î”Kurtosis': percent_delta_metric(stats.kurtosis(rec_vals), stats.kurtosis(hist_vals)),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Test Recall@10: 0.0003 | NDCG@10: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khari\\AppData\\Local\\Temp\\ipykernel_33248\\2561634086.py:97: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  '%Î”Skew': percent_delta_metric(stats.skew(rec_vals), stats.skew(hist_vals)),\n",
      "C:\\Users\\khari\\AppData\\Local\\Temp\\ipykernel_33248\\2561634086.py:98: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  '%Î”Kurtosis': percent_delta_metric(stats.kurtosis(rec_vals), stats.kurtosis(hist_vals)),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Test Recall@10: 0.0002 | NDCG@10: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khari\\AppData\\Local\\Temp\\ipykernel_33248\\2561634086.py:97: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  '%Î”Skew': percent_delta_metric(stats.skew(rec_vals), stats.skew(hist_vals)),\n",
      "C:\\Users\\khari\\AppData\\Local\\Temp\\ipykernel_33248\\2561634086.py:98: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  '%Î”Kurtosis': percent_delta_metric(stats.kurtosis(rec_vals), stats.kurtosis(hist_vals)),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 Test Recall@10: 0.0002 | NDCG@10: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khari\\AppData\\Local\\Temp\\ipykernel_33248\\2561634086.py:97: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  '%Î”Skew': percent_delta_metric(stats.skew(rec_vals), stats.skew(hist_vals)),\n",
      "C:\\Users\\khari\\AppData\\Local\\Temp\\ipykernel_33248\\2561634086.py:98: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  '%Î”Kurtosis': percent_delta_metric(stats.kurtosis(rec_vals), stats.kurtosis(hist_vals)),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 Test Recall@10: 0.0003 | NDCG@10: 0.0001\n",
      "\n",
      "ðŸ“Š RAND Model Popularity Bias Results:\n",
      "           | %Î”Mean   | %Î”Median | %Î”Var    | %Î”Skew   | %Î”Kurtosis |    KL    | KendallÏ„ | NDCG@10 \n",
      "-----------------------------------------------------------------------------------------------\n",
      "All       |    -57.50 |    -66.67 |      0.00 |      0.00 |   -189.60 |      1.61 |      0.48 |   0.0001 \n",
      "Î”Female   |      4.51 |      0.00 |      0.00 |      0.00 |    -17.06 |      0.00 |      0.00 \n",
      "Î”Male     |     -5.14 |      0.00 |      0.00 |      0.00 |      8.75 |      0.35 |      0.00 \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import random\n",
    "\n",
    "# Metrics Definitions \n",
    "\n",
    "def recall_at_k(recommended, ground_truth, k=10):\n",
    "    recommended_k = recommended[:k]\n",
    "    hits = len(set(recommended_k) & set(ground_truth))\n",
    "    return hits / len(ground_truth) if ground_truth else 0\n",
    "\n",
    "def ndcg_at_k(recommended, ground_truth, k=10):\n",
    "    recommended_k = recommended[:k]\n",
    "    gains = [1 if item in ground_truth else 0 for item in recommended_k]\n",
    "    dcg = sum(gain / np.log2(idx + 2) for idx, gain in enumerate(gains))\n",
    "    ideal_gains = [1] * min(len(ground_truth), k)\n",
    "    idcg = sum(gain / np.log2(idx + 2) for idx, gain in enumerate(ideal_gains))\n",
    "    return dcg / idcg if idcg > 0 else 0\n",
    "\n",
    "# RAND recommender evaluation \n",
    "\n",
    "def evaluate_rand(fold_data, input_key, target_key, k=10, seed=42):\n",
    "    random.seed(seed)\n",
    "    train_df = fold_data['train']\n",
    "    input_df = fold_data[input_key]\n",
    "    target_df = fold_data[target_key]\n",
    "\n",
    "    all_tracks = set(train_df['item_id'].unique())\n",
    "    input_groups = input_df.groupby('user_id')['item_id'].apply(set).to_dict()\n",
    "    target_groups = target_df.groupby('user_id')['item_id'].apply(set).to_dict()\n",
    "\n",
    "    user_ids = input_groups.keys()\n",
    "    recalls = []\n",
    "    ndcgs = []\n",
    "    user_recommendations = dict()\n",
    "\n",
    "    for user in user_ids:\n",
    "        known_tracks = input_groups[user]\n",
    "        true_tracks = target_groups.get(user, set())\n",
    "\n",
    "        candidate_tracks = list(all_tracks - known_tracks)\n",
    "        if len(candidate_tracks) >= k:\n",
    "            recommendations = random.sample(candidate_tracks, k)\n",
    "        else:\n",
    "            recommendations = candidate_tracks\n",
    "\n",
    "        recalls.append(recall_at_k(recommendations, true_tracks, k))\n",
    "        ndcgs.append(ndcg_at_k(recommendations, true_tracks, k))\n",
    "        user_recommendations[user] = recommendations\n",
    "\n",
    "    avg_recall = np.mean(recalls) if recalls else 0\n",
    "    avg_ndcg = np.mean(ndcgs) if ndcgs else 0\n",
    "\n",
    "    return avg_recall, avg_ndcg, user_recommendations, target_groups\n",
    "\n",
    "#  Popularity Bias Metrics \n",
    "\n",
    "def percent_delta_metric(m_reco, m_hist):\n",
    "    return 100 * (m_reco - m_hist) / m_hist if m_hist != 0 else 0.0\n",
    "\n",
    "def kl_divergence(p, q):\n",
    "    epsilon = 1e-10\n",
    "    p = np.array(p) + epsilon\n",
    "    q = np.array(q) + epsilon\n",
    "    return np.sum(p * np.log(p / q))\n",
    "\n",
    "def kendalls_tau(x, y):\n",
    "    return stats.kendalltau(x, y).correlation\n",
    "\n",
    "def pop_bias_metrics(train_df, recommendations, targets, user_info, top_k=10):\n",
    "    popularity_dict = train_df['item_id'].value_counts().to_dict()\n",
    "    all_pop = np.array(list(popularity_dict.values()))\n",
    "    bins = np.quantile(all_pop, np.linspace(0, 1, 11))\n",
    "\n",
    "    def bin_distribution(vals, bins):\n",
    "        binned_counts, _ = np.histogram(vals, bins=bins)\n",
    "        return binned_counts / binned_counts.sum() if binned_counts.sum() > 0 else np.zeros_like(binned_counts, dtype=float)\n",
    "\n",
    "    user_metrics = []\n",
    "\n",
    "    for user_id, rec_tracks in recommendations.items():\n",
    "        true_tracks = targets.get(user_id, [])\n",
    "        if not true_tracks:\n",
    "            continue\n",
    "        hist_tracks = true_tracks  \n",
    "\n",
    "        hist_vals = [popularity_dict.get(t, 0) for t in hist_tracks]\n",
    "        rec_vals = [popularity_dict.get(t, 0) for t in rec_tracks]\n",
    "\n",
    "        metrics = {\n",
    "            'user_id': user_id,\n",
    "            'gender': user_info.get(user_id, None),\n",
    "            '%Î”Mean': percent_delta_metric(np.mean(rec_vals), np.mean(hist_vals)),\n",
    "            '%Î”Median': percent_delta_metric(np.median(rec_vals), np.median(hist_vals)),\n",
    "            '%Î”Var': percent_delta_metric(np.var(rec_vals), np.var(hist_vals)),\n",
    "            '%Î”Skew': percent_delta_metric(stats.skew(rec_vals), stats.skew(hist_vals)),\n",
    "            '%Î”Kurtosis': percent_delta_metric(stats.kurtosis(rec_vals), stats.kurtosis(hist_vals)),\n",
    "        }\n",
    "\n",
    "        hist_binned = bin_distribution(hist_vals, bins)\n",
    "        rec_binned = bin_distribution(rec_vals, bins)\n",
    "\n",
    "        metrics['KL'] = kl_divergence(hist_binned, rec_binned)\n",
    "        metrics['Kendall_tau'] = kendalls_tau(hist_binned, rec_binned)\n",
    "\n",
    "        user_metrics.append(metrics)\n",
    "\n",
    "    return user_metrics\n",
    "\n",
    "# Main Evaluation Loop \n",
    "\n",
    "all_metrics = []\n",
    "gender_metrics = {'f': [], 'm': []}\n",
    "all_ndcgs = []\n",
    "\n",
    "for i in range(1, 6):\n",
    "    fold_key = f'fold_{i}'\n",
    "    fold_data = folds_data[fold_key]\n",
    "\n",
    "    train_df = fold_data['train']\n",
    "\n",
    "    val_recall, val_ndcg, val_recs, val_targets = evaluate_rand(fold_data, 'val_input', 'val_target', k=10)\n",
    "    test_recall, test_ndcg, test_recs, test_targets = evaluate_rand(fold_data, 'test_input', 'test_target', k=10)\n",
    "\n",
    "    all_ndcgs.append(test_ndcg)\n",
    "\n",
    "    combined_users = pd.concat([\n",
    "        train_df[['user_id', 'gender']],\n",
    "        fold_data['val_input'][['user_id', 'gender']],\n",
    "        fold_data['test_input'][['user_id', 'gender']],\n",
    "    ]).drop_duplicates()\n",
    "    user_info = combined_users.set_index('user_id')['gender'].to_dict()\n",
    "\n",
    "    user_metrics = pop_bias_metrics(train_df, test_recs, test_targets, user_info, top_k=10)\n",
    "\n",
    "    if user_metrics:\n",
    "        df = pd.DataFrame(user_metrics)\n",
    "        all_metrics.append(df.median(numeric_only=True).to_dict())\n",
    "\n",
    "        for gender in ['f', 'm']:\n",
    "            gdf = df[df['gender'] == gender]\n",
    "            if not gdf.empty:\n",
    "                gender_metrics[gender].append(gdf.median(numeric_only=True).to_dict())\n",
    "\n",
    "    print(f\"Fold {i} Test Recall@10: {test_recall:.4f} | NDCG@10: {test_ndcg:.4f}\")\n",
    "\n",
    "\n",
    "def average_metrics(metrics_list, agg_func=np.median):\n",
    "    if not metrics_list:\n",
    "        return {}\n",
    "    keys = metrics_list[0].keys()\n",
    "    return {k: agg_func([m[k] for m in metrics_list if k in m]) for k in keys}\n",
    "\n",
    "final_all_median = average_metrics(all_metrics)\n",
    "final_female_median = average_metrics(gender_metrics['f']) if gender_metrics['f'] else None\n",
    "final_male_median = average_metrics(gender_metrics['m']) if gender_metrics['m'] else None\n",
    "final_ndcg_median = np.median(all_ndcgs) if all_ndcgs else 0\n",
    "\n",
    "def delta(group, overall):\n",
    "    return {k: overall[k] - group.get(k, 0) for k in overall if k in group}\n",
    "\n",
    "delta_f_median = delta(final_female_median, final_all_median) if final_female_median else {}\n",
    "delta_m_median = delta(final_male_median, final_all_median) if final_male_median else {}\n",
    "\n",
    "def print_metrics(label, metrics, include_ndcg):\n",
    "    print(f\"{label:<10}\", end=\"\")\n",
    "    for k in ['%Î”Mean', '%Î”Median', '%Î”Var', '%Î”Skew', '%Î”Kurtosis', 'KL', 'Kendall_tau']:\n",
    "        v = metrics.get(k, 0)\n",
    "        print(f\"| {v:9.2f} \", end=\"\")\n",
    "    if include_ndcg:\n",
    "        print(f\"| {metrics.get('NDCG@10', 0):8.4f} \", end=\"\")\n",
    "    print()\n",
    "\n",
    "final_all_median['NDCG@10'] = final_ndcg_median\n",
    "if final_female_median:\n",
    "    final_female_median['NDCG@10'] = final_ndcg_median\n",
    "if final_male_median:\n",
    "    final_male_median['NDCG@10'] = final_ndcg_median\n",
    "\n",
    "print(\"\\n RAND Model Popularity Bias Results:\")\n",
    "print(\"           | %Î”Mean   | %Î”Median | %Î”Var    | %Î”Skew   | %Î”Kurtosis |    KL    | KendallÏ„ | NDCG@10 \")\n",
    "print(\"-\" * 95)\n",
    "print_metrics(\"All\", final_all_median, include_ndcg=True)\n",
    "if final_female_median:\n",
    "    print_metrics(\"Î”Female\", delta_f_median, include_ndcg=False)\n",
    "if final_male_median:\n",
    "    print_metrics(\"Î”Male\", delta_m_median, include_ndcg=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079ec018",
   "metadata": {},
   "source": [
    "## Item KNN - done locally using Pycharm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86724788",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "folds_data = {}\n",
    "base_dir = \"book_folds\"  \n",
    "\n",
    "for i in range(1, 6):\n",
    "    fold_path = os.path.join(base_dir, f\"fold_{i}\")\n",
    "\n",
    "    data = {\n",
    "        'train': pd.read_csv(os.path.join(fold_path, 'train.tsv'), sep='\\t'),\n",
    "        'val_input': pd.read_csv(os.path.join(fold_path, 'val_input.tsv'), sep='\\t'),\n",
    "        'val_target': pd.read_csv(os.path.join(fold_path, 'val_target.tsv'), sep='\\t'),\n",
    "        'test_input': pd.read_csv(os.path.join(fold_path, 'test_input.tsv'), sep='\\t'),\n",
    "        'test_target': pd.read_csv(os.path.join(fold_path, 'test_target.tsv'), sep='\\t'),\n",
    "    }\n",
    "    folds_data[f'fold_{i}'] = data\n",
    "    print(f\"Loaded fold_{i} datasets\")\n",
    "\n",
    "#  Metrics \n",
    "def recall_at_k(recommended, ground_truth, k=10):\n",
    "    recommended_k = recommended[:k]\n",
    "    hits = len(set(recommended_k) & set(ground_truth))\n",
    "    return hits / len(ground_truth) if ground_truth else 0\n",
    "\n",
    "def ndcg_at_k(recommended, ground_truth, k=10):\n",
    "    recommended_k = recommended[:k]\n",
    "    gains = [1 if item in ground_truth else 0 for item in recommended_k]\n",
    "    dcg = sum(g / np.log2(i + 2) for i, g in enumerate(gains))\n",
    "    idcg = sum(1 / np.log2(i + 2) for i in range(min(len(ground_truth), k)))\n",
    "    return dcg / idcg if idcg > 0 else 0\n",
    "\n",
    "#  Item KNN Evaluation \n",
    "def evaluate_item_knn(fold_data, input_key, target_key, k=10, topk_sim=100):\n",
    "    train_df = fold_data['train']\n",
    "    input_df = fold_data[input_key]\n",
    "    target_df = fold_data[target_key]\n",
    "\n",
    "    print(f\"\\nEvaluating with ITEM KNN on {input_key}...\")\n",
    "\n",
    "    input_df_extended = input_df[['user_id', 'item_id']].copy()\n",
    "    input_df_extended[\"binary_listen\"] = 1\n",
    "    combined_df = pd.concat([train_df, input_df_extended])\n",
    "\n",
    "    users = combined_df['user_id'].unique()\n",
    "    items = combined_df['item_id'].unique()\n",
    "\n",
    "    user_to_idx = {user: i for i, user in enumerate(users)}\n",
    "    item_to_idx = {item: i for i, item in enumerate(items)}\n",
    "    idx_to_item = {i: item for item, i in item_to_idx.items()}\n",
    "\n",
    "    print(f\"Users in train+input: {len(users)} | Items: {len(items)}\")\n",
    "\n",
    "    row_idx = combined_df['user_id'].map(user_to_idx)\n",
    "    col_idx = combined_df['item_id'].map(item_to_idx)\n",
    "    data = combined_df['binary_listen'].astype(float)\n",
    "\n",
    "    user_item_matrix = csr_matrix((data, (row_idx, col_idx)), shape=(len(users), len(items)))\n",
    "\n",
    "    print(\"Computing item-item similarity...\")\n",
    "    item_sim = cosine_similarity(user_item_matrix.T, dense_output=False)\n",
    "\n",
    "    for i in range(item_sim.shape[0]):\n",
    "        row = item_sim[i]\n",
    "        if row.nnz > topk_sim:\n",
    "            top_k_idx = np.argpartition(row.data, -topk_sim)[-topk_sim:]\n",
    "            mask = np.ones(len(row.data), dtype=bool)\n",
    "            mask[top_k_idx] = False\n",
    "            row.data[mask] = 0\n",
    "    item_sim.eliminate_zeros()\n",
    "\n",
    "    print(\"Generating recommendations...\")\n",
    "    input_groups = input_df.groupby('user_id')['item_id'].apply(set).to_dict()\n",
    "    target_groups = target_df.groupby('user_id')['item_id'].apply(set).to_dict()\n",
    "\n",
    "    recalls, ndcgs = [], []\n",
    "    user_recommendations = {}\n",
    "\n",
    "    for user in input_groups:\n",
    "        if user not in user_to_idx:\n",
    "            continue\n",
    "\n",
    "        known_items = input_groups[user]\n",
    "        known_indices = [item_to_idx[i] for i in known_items if i in item_to_idx]\n",
    "\n",
    "        if not known_indices:\n",
    "            continue\n",
    "\n",
    "        scores = item_sim[known_indices].sum(axis=0).A1\n",
    "        scores[[item_to_idx[i] for i in known_items if i in item_to_idx]] = 0  \n",
    "\n",
    "        top_items_idx = np.argpartition(scores, -k)[-k:]\n",
    "        top_items_sorted = top_items_idx[np.argsort(-scores[top_items_idx])]\n",
    "        recommended_items = [idx_to_item[i] for i in top_items_sorted if scores[i] > 0]\n",
    "\n",
    "        true_items = target_groups.get(user, set())\n",
    "        recalls.append(recall_at_k(recommended_items, true_items, k))\n",
    "        ndcgs.append(ndcg_at_k(recommended_items, true_items, k))\n",
    "        user_recommendations[user] = recommended_items\n",
    "\n",
    "    avg_recall = np.mean(recalls) if recalls else 0\n",
    "    avg_ndcg = np.mean(ndcgs) if ndcgs else 0\n",
    "\n",
    "    return avg_recall, avg_ndcg, user_recommendations, target_groups\n",
    "\n",
    "itemknn_test_targets = {}\n",
    "itemknn_test_recommendations = {}\n",
    "itemknn_test_ndcg_scores = {}\n",
    "\n",
    "# Main Evaluation \n",
    "all_val_recalls, all_val_ndcgs = [], []\n",
    "all_test_recalls, all_test_ndcgs = [], []\n",
    "\n",
    "for i in range(1, 6):\n",
    "    fold_key = f'fold_{i}'\n",
    "    fold_data = folds_data[fold_key]\n",
    "\n",
    "    val_recall, val_ndcg, _, _ = evaluate_item_knn(fold_data, 'val_input', 'val_target', k=10)\n",
    "    test_recall, test_ndcg, test_recs, test_targets = evaluate_item_knn(fold_data, 'test_input', 'test_target', k=10)\n",
    "\n",
    "    itemknn_test_recommendations[fold_key] = test_recs\n",
    "    itemknn_test_targets[fold_key] = test_targets\n",
    "    itemknn_test_ndcg_scores[fold_key] = test_ndcg\n",
    "\n",
    "    print(f\"Fold {i} Val Recall@10: {val_recall:.4f} | NDCG@10: {val_ndcg:.4f}\")\n",
    "    print(f\"Fold {i} Test Recall@10: {test_recall:.4f} | NDCG@10: {test_ndcg:.4f}\")\n",
    "\n",
    "    all_val_recalls.append(val_recall)\n",
    "    all_val_ndcgs.append(val_ndcg)\n",
    "    all_test_recalls.append(test_recall)\n",
    "    all_test_ndcgs.append(test_ndcg)\n",
    "\n",
    "\n",
    "print(\"\\n====== Overall Results ======\")\n",
    "print(f\"Average Val Recall@10:  {np.mean(all_val_recalls):.4f}\")\n",
    "print(f\"Average Val NDCG@10:    {np.mean(all_val_ndcgs):.4f}\")\n",
    "print(f\"Average Test Recall@10: {np.mean(all_test_recalls):.4f}\")\n",
    "print(f\"Average Test NDCG@10:   {np.mean(all_test_ndcgs):.4f}\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Popularity Bias Metrics Functions \n",
    "\n",
    "def percent_delta_metric(m_reco, m_hist):\n",
    "    return 100 * (m_reco - m_hist) / m_hist if m_hist != 0 else 0.0\n",
    "\n",
    "def kl_divergence(p, q):\n",
    "    epsilon = 1e-10\n",
    "    p = np.array(p) + epsilon\n",
    "    q = np.array(q) + epsilon\n",
    "    return np.sum(p * np.log(p / q))\n",
    "\n",
    "def kendalls_tau(x, y):\n",
    "    return stats.kendalltau(x, y).correlation\n",
    "\n",
    "def pop_bias_metrics(train_df, recommendations, targets, user_info, top_k=10):\n",
    "    popularity_dict = train_df['item_id'].value_counts().to_dict()\n",
    "    all_pop = np.array(list(popularity_dict.values()))\n",
    "    bins = np.quantile(all_pop, np.linspace(0, 1, 11))\n",
    "\n",
    "    def bin_distribution(vals, bins):\n",
    "        binned_counts, _ = np.histogram(vals, bins=bins)\n",
    "        return binned_counts / binned_counts.sum() if binned_counts.sum() > 0 else np.zeros_like(binned_counts, dtype=float)\n",
    "\n",
    "    user_metrics = []\n",
    "\n",
    "    for user_id, rec_tracks in recommendations.items():\n",
    "        true_tracks = targets.get(user_id, [])\n",
    "        if not true_tracks:\n",
    "            continue\n",
    "        hist_tracks = true_tracks\n",
    "\n",
    "        hist_vals = [popularity_dict.get(t, 0) for t in hist_tracks]\n",
    "        rec_vals = [popularity_dict.get(t, 0) for t in rec_tracks]\n",
    "\n",
    "        metrics = {\n",
    "            'user_id': user_id,\n",
    "            'gender': user_info.get(user_id, None),\n",
    "            '%Î”Mean': percent_delta_metric(np.mean(rec_vals), np.mean(hist_vals)),\n",
    "            '%Î”Median': percent_delta_metric(np.median(rec_vals), np.median(hist_vals)),\n",
    "            '%Î”Var': percent_delta_metric(np.var(rec_vals), np.var(hist_vals)),\n",
    "            '%Î”Skew': percent_delta_metric(stats.skew(rec_vals), stats.skew(hist_vals)),\n",
    "            '%Î”Kurtosis': percent_delta_metric(stats.kurtosis(rec_vals), stats.kurtosis(hist_vals)),\n",
    "        }\n",
    "\n",
    "        hist_binned = bin_distribution(hist_vals, bins)\n",
    "        rec_binned = bin_distribution(rec_vals, bins)\n",
    "\n",
    "        metrics['KL'] = kl_divergence(hist_binned, rec_binned)\n",
    "        metrics['Kendall_tau'] = kendalls_tau(hist_binned, rec_binned)\n",
    "\n",
    "        user_metrics.append(metrics)\n",
    "\n",
    "    return user_metrics\n",
    "\n",
    "all_metrics = []\n",
    "gender_metrics = {'f': [], 'm': []}\n",
    "all_ndcgs = []\n",
    "\n",
    "for i in range(1, 6):\n",
    "    fold_key = f'fold_{i}'\n",
    "    fold_data = folds_data[fold_key]\n",
    "\n",
    "    train_df = fold_data['train']\n",
    "    test_targets = itemknn_test_targets[fold_key]  \n",
    "    test_recs = itemknn_test_recommendations[fold_key]\n",
    "    ndcg_score = itemknn_test_ndcg_scores[fold_key]\n",
    "\n",
    "    all_ndcgs.append(ndcg_score)\n",
    "\n",
    "    combined_users = pd.concat([\n",
    "        train_df[['user_id', 'gender']],\n",
    "        fold_data['val_input'][['user_id', 'gender']],\n",
    "        fold_data['test_input'][['user_id', 'gender']],\n",
    "    ]).drop_duplicates()\n",
    "    user_info = combined_users.set_index('user_id')['gender'].to_dict()\n",
    "\n",
    "    user_metrics = pop_bias_metrics(train_df, test_recs, test_targets, user_info, top_k=10)\n",
    "\n",
    "    if user_metrics:\n",
    "        df = pd.DataFrame(user_metrics)\n",
    "        all_metrics.append(df.median(numeric_only=True).to_dict())\n",
    "\n",
    "        for gender in ['f', 'm']:\n",
    "            gdf = df[df['gender'] == gender]\n",
    "            if not gdf.empty:\n",
    "                gender_metrics[gender].append(gdf.median(numeric_only=True).to_dict())\n",
    "\n",
    "# Aggregate Results\n",
    "\n",
    "def average_metrics(metrics_list, agg_func=np.median):\n",
    "    if not metrics_list:\n",
    "        return {}\n",
    "    keys = metrics_list[0].keys()\n",
    "    return {k: agg_func([m[k] for m in metrics_list if k in m]) for k in keys}\n",
    "\n",
    "final_all_median = average_metrics(all_metrics)\n",
    "final_female_median = average_metrics(gender_metrics['f']) if gender_metrics['f'] else None\n",
    "final_male_median = average_metrics(gender_metrics['m']) if gender_metrics['m'] else None\n",
    "final_ndcg_median = np.median(all_ndcgs) if all_ndcgs else 0\n",
    "\n",
    "def delta(group, overall):\n",
    "    return {k: overall[k] - group.get(k, 0) for k in overall if k in group}\n",
    "\n",
    "delta_f_median = delta(final_female_median, final_all_median) if final_female_median else {}\n",
    "delta_m_median = delta(final_male_median, final_all_median) if final_male_median else {}\n",
    "\n",
    "def print_metrics(label, metrics, include_ndcg):\n",
    "    print(f\"{label:<10}\", end=\"\")\n",
    "    for k in ['%Î”Mean', '%Î”Median', '%Î”Var', '%Î”Skew', '%Î”Kurtosis', 'KL', 'Kendall_tau']:\n",
    "        v = metrics.get(k, 0)\n",
    "        print(f\"| {v:9.2f} \", end=\"\")\n",
    "    if include_ndcg:\n",
    "        print(f\"| {metrics.get('NDCG@10', 0):8.4f} \", end=\"\")\n",
    "    print()\n",
    "\n",
    "final_all_median['NDCG@10'] = final_ndcg_median\n",
    "if final_female_median:\n",
    "    final_female_median['NDCG@10'] = final_ndcg_median\n",
    "if final_male_median:\n",
    "    final_male_median['NDCG@10'] = final_ndcg_median\n",
    "\n",
    "print(\"\\n\\U0001F4CA Item KNN Model Popularity Bias Results:\")\n",
    "print(\"           | %Î”Mean   | %Î”Median | %Î”Var    | %Î”Skew   | %Î”Kurtosis |    KL    | KendallÏ„ | NDCG@10 \")\n",
    "print(\"-\" * 95)\n",
    "print_metrics(\"All\", final_all_median, include_ndcg=True)\n",
    "if final_female_median:\n",
    "    print_metrics(\"Î”Female\", delta_f_median, include_ndcg=False)\n",
    "if final_male_median:\n",
    "    print_metrics(\"Î”Male\", delta_m_median, include_ndcg=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a8d393",
   "metadata": {},
   "source": [
    "###  Item KNN Model Popularity Bias Results:\n",
    "\n",
    "|           | %Î”Mean  | %Î”Median | %Î”Var   | %Î”Skew  | %Î”Kurtosis | KL   | KendallÏ„ | NDCG@10 |\n",
    "|-----------|---------|----------|---------|---------|-------------|------|-----------|---------|\n",
    "| **All**     | -67.46  | -66.67   | 0.00    | 0.00    | -116.54     | 2.30 | 0.34      | 0.0112  |\n",
    "| **Î”Female** | 5.87    | 0.00     | 0.00    | 0.00    | -0.24       | 0.00 | -0.01     |         |\n",
    "| **Î”Male**   | -0.80   | 0.00     | 0.00    | 0.00    | -0.66       | 0.00 | 0.00      |         |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d67f753",
   "metadata": {},
   "source": [
    "## ALS - done locally using Pycharm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe50d827",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.sparse import csr_matrix\n",
    "from numpy.linalg import solve\n",
    "\n",
    "\n",
    "fold_data = {}\n",
    "for i in range(1, 6):\n",
    "    fold_key = f\"fold_{i}\"\n",
    "    fold_path = os.path.join(\"book_folds\", fold_key)\n",
    "\n",
    "    try:\n",
    "        fold_data[fold_key] = {\n",
    "            \"train\": pd.read_csv(os.path.join(fold_path, \"train.tsv\"), sep='\\t'),\n",
    "            \"val_input\": pd.read_csv(os.path.join(fold_path, \"val_input.tsv\"), sep='\\t'),\n",
    "            \"val_target\": pd.read_csv(os.path.join(fold_path, \"val_target.tsv\"), sep='\\t'),\n",
    "            \"test_input\": pd.read_csv(os.path.join(fold_path, \"test_input.tsv\"), sep='\\t'),\n",
    "            \"test_target\": pd.read_csv(os.path.join(fold_path, \"test_target.tsv\"), sep='\\t'),\n",
    "        }\n",
    "        print(f\"Loaded {fold_key} datasets\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load {fold_key}: {e}\")\n",
    "\n",
    "print(\"Loaded folds:\", list(fold_data.keys()))\n",
    "\n",
    "\n",
    "#  Metrics \n",
    "def recall_at_k(recommended, ground_truth, k=10):\n",
    "    recommended_k = recommended[:k]\n",
    "    hits = len(set(recommended_k) & set(ground_truth))\n",
    "    return hits / len(ground_truth) if ground_truth else 0\n",
    "\n",
    "\n",
    "def ndcg_at_k(recommended, ground_truth, k=10):\n",
    "    recommended_k = recommended[:k]\n",
    "    gains = [1 if item in ground_truth else 0 for item in recommended_k]\n",
    "    dcg = sum(g / np.log2(i + 2) for i, g in enumerate(gains))\n",
    "    idcg = sum(1 / np.log2(i + 2) for i in range(min(len(ground_truth), k)))\n",
    "    return dcg / idcg if idcg > 0 else 0\n",
    "\n",
    "\n",
    "# ALS Implementation \n",
    "def als_explicit(user_item_matrix, n_factors=10, n_iters=10, reg=1):\n",
    "    n_users, n_items = user_item_matrix.shape\n",
    "    user_factors = np.random.normal(scale=1. / n_factors, size=(n_users, n_factors))\n",
    "    item_factors = np.random.normal(scale=1. / n_factors, size=(n_items, n_factors))\n",
    "    eye = np.eye(n_factors)\n",
    "\n",
    "    for iteration in range(n_iters):\n",
    "        for u in range(n_users):\n",
    "            start_ptr, end_ptr = user_item_matrix.indptr[u], user_item_matrix.indptr[u + 1]\n",
    "            item_indices = user_item_matrix.indices[start_ptr:end_ptr]\n",
    "            ratings = user_item_matrix.data[start_ptr:end_ptr]\n",
    "            if len(item_indices) == 0:\n",
    "                continue\n",
    "            V = item_factors[item_indices]\n",
    "            A = V.T @ V + reg * eye\n",
    "            b = V.T @ ratings\n",
    "            user_factors[u] = solve(A, b)\n",
    "\n",
    "        user_item_csc = user_item_matrix.tocsc()\n",
    "        for i in range(n_items):\n",
    "            start_ptr, end_ptr = user_item_csc.indptr[i], user_item_csc.indptr[i + 1]\n",
    "            user_indices = user_item_csc.indices[start_ptr:end_ptr]\n",
    "            ratings = user_item_csc.data[start_ptr:end_ptr]\n",
    "            if len(user_indices) == 0:\n",
    "                continue\n",
    "            U = user_factors[user_indices]\n",
    "            A = U.T @ U + reg * eye\n",
    "            b = U.T @ ratings\n",
    "            item_factors[i] = solve(A, b)\n",
    "\n",
    "        print(f\"ALS Iteration {iteration + 1}/{n_iters} completed\")\n",
    "\n",
    "    return user_factors, item_factors\n",
    "\n",
    "\n",
    "# Evaluation with ALS \n",
    "def evaluate_als(fold_data, input_key, target_key, n_factors=20, n_iters=10, k=10):\n",
    "    train_df = fold_data['train']\n",
    "    input_df = fold_data[input_key]\n",
    "    target_df = fold_data[target_key]\n",
    "\n",
    "    print(f\"\\nEvaluating with ALS on {input_key}...\")\n",
    "\n",
    "    input_df_extended = input_df[['user_id', 'item_id']].copy()\n",
    "    input_df_extended[\"rating\"] = 1.0\n",
    "    train_ratings = train_df.rename(columns={'binary_listen': 'rating'})[['user_id', 'item_id', 'rating']]\n",
    "\n",
    "    train_ratings = train_ratings.loc[:, ~train_ratings.columns.duplicated()].reset_index(drop=True)\n",
    "    input_df_extended = input_df_extended.loc[:, ~input_df_extended.columns.duplicated()].reset_index(drop=True)\n",
    "\n",
    "    combined_df = pd.concat([train_ratings[['user_id', 'item_id', 'rating']],\n",
    "                             input_df_extended[['user_id', 'item_id', 'rating']]],\n",
    "                            ignore_index=True)\n",
    "\n",
    "    users = combined_df['user_id'].unique()\n",
    "    items = combined_df['item_id'].unique()\n",
    "    user_to_idx = {user: i for i, user in enumerate(users)}\n",
    "    item_to_idx = {item: i for i, item in enumerate(items)}\n",
    "    idx_to_item = {i: item for item, i in item_to_idx.items()}\n",
    "\n",
    "    print(f\"Users in train+input: {len(users)} | Items: {len(items)}\")\n",
    "\n",
    "    row_idx = combined_df['user_id'].map(user_to_idx)\n",
    "    col_idx = combined_df['item_id'].map(item_to_idx)\n",
    "    data = combined_df['rating'].astype(float)\n",
    "    user_item_matrix = csr_matrix((data, (row_idx, col_idx)), shape=(len(users), len(items)))\n",
    "\n",
    "    user_factors, item_factors = als_explicit(user_item_matrix, n_factors=n_factors, n_iters=n_iters)\n",
    "\n",
    "    input_groups = input_df.groupby('user_id')['item_id'].apply(set).to_dict()\n",
    "    target_groups = target_df.groupby('user_id')['item_id'].apply(set).to_dict()\n",
    "\n",
    "    recalls, ndcgs = [], []\n",
    "    user_recommendations = {}\n",
    "\n",
    "    for user in input_groups:\n",
    "        if user not in user_to_idx:\n",
    "            continue\n",
    "        user_idx = user_to_idx[user]\n",
    "        known_items = input_groups[user]\n",
    "        known_indices = [item_to_idx[i] for i in known_items if i in item_to_idx]\n",
    "\n",
    "        if not known_indices:\n",
    "            continue\n",
    "\n",
    "        scores = user_factors[user_idx] @ item_factors.T\n",
    "        scores[known_indices] = -np.inf  \n",
    "\n",
    "        top_items_idx = np.argpartition(scores, -k)[-k:]\n",
    "        top_items_sorted = top_items_idx[np.argsort(-scores[top_items_idx])]\n",
    "        recommended_items = [idx_to_item[i] for i in top_items_sorted if scores[i] > -np.inf]\n",
    "\n",
    "        true_items = target_groups.get(user, set())\n",
    "        recalls.append(recall_at_k(recommended_items, true_items, k))\n",
    "        ndcgs.append(ndcg_at_k(recommended_items, true_items, k))\n",
    "        user_recommendations[user] = recommended_items\n",
    "\n",
    "    avg_recall = np.mean(recalls) if recalls else 0\n",
    "    avg_ndcg = np.mean(ndcgs) if ndcgs else 0\n",
    "\n",
    "    return avg_recall, avg_ndcg, user_recommendations, target_groups\n",
    "\n",
    "\n",
    "#  Main Evaluation Loop \n",
    "all_val_recalls, all_val_ndcgs = [], []\n",
    "all_test_recalls, all_test_ndcgs = [], []\n",
    "\n",
    "als_test_targets = {}\n",
    "als_test_recommendations = {}\n",
    "als_test_ndcg_scores = {}\n",
    "\n",
    "for i in range(1, 6):\n",
    "    fold_key = f'fold_{i}'\n",
    "    fd = fold_data[fold_key]\n",
    "\n",
    "    val_recall, val_ndcg, _, _ = evaluate_als(fd, 'val_input', 'val_target', n_factors=20, n_iters=10, k=10)\n",
    "    test_recall, test_ndcg, test_recs, test_targets = evaluate_als(fd, 'test_input', 'test_target', n_factors=20,\n",
    "                                                                   n_iters=10, k=10)\n",
    "\n",
    "    als_test_recommendations[fold_key] = test_recs\n",
    "    als_test_targets[fold_key] = test_targets\n",
    "    als_test_ndcg_scores[fold_key] = test_ndcg\n",
    "\n",
    "    print(f\"Fold {i} Val Recall@10: {val_recall:.4f} | NDCG@10: {val_ndcg:.4f}\")\n",
    "    print(f\"Fold {i} Test Recall@10: {test_recall:.4f} | NDCG@10: {test_ndcg:.4f}\")\n",
    "\n",
    "    all_val_recalls.append(val_recall)\n",
    "    all_val_ndcgs.append(val_ndcg)\n",
    "    all_test_recalls.append(test_recall)\n",
    "    all_test_ndcgs.append(test_ndcg)\n",
    "\n",
    "print(\"\\n====== Overall ALS Results ======\")\n",
    "print(f\"Average Val Recall@10:  {np.mean(all_val_recalls):.4f}\")\n",
    "print(f\"Average Val NDCG@10:    {np.mean(all_val_ndcgs):.4f}\")\n",
    "print(f\"Average Test Recall@10: {np.mean(all_test_recalls):.4f}\")\n",
    "print(f\"Average Test NDCG@10:   {np.mean(all_test_ndcgs):.4f}\")\n",
    "\n",
    "\n",
    "#  Popularity Bias Metrics \n",
    "def percent_delta_metric(m_reco, m_hist):\n",
    "    return 100 * (m_reco - m_hist) / m_hist if m_hist != 0 else 0.0\n",
    "\n",
    "\n",
    "def kl_divergence(p, q):\n",
    "    epsilon = 1e-10\n",
    "    p = np.array(p) + epsilon\n",
    "    q = np.array(q) + epsilon\n",
    "    return np.sum(p * np.log(p / q))\n",
    "\n",
    "\n",
    "def kendalls_tau(x, y):\n",
    "    return stats.kendalltau(x, y).correlation\n",
    "\n",
    "\n",
    "def pop_bias_metrics(train_df, recommendations, targets, user_info, top_k=50):\n",
    "    popularity_dict = train_df['item_id'].value_counts().to_dict()\n",
    "    all_pop = np.array(list(popularity_dict.values()))\n",
    "    bins = np.quantile(all_pop, np.linspace(0, 1, 11))\n",
    "\n",
    "    def bin_distribution(vals, bins):\n",
    "        binned_counts, _ = np.histogram(vals, bins=bins)\n",
    "        return binned_counts / binned_counts.sum() if binned_counts.sum() > 0 else np.zeros_like(binned_counts, dtype=float)\n",
    "\n",
    "    user_metrics = []\n",
    "\n",
    "    for user_id, rec_tracks in recommendations.items():\n",
    "        true_tracks = targets.get(user_id, [])\n",
    "        if not true_tracks:\n",
    "            continue\n",
    "        hist_tracks = true_tracks\n",
    "\n",
    "        hist_vals = [popularity_dict.get(t, 0) for t in hist_tracks]\n",
    "        rec_vals = [popularity_dict.get(t, 0) for t in rec_tracks]\n",
    "\n",
    "        metrics = {\n",
    "            'user_id': user_id,\n",
    "            'gender': user_info.get(user_id, None),\n",
    "            '%Î”Mean': percent_delta_metric(np.mean(rec_vals), np.mean(hist_vals)),\n",
    "            '%Î”Median': percent_delta_metric(np.median(rec_vals), np.median(hist_vals)),\n",
    "            '%Î”Var': percent_delta_metric(np.var(rec_vals), np.var(hist_vals)),\n",
    "            '%Î”Skew': percent_delta_metric(stats.skew(rec_vals), stats.skew(hist_vals)),\n",
    "            '%Î”Kurtosis': percent_delta_metric(stats.kurtosis(rec_vals), stats.kurtosis(hist_vals)),\n",
    "        }\n",
    "\n",
    "        hist_binned = bin_distribution(hist_vals, bins)\n",
    "        rec_binned = bin_distribution(rec_vals, bins)\n",
    "\n",
    "        metrics['KL'] = kl_divergence(hist_binned, rec_binned)\n",
    "        metrics['Kendall_tau'] = kendalls_tau(hist_binned, rec_binned)\n",
    "\n",
    "        user_metrics.append(metrics)\n",
    "\n",
    "    return user_metrics\n",
    "\n",
    "\n",
    "#  Popularity Bias Analysis \n",
    "all_metrics = []\n",
    "gender_metrics = {'f': [], 'm': []}\n",
    "all_ndcgs = []\n",
    "\n",
    "for i in range(1, 6):\n",
    "    fold_key = f'fold_{i}'\n",
    "    fd = fold_data[fold_key]\n",
    "\n",
    "    train_df = fd['train']\n",
    "    test_targets = als_test_targets[fold_key]\n",
    "    test_recs = als_test_recommendations[fold_key]\n",
    "    ndcg_score = als_test_ndcg_scores[fold_key]\n",
    "    all_ndcgs.append(ndcg_score)\n",
    "\n",
    "    combined_users = pd.concat([\n",
    "        train_df[['user_id', 'gender']],\n",
    "        fd['val_input'][['user_id', 'gender']],\n",
    "        fd['test_input'][['user_id', 'gender']],\n",
    "    ]).drop_duplicates()\n",
    "    user_info = combined_users.set_index('user_id')['gender'].to_dict()\n",
    "\n",
    "    user_metrics = pop_bias_metrics(train_df, test_recs, test_targets, user_info, top_k=10)\n",
    "\n",
    "    if user_metrics:\n",
    "        df = pd.DataFrame(user_metrics)\n",
    "        all_metrics.append(df.median(numeric_only=True).to_dict())\n",
    "\n",
    "        for gender in ['f', 'm']:\n",
    "            gdf = df[df['gender'] == gender]\n",
    "            if not gdf.empty:\n",
    "                gender_metrics[gender].append(gdf.median(numeric_only=True).to_dict())\n",
    "\n",
    "\n",
    "def average_metrics(metrics_list, agg_func=np.median):\n",
    "    if not metrics_list:\n",
    "        return {}\n",
    "    keys = metrics_list[0].keys()\n",
    "    return {k: agg_func([m[k] for m in metrics_list if k in m]) for k in keys}\n",
    "\n",
    "\n",
    "final_all_median = average_metrics(all_metrics)\n",
    "final_female_median = average_metrics(gender_metrics['f']) if gender_metrics['f'] else None\n",
    "final_male_median = average_metrics(gender_metrics['m']) if gender_metrics['m'] else None\n",
    "final_ndcg_median = np.median(all_ndcgs) if all_ndcgs else 0\n",
    "\n",
    "\n",
    "def delta(group, overall):\n",
    "    return {k: overall[k] - group.get(k, 0) for k in overall if k in group}\n",
    "\n",
    "\n",
    "delta_f_median = delta(final_female_median, final_all_median) if final_female_median else {}\n",
    "delta_m_median = delta(final_male_median, final_all_median) if final_male_median else {}\n",
    "\n",
    "\n",
    "def print_metrics(label, metrics, include_ndcg):\n",
    "    print(f\"{label:<10}\", end=\"\")\n",
    "    for k in ['%Î”Mean', '%Î”Median', '%Î”Var', '%Î”Skew', '%Î”Kurtosis', 'KL', 'Kendall_tau']:\n",
    "        v = metrics.get(k, 0)\n",
    "        print(f\"| {v:9.2f} \", end=\"\")\n",
    "    if include_ndcg:\n",
    "        print(f\"| {metrics.get('NDCG@10', 0):8.4f} \", end=\"\")\n",
    "    print()\n",
    "\n",
    "\n",
    "final_all_median['NDCG@10'] = final_ndcg_median\n",
    "if final_female_median:\n",
    "    final_female_median['NDCG@10'] = final_ndcg_median\n",
    "if final_male_median:\n",
    "    final_male_median['NDCG@10'] = final_ndcg_median\n",
    "\n",
    "print(\"\\n ALS Model Popularity Bias Results:\")\n",
    "print(\"           | %Î”Mean   | %Î”Median | %Î”Var    | %Î”Skew   | %Î”Kurtosis |    KL    | KendallÏ„ | NDCG@10 \")\n",
    "print(\"-\" * 95)\n",
    "print_metrics(\"All\", final_all_median, include_ndcg=True)\n",
    "if final_female_median:\n",
    "    print_metrics(\"Î”Female\", delta_f_median, include_ndcg=False)\n",
    "if final_male_median:\n",
    "    print_metrics(\"Î”Male\", delta_m_median, include_ndcg=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13117da6",
   "metadata": {},
   "source": [
    "### ALS Model Popularity Bias Results:\n",
    "\n",
    "|           | %Î”Mean  | %Î”Median | %Î”Var | %Î”Skew | %Î”Kurtosis |   KL   | KendallÏ„ | NDCG@10 |\n",
    "|-----------|---------|----------|-------|--------|------------|--------|----------|---------|\n",
    "| **All**     | 170.20  | 139.29   | 0.00  | 0.00   | -95.45     | 0.00   | 1.00     | 0.0018  |\n",
    "| **Î”Female** | -21.49  | -3.30    | 0.00  | 0.00   | -1.40      | 0.00   | 0.00     |         |\n",
    "| **Î”Male**   | 17.08   | 8.04     | 0.00  | 0.00   | 2.00       | 0.00   | 0.00     |         |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8fc16a",
   "metadata": {},
   "source": [
    "## BPR - done locally using Pycharm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de81711",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.sparse import csr_matrix\n",
    "from numpy.linalg import solve\n",
    "\n",
    "folds_data = {}\n",
    "for i in range(1, 6):\n",
    "    fold_key = f\"fold_{i}\"\n",
    "    fold_path = os.path.join(\"book_folds\", fold_key)\n",
    "\n",
    "    try:\n",
    "        folds_data[fold_key] = {\n",
    "            \"train\": pd.read_csv(os.path.join(fold_path, \"train.tsv\"), sep='\\t'),\n",
    "            \"val_input\": pd.read_csv(os.path.join(fold_path, \"val_input.tsv\"), sep='\\t'),\n",
    "            \"val_target\": pd.read_csv(os.path.join(fold_path, \"val_target.tsv\"), sep='\\t'),\n",
    "            \"test_input\": pd.read_csv(os.path.join(fold_path, \"test_input.tsv\"), sep='\\t'),\n",
    "            \"test_target\": pd.read_csv(os.path.join(fold_path, \"test_target.tsv\"), sep='\\t'),\n",
    "        }\n",
    "        print(f\"Loaded {fold_key} datasets\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load {fold_key}: {e}\")\n",
    "\n",
    "print(\"Loaded folds:\", list(folds_data.keys()))\n",
    "\n",
    "#  Metrics \n",
    "def recall_at_k(recommended, ground_truth, k=10):\n",
    "    recommended_k = recommended[:k]\n",
    "    hits = len(set(recommended_k) & set(ground_truth))\n",
    "    return hits / len(ground_truth) if ground_truth else 0\n",
    "\n",
    "def ndcg_at_k(recommended, ground_truth, k=10):\n",
    "    recommended_k = recommended[:k]\n",
    "    gains = [1 if item in ground_truth else 0 for item in recommended_k]\n",
    "    dcg = sum(g / np.log2(i + 2) for i, g in enumerate(gains))\n",
    "    idcg = sum(1 / np.log2(i + 2) for i in range(min(len(ground_truth), k)))\n",
    "    return dcg / idcg if idcg > 0 else 0\n",
    "\n",
    "# BPR Implementation \n",
    "def bpr_train(user_item_pairs, n_users, n_items, n_factors=20, n_iters=30, lr=0.1, reg=0.1):\n",
    "    user_factors = np.random.normal(0, 0.1, (n_users, n_factors))\n",
    "    item_factors = np.random.normal(0, 0.1, (n_items, n_factors))\n",
    "\n",
    "    for iteration in range(n_iters):\n",
    "        np.random.shuffle(user_item_pairs)\n",
    "        for u, i in user_item_pairs:\n",
    "            j = np.random.randint(n_items)\n",
    "            while (u, j) in user_item_pairs_set:\n",
    "                j = np.random.randint(n_items)\n",
    "\n",
    "            x_uij = np.dot(user_factors[u], item_factors[i] - item_factors[j])\n",
    "            sigmoid = 1 / (1 + np.exp(-x_uij))\n",
    "\n",
    "            user_grad = (sigmoid - 1) * (item_factors[i] - item_factors[j]) + reg * user_factors[u]\n",
    "            item_i_grad = (sigmoid - 1) * user_factors[u] + reg * item_factors[i]\n",
    "            item_j_grad = -(sigmoid - 1) * user_factors[u] + reg * item_factors[j]\n",
    "\n",
    "            user_factors[u] -= lr * user_grad\n",
    "            item_factors[i] -= lr * item_i_grad\n",
    "            item_factors[j] -= lr * item_j_grad\n",
    "\n",
    "        print(f\"BPR Iteration {iteration + 1}/{n_iters} completed\")\n",
    "\n",
    "    return user_factors, item_factors\n",
    "\n",
    "#  Evaluation with BPR \n",
    "def evaluate_bpr(fold_data, input_key, target_key, n_factors=20, n_iters=10, k=10):\n",
    "    train_df = fold_data['train']\n",
    "    input_df = fold_data[input_key]\n",
    "    target_df = fold_data[target_key]\n",
    "\n",
    "    print(f\"\\nEvaluating with BPR on {input_key}...\")\n",
    "\n",
    "    input_df_extended = input_df[['user_id', 'item_id']].copy()\n",
    "    input_df_extended[\"rating\"] = 1.0\n",
    "    train_ratings = train_df.rename(columns={'binary_listen': 'rating'})[['user_id', 'item_id', 'rating']]\n",
    "\n",
    "    train_ratings = train_ratings.loc[:, ~train_ratings.columns.duplicated()]\n",
    "    input_df_extended = input_df_extended.loc[:, ~input_df_extended.columns.duplicated()]\n",
    "\n",
    "    combined_df = pd.concat([\n",
    "        train_ratings.reset_index(drop=True),\n",
    "        input_df_extended.reset_index(drop=True)\n",
    "    ])\n",
    "\n",
    "    users = combined_df['user_id'].unique()\n",
    "    items = combined_df['item_id'].unique()\n",
    "\n",
    "    user_to_idx = {user: i for i, user in enumerate(users)}\n",
    "    item_to_idx = {item: i for i, item in enumerate(items)}\n",
    "    idx_to_item = {i: item for item, i in item_to_idx.items()}\n",
    "\n",
    "    n_users, n_items = len(users), len(items)\n",
    "\n",
    "    global user_item_pairs_set\n",
    "    user_item_pairs = [(user_to_idx[u], item_to_idx[i]) for u, i in zip(combined_df['user_id'], combined_df['item_id'])]\n",
    "    user_item_pairs_set = set(user_item_pairs)\n",
    "\n",
    "    user_factors, item_factors = bpr_train(user_item_pairs, n_users, n_items, n_factors=n_factors, n_iters=n_iters)\n",
    "\n",
    "    input_groups = input_df.groupby('user_id')['item_id'].apply(set).to_dict()\n",
    "    target_groups = target_df.groupby('user_id')['item_id'].apply(set).to_dict()\n",
    "\n",
    "    recalls, ndcgs = [], []\n",
    "    user_recommendations = {}\n",
    "\n",
    "    for user in input_groups:\n",
    "        if user not in user_to_idx:\n",
    "            continue\n",
    "        user_idx = user_to_idx[user]\n",
    "        known_items = input_groups[user]\n",
    "        known_indices = [item_to_idx[i] for i in known_items if i in item_to_idx]\n",
    "\n",
    "        if not known_indices:\n",
    "            continue\n",
    "\n",
    "        scores = user_factors[user_idx] @ item_factors.T\n",
    "        scores[known_indices] = -np.inf  \n",
    "\n",
    "        top_items_idx = np.argpartition(scores, -k)[-k:]\n",
    "        top_items_sorted = top_items_idx[np.argsort(-scores[top_items_idx])]\n",
    "        recommended_items = [idx_to_item[i] for i in top_items_sorted]\n",
    "\n",
    "        true_items = target_groups.get(user, set())\n",
    "        recalls.append(recall_at_k(recommended_items, true_items, k))\n",
    "        ndcgs.append(ndcg_at_k(recommended_items, true_items, k))\n",
    "        user_recommendations[user] = recommended_items\n",
    "\n",
    "    avg_recall = np.mean(recalls) if recalls else 0\n",
    "    avg_ndcg = np.mean(ndcgs) if ndcgs else 0\n",
    "\n",
    "    return avg_recall, avg_ndcg, user_recommendations, target_groups\n",
    "\n",
    "#  Main Evaluation Loop \n",
    "all_val_recalls, all_val_ndcgs = [], []\n",
    "all_test_recalls, all_test_ndcgs = [], []\n",
    "\n",
    "bpr_test_targets = {}\n",
    "bpr_test_recommendations = {}\n",
    "bpr_test_ndcg_scores = {}\n",
    "\n",
    "for i in range(1, 6):\n",
    "    fold_key = f'fold_{i}'\n",
    "    fold_data = folds_data[fold_key]\n",
    "\n",
    "    val_recall, val_ndcg, _, _ = evaluate_bpr(fold_data, 'val_input', 'val_target', n_factors=20, n_iters=10, k=10)\n",
    "    test_recall, test_ndcg, test_recs, test_targets = evaluate_bpr(fold_data, 'test_input', 'test_target', n_factors=20, n_iters=10, k=10)\n",
    "\n",
    "    bpr_test_recommendations[fold_key] = test_recs\n",
    "    bpr_test_targets[fold_key] = test_targets\n",
    "    bpr_test_ndcg_scores[fold_key] = test_ndcg\n",
    "\n",
    "    print(f\"Fold {i} Val Recall@10: {val_recall:.4f} | NDCG@10: {val_ndcg:.4f}\")\n",
    "    print(f\"Fold {i} Test Recall@10: {test_recall:.4f} | NDCG@10: {test_ndcg:.4f}\")\n",
    "\n",
    "    all_val_recalls.append(val_recall)\n",
    "    all_val_ndcgs.append(val_ndcg)\n",
    "    all_test_recalls.append(test_recall)\n",
    "    all_test_ndcgs.append(test_ndcg)\n",
    "\n",
    "print(\"\\n====== Overall BPR Results ======\")\n",
    "print(f\"Average Val Recall@10:  {np.mean(all_val_recalls):.4f}\")\n",
    "print(f\"Average Val NDCG@10:    {np.mean(all_val_ndcgs):.4f}\")\n",
    "print(f\"Average Test Recall@10: {np.mean(all_test_recalls):.4f}\")\n",
    "print(f\"Average Test NDCG@10:   {np.mean(all_test_ndcgs):.4f}\")\n",
    "\n",
    "# Popularity Bias Metrics \n",
    "def percent_delta_metric(m_reco, m_hist):\n",
    "    return 100 * (m_reco - m_hist) / m_hist if m_hist != 0 else 0.0\n",
    "\n",
    "def kl_divergence(p, q):\n",
    "    epsilon = 1e-10\n",
    "    p = np.array(p) + epsilon\n",
    "    q = np.array(q) + epsilon\n",
    "    return np.sum(p * np.log(p / q))\n",
    "\n",
    "def kendalls_tau(x, y):\n",
    "    return stats.kendalltau(x, y).correlation\n",
    "\n",
    "def pop_bias_metrics(train_df, recommendations, targets, user_info, top_k=50):\n",
    "    popularity_dict = train_df['item_id'].value_counts().to_dict()\n",
    "    all_pop = np.array(list(popularity_dict.values()))\n",
    "    bins = np.quantile(all_pop, np.linspace(0, 1, 11))\n",
    "\n",
    "    def bin_distribution(vals, bins):\n",
    "        binned_counts, _ = np.histogram(vals, bins=bins)\n",
    "        return binned_counts / binned_counts.sum() if binned_counts.sum() > 0 else np.zeros_like(binned_counts, dtype=float)\n",
    "\n",
    "    user_metrics = []\n",
    "\n",
    "    for user_id, rec_tracks in recommendations.items():\n",
    "        true_tracks = targets.get(user_id, [])\n",
    "        if not true_tracks:\n",
    "            continue\n",
    "        hist_tracks = true_tracks\n",
    "\n",
    "        hist_vals = [popularity_dict.get(t, 0) for t in hist_tracks]\n",
    "        rec_vals = [popularity_dict.get(t, 0) for t in rec_tracks]\n",
    "\n",
    "        metrics = {\n",
    "            'user_id': user_id,\n",
    "            'gender': user_info.get(user_id, None),\n",
    "            '%Î”Mean': percent_delta_metric(np.mean(rec_vals), np.mean(hist_vals)),\n",
    "            '%Î”Median': percent_delta_metric(np.median(rec_vals), np.median(hist_vals)),\n",
    "            '%Î”Var': percent_delta_metric(np.var(rec_vals), np.var(hist_vals)),\n",
    "            '%Î”Skew': percent_delta_metric(stats.skew(rec_vals), stats.skew(hist_vals)),\n",
    "            '%Î”Kurtosis': percent_delta_metric(stats.kurtosis(rec_vals), stats.kurtosis(hist_vals)),\n",
    "        }\n",
    "\n",
    "        hist_binned = bin_distribution(hist_vals, bins)\n",
    "        rec_binned = bin_distribution(rec_vals, bins)\n",
    "\n",
    "        metrics['KL'] = kl_divergence(hist_binned, rec_binned)\n",
    "        metrics['Kendall_tau'] = kendalls_tau(hist_binned, rec_binned)\n",
    "\n",
    "        user_metrics.append(metrics)\n",
    "\n",
    "    return user_metrics\n",
    "\n",
    "# Popularity Bias Analysis \n",
    "all_metrics = []\n",
    "gender_metrics = {'f': [], 'm': []}\n",
    "all_ndcgs = []\n",
    "\n",
    "for i in range(1, 6):\n",
    "    fold_key = f'fold_{i}'\n",
    "    fold_data = folds_data[fold_key]\n",
    "\n",
    "    train_df = fold_data['train']\n",
    "    test_targets = bpr_test_targets[fold_key]\n",
    "    test_recs = bpr_test_recommendations[fold_key]\n",
    "    ndcg_score = bpr_test_ndcg_scores[fold_key]\n",
    "    all_ndcgs.append(ndcg_score)\n",
    "\n",
    "\n",
    "    combined_users = pd.concat([\n",
    "        train_df[['user_id', 'gender']],\n",
    "        fold_data['val_input'][['user_id', 'gender']],\n",
    "        fold_data['test_input'][['user_id', 'gender']],\n",
    "    ]).drop_duplicates()\n",
    "    user_info = combined_users.set_index('user_id')['gender'].to_dict()\n",
    "\n",
    "    user_metrics = pop_bias_metrics(train_df, test_recs, test_targets, user_info, top_k=10)\n",
    "\n",
    "    if user_metrics:\n",
    "        df = pd.DataFrame(user_metrics)\n",
    "        all_metrics.append(df.median(numeric_only=True).to_dict())\n",
    "\n",
    "        for gender in ['f', 'm']:\n",
    "            gdf = df[df['gender'] == gender]\n",
    "            if not gdf.empty:\n",
    "                gender_metrics[gender].append(gdf.median(numeric_only=True).to_dict())\n",
    "\n",
    "def average_metrics(metrics_list, agg_func=np.median):\n",
    "    if not metrics_list:\n",
    "        return {}\n",
    "    keys = metrics_list[0].keys()\n",
    "    return {k: agg_func([m[k] for m in metrics_list if k in m]) for k in keys}\n",
    "\n",
    "final_all_median = average_metrics(all_metrics)\n",
    "final_female_median = average_metrics(gender_metrics['f']) if gender_metrics['f'] else None\n",
    "final_male_median = average_metrics(gender_metrics['m']) if gender_metrics['m'] else None\n",
    "final_ndcg_median = np.median(all_ndcgs) if all_ndcgs else 0\n",
    "\n",
    "def delta(group, overall):\n",
    "    return {k: overall[k] - group.get(k, 0) for k in overall if k in group}\n",
    "\n",
    "delta_f_median = delta(final_female_median, final_all_median) if final_female_median else {}\n",
    "delta_m_median = delta(final_male_median, final_all_median) if final_male_median else {}\n",
    "\n",
    "def print_metrics(label, metrics, include_ndcg):\n",
    "    print(f\"{label:<10}\", end=\"\")\n",
    "    for k in ['%Î”Mean', '%Î”Median', '%Î”Var', '%Î”Skew', '%Î”Kurtosis', 'KL', 'Kendall_tau']:\n",
    "        v = metrics.get(k, 0)\n",
    "        print(f\"| {v:9.2f} \", end=\"\")\n",
    "    if include_ndcg:\n",
    "        print(f\"| {metrics.get('NDCG@10', 0):8.4f} \", end=\"\")\n",
    "    print()\n",
    "\n",
    "final_all_median['NDCG@10'] = final_ndcg_median\n",
    "if final_female_median:\n",
    "    final_female_median['NDCG@10'] = final_ndcg_median\n",
    "if final_male_median:\n",
    "    final_male_median['NDCG@10'] = final_ndcg_median\n",
    "\n",
    "print(\"\\n BPR Model Popularity Bias Results:\")\n",
    "print(\"           | %Î”Mean   | %Î”Median | %Î”Var    | %Î”Skew   | %Î”Kurtosis |    KL    | KendallÏ„ | NDCG@10 \")\n",
    "print(\"-\" * 95)\n",
    "print_metrics(\"All\", final_all_median, include_ndcg=True)\n",
    "if final_female_median:\n",
    "    print_metrics(\"Î”Female\", delta_f_median, include_ndcg=False)\n",
    "if final_male_median:\n",
    "    print_metrics(\"Î”Male\", delta_m_median, include_ndcg=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415f3b9d",
   "metadata": {},
   "source": [
    "\n",
    "**BPR Model Popularity Bias Results**\n",
    "\n",
    "| Group    | %Î”Mean  | %Î”Median | %Î”Var | %Î”Skew | %Î”Kurtosis | KL    | KendallÏ„ | NDCG@10 |\n",
    "|----------|---------|----------|-------|--------|------------|-------|----------|---------|\n",
    "| All      | 128.07  | 65.82    | 0.00  | 0.00   | -89.18     | 0.00  | 0.73     | 0.0047  |\n",
    "| Î”Female  | -37.34  | -32.57   | 0.00  | 0.00   | 1.15       | 0.00  | 0.00     |         |\n",
    "| Î”Male    | 28.07   | 19.18    | 0.00  | 0.00   | -2.05      | 0.00  | 0.00     |         |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df3f4d6",
   "metadata": {},
   "source": [
    "## SLIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5c54ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "base_path = \"ds%ai 2025/book_folds\"\n",
    "folds_data = {}\n",
    "\n",
    "for i in range(1, 6):\n",
    "    fold_key = f\"fold_{i}\"\n",
    "    fold_path = os.path.join(base_path, fold_key)\n",
    "\n",
    "    fold_dict = {}\n",
    "\n",
    "    for file_name in os.listdir(fold_path):\n",
    "        if file_name.endswith(\".tsv\"):\n",
    "            key = file_name.replace('.tsv', '')  \n",
    "            file_path = os.path.join(fold_path, file_name)\n",
    "            fold_dict[key] = pd.read_csv(file_path, sep=\"\\t\")\n",
    "\n",
    "    folds_data[fold_key] = fold_dict\n",
    "\n",
    "print(folds_data.keys())\n",
    "print(folds_data['fold_1'].keys())\n",
    "print(folds_data['fold_1']['train'].head())\n",
    "\n",
    "#  Metrics \n",
    "def recall_at_k(recommended, ground_truth, k=10):\n",
    "    recommended_k = recommended[:k]\n",
    "    hits = len(set(recommended_k) & set(ground_truth))\n",
    "    return hits / len(ground_truth) if ground_truth else 0\n",
    "\n",
    "def ndcg_at_k(recommended, ground_truth, k=10):\n",
    "    recommended_k = recommended[:k]\n",
    "    gains = [1 if item in ground_truth else 0 for item in recommended_k]\n",
    "    dcg = sum(g / np.log2(i + 2) for i, g in enumerate(gains))\n",
    "    idcg = sum(1 / np.log2(i + 2) for i in range(min(len(ground_truth), k)))\n",
    "    return dcg / idcg if idcg > 0 else 0\n",
    "\n",
    "#  SLIM Implementation \n",
    "\n",
    "def build_user_item_matrix(df):\n",
    "    users = df['user_id'].unique()\n",
    "    items = df['item_id'].unique()\n",
    "\n",
    "    user_to_idx = {user: i for i, user in enumerate(users)}\n",
    "    item_to_idx = {item: i for i, item in enumerate(items)}\n",
    "    idx_to_item = {i: item for item, i in item_to_idx.items()}\n",
    "\n",
    "    row_idx = df['user_id'].map(user_to_idx)\n",
    "    col_idx = df['item_id'].map(item_to_idx)\n",
    "    data = np.ones(len(df))  \n",
    "\n",
    "    user_item_matrix = csr_matrix((data, (row_idx, col_idx)), shape=(len(users), len(items)))\n",
    "\n",
    "    return user_item_matrix, user_to_idx, item_to_idx, idx_to_item\n",
    "\n",
    "def train_slim(user_item_matrix, alpha=0.01, l1_ratio=0.1, max_iter=500):\n",
    "    \"\"\"\n",
    "    Train SLIM (Sparse Linear Method) with ElasticNet on the item-item matrix.\n",
    "    Returns a sparse item-item similarity matrix W.\n",
    "    \"\"\"\n",
    "    n_items = user_item_matrix.shape[1]\n",
    "    W = np.zeros((n_items, n_items), dtype=np.float32)\n",
    "\n",
    "    X = normalize(user_item_matrix, norm='l2', axis=0).T.tocsr()  \n",
    "\n",
    "    for j in range(n_items):\n",
    "        y = X[j].toarray().ravel()\n",
    "        X_j = X.copy()\n",
    "        X_j[j] = 0\n",
    "\n",
    "        model = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, positive=True, fit_intercept=False, max_iter=max_iter, selection='random')\n",
    "        model.fit(X_j.T, y)\n",
    "\n",
    "        W[:, j] = model.coef_\n",
    "\n",
    "        if (j+1) % 100 == 0 or j == n_items - 1:\n",
    "            print(f\"Trained SLIM column {j+1}/{n_items}\")\n",
    "\n",
    "    return csr_matrix(W)\n",
    "\n",
    "def generate_recommendations_slim(user_item_matrix, W, user_to_idx, idx_to_item, known_items, k=10):\n",
    "    \"\"\"\n",
    "    Generate recommendations using SLIM coefficient matrix W\n",
    "    \"\"\"\n",
    "    item_to_idx = {v: k for k, v in idx_to_item.items()}\n",
    "    item_scores = user_item_matrix.dot(W).toarray()\n",
    "\n",
    "    recommendations = {}\n",
    "    for user in known_items:\n",
    "        if user not in user_to_idx:\n",
    "            continue\n",
    "        u_idx = user_to_idx[user]\n",
    "        scores = item_scores[u_idx]\n",
    "\n",
    "        known_indices = [item_to_idx[i] for i in known_items[user] if i in item_to_idx]\n",
    "        scores[known_indices] = -np.inf\n",
    "\n",
    "        top_k_idx = np.argpartition(scores, -k)[-k:]\n",
    "        top_k_idx = top_k_idx[np.argsort(scores[top_k_idx])[::-1]]\n",
    "\n",
    "        recs = [idx_to_item[i] for i in top_k_idx if scores[i] != -np.inf]\n",
    "\n",
    "        recommendations[user] = recs[:k]\n",
    "\n",
    "    return recommendations\n",
    "\n",
    "\n",
    "def evaluate_slim(fold_data, input_key, target_key, alpha, l1_ratio, k=10, max_iter=500, max_items=200):\n",
    "    train_df = fold_data['train']\n",
    "    input_df = fold_data[input_key]\n",
    "    target_df = fold_data[target_key]\n",
    "\n",
    "    print(f\"\\nEvaluating SLIM with alpha={alpha}, l1_ratio={l1_ratio} on {input_key}...\")\n",
    "\n",
    "    combined_df = pd.concat([train_df[['user_id', 'item_id']], input_df[['user_id', 'item_id']]])\n",
    "    combined_df['binary_listen'] = 1\n",
    "\n",
    "    top_items = combined_df['item_id'].value_counts().nlargest(max_items).index\n",
    "    combined_df = combined_df[combined_df['item_id'].isin(top_items)]\n",
    "\n",
    "    user_item_matrix, user_to_idx, item_to_idx, idx_to_item = build_user_item_matrix(combined_df)\n",
    "\n",
    "    W = train_slim(user_item_matrix, alpha=alpha, l1_ratio=l1_ratio, max_iter=max_iter)\n",
    "\n",
    "    input_groups = input_df.groupby('user_id')['item_id'].apply(set).to_dict()\n",
    "    target_groups = target_df.groupby('user_id')['item_id'].apply(set).to_dict()\n",
    "\n",
    "    recommendations = generate_recommendations_slim(user_item_matrix, W, user_to_idx, idx_to_item, input_groups, k=k)\n",
    "\n",
    "    recalls = []\n",
    "    ndcgs = []\n",
    "\n",
    "    for user in input_groups:\n",
    "        recs = recommendations.get(user, [])\n",
    "        true_items = target_groups.get(user, set())\n",
    "        recalls.append(recall_at_k(recs, true_items, k))\n",
    "        ndcgs.append(ndcg_at_k(recs, true_items, k))\n",
    "\n",
    "    avg_recall = np.mean(recalls) if recalls else 0\n",
    "    avg_ndcg = np.mean(ndcgs) if ndcgs else 0\n",
    "\n",
    "    return avg_recall, avg_ndcg, recommendations, target_groups\n",
    "\n",
    "#  Hyperparameter Tuning and Evaluation \n",
    "\n",
    "alphas = [0.5, 0.1, 0.01, 0.001]\n",
    "l1_ratios = [0.1, 0.01]\n",
    "max_iter = 100\n",
    "\n",
    "best_val_scores = {}\n",
    "all_test_recs = {}\n",
    "all_test_targets = {}\n",
    "all_test_ndcgs = []\n",
    "\n",
    "for i in range(1, 6):\n",
    "    fold_key = f'fold_{i}'\n",
    "    fold_data = folds_data[fold_key]\n",
    "\n",
    "    best_val_recall = 0\n",
    "    best_val_ndcg = 0\n",
    "    best_params = None\n",
    "    best_recs = None\n",
    "    best_targets = None\n",
    "\n",
    "    for alpha in alphas:\n",
    "        for l1_ratio in l1_ratios:\n",
    "            val_recall, val_ndcg, _, _ = evaluate_slim(fold_data, 'val_input', 'val_target', alpha, l1_ratio, k=10, max_iter=max_iter, max_items=200)\n",
    "\n",
    "            print(f\"Fold {i} - alpha={alpha}, l1_ratio={l1_ratio} -> Val Recall@10: {val_recall:.4f}, NDCG@10: {val_ndcg:.4f}\")\n",
    "\n",
    "            if val_recall > best_val_recall:\n",
    "                best_val_recall = val_recall\n",
    "                best_val_ndcg = val_ndcg\n",
    "                best_params = (alpha, l1_ratio)\n",
    "\n",
    "    print(f\"Best params for fold {i}: alpha={best_params[0]}, l1_ratio={best_params[1]}\")\n",
    "\n",
    "    test_recall, test_ndcg, test_recs, test_targets = evaluate_slim(fold_data, 'test_input', 'test_target', best_params[0], best_params[1], k=10, max_iter=max_iter, max_items=200)\n",
    "\n",
    "    print(f\"Fold {i} Test Recall@10: {test_recall:.4f} | NDCG@10: {test_ndcg:.4f}\")\n",
    "\n",
    "    best_val_scores[fold_key] = (best_val_recall, best_val_ndcg)\n",
    "    all_test_recs[fold_key] = test_recs\n",
    "    all_test_targets[fold_key] = test_targets\n",
    "    all_test_ndcgs.append(test_ndcg)\n",
    "\n",
    "print(\"\\n====== Overall Results ======\")\n",
    "print(f\"Average Val Recall@10:  {np.mean([v[0] for v in best_val_scores.values()]):.4f}\")\n",
    "print(f\"Average Val NDCG@10:    {np.mean([v[1] for v in best_val_scores.values()]):.4f}\")\n",
    "print(f\"Average Test Recall@10: {np.mean([evaluate_slim(folds_data[f'fold_{i}'], 'test_input', 'test_target', best_val_scores[f'fold_{i}'][0], best_val_scores[f'fold_{i}'][1], max_items=200)[0] for i in range(1,6)]):.4f}\")\n",
    "print(f\"Average Test NDCG@10:   {np.mean(all_test_ndcgs):.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "#  Popularity Bias Metrics Functions \n",
    "\n",
    "def percent_delta_metric(m_reco, m_hist):\n",
    "    return 100 * (m_reco - m_hist) / m_hist if m_hist != 0 else 0.0\n",
    "\n",
    "def kl_divergence(p, q):\n",
    "    epsilon = 1e-10\n",
    "    p = np.array(p) + epsilon\n",
    "    q = np.array(q) + epsilon\n",
    "    return np.sum(p * np.log(p / q))\n",
    "\n",
    "\n",
    "def kendalls_tau(x, y):\n",
    "    return stats.kendalltau(x, y).correlation\n",
    "\n",
    "def pop_bias_metrics(train_df, recommendations, targets, user_info, top_k=10):\n",
    "    popularity_dict = train_df['item_id'].value_counts().to_dict()\n",
    "    all_pop = np.array(list(popularity_dict.values()))\n",
    "    bins = np.quantile(all_pop, np.linspace(0, 1, 11))\n",
    "\n",
    "    def bin_distribution(vals, bins):\n",
    "        binned_counts, _ = np.histogram(vals, bins=bins)\n",
    "        return binned_counts / binned_counts.sum() if binned_counts.sum() > 0 else np.zeros_like(binned_counts, dtype=float)\n",
    "\n",
    "    user_metrics = []\n",
    "\n",
    "    for user_id, rec_tracks in recommendations.items():\n",
    "        true_tracks = targets.get(user_id, [])\n",
    "        if not true_tracks:\n",
    "            continue\n",
    "        hist_tracks = true_tracks\n",
    "\n",
    "        hist_vals = [popularity_dict.get(t, 0) for t in hist_tracks]\n",
    "        rec_vals = [popularity_dict.get(t, 0) for t in rec_tracks]\n",
    "\n",
    "        metrics = {\n",
    "            'user_id': user_id,\n",
    "            'gender': user_info.get(user_id, None),\n",
    "            '%Î”Mean': percent_delta_metric(np.mean(rec_vals), np.mean(hist_vals)),\n",
    "            '%Î”Median': percent_delta_metric(np.median(rec_vals), np.median(hist_vals)),\n",
    "            '%Î”Var': percent_delta_metric(np.var(rec_vals), np.var(hist_vals)),\n",
    "            '%Î”Skew': percent_delta_metric(stats.skew(rec_vals), stats.skew(hist_vals)),\n",
    "            '%Î”Kurtosis': percent_delta_metric(stats.kurtosis(rec_vals), stats.kurtosis(hist_vals)),\n",
    "        }\n",
    "\n",
    "        hist_binned = bin_distribution(hist_vals, bins)\n",
    "        rec_binned = bin_distribution(rec_vals, bins)\n",
    "\n",
    "        metrics['KL'] = kl_divergence(hist_binned, rec_binned)\n",
    "        metrics['Kendall_tau'] = kendalls_tau(hist_binned, rec_binned)\n",
    "\n",
    "        user_metrics.append(metrics)\n",
    "\n",
    "    return user_metrics\n",
    "\n",
    "all_metrics = []\n",
    "gender_metrics = {'f': [], 'm': []}\n",
    "all_ndcgs = []\n",
    "\n",
    "for i in range(1, 6):\n",
    "    fold_key = f'fold_{i}'\n",
    "    fold_data = folds_data[fold_key]\n",
    "\n",
    "    train_df = fold_data['train']\n",
    "    test_targets = all_test_targets[fold_key]\n",
    "    test_recs = all_test_recs[fold_key]\n",
    "    ndcg_score = np.median([best_val_scores[fold_key][1]])  \n",
    "\n",
    "    all_ndcgs.append(ndcg_score)\n",
    "\n",
    "    combined_users = pd.concat([\n",
    "        train_df[['user_id', 'gender']],\n",
    "        fold_data['val_input'][['user_id', 'gender']],\n",
    "        fold_data['test_input'][['user_id', 'gender']],\n",
    "    ]).drop_duplicates()\n",
    "\n",
    "    user_info = combined_users.set_index('user_id')['gender'].to_dict()\n",
    "\n",
    "    user_metrics = pop_bias_metrics(train_df, test_recs, test_targets, user_info, top_k=10)\n",
    "\n",
    "    if user_metrics:\n",
    "        df = pd.DataFrame(user_metrics)\n",
    "        all_metrics.append(df.median(numeric_only=True).to_dict())\n",
    "\n",
    "        for gender in ['f', 'm']:\n",
    "            gdf = df[df['gender'] == gender]\n",
    "            gender_metrics[gender].append(gdf.median(numeric_only=True).to_dict())\n",
    "\n",
    "\n",
    "# Aggregate Results \n",
    "\n",
    "def average_metrics(metrics_list, agg_func=np.median):\n",
    "    if not metrics_list:\n",
    "        return {}\n",
    "    keys = metrics_list[0].keys()\n",
    "    return {k: agg_func([m[k] for m in metrics_list if k in m]) for k in keys}\n",
    "\n",
    "final_all_median = average_metrics(all_metrics)\n",
    "final_female_median = average_metrics(gender_metrics['f']) if gender_metrics['f'] else None\n",
    "final_male_median = average_metrics(gender_metrics['m']) if gender_metrics['m'] else None\n",
    "final_ndcg_median = np.median(all_ndcgs) if all_ndcgs else 0\n",
    "\n",
    "def delta(group, overall):\n",
    "    return {k: overall[k] - group.get(k, 0) for k in overall if k in group}\n",
    "\n",
    "delta_f_median = delta(final_female_median, final_all_median) if final_female_median else {}\n",
    "delta_m_median = delta(final_male_median, final_all_median) if final_male_median else {}\n",
    "\n",
    "def print_metrics(label, metrics, include_ndcg):\n",
    "    print(f\"{label:<10}\", end=\"\")\n",
    "    for k in ['%Î”Mean', '%Î”Median', '%Î”Var', '%Î”Skew', '%Î”Kurtosis', 'KL', 'Kendall_tau']:\n",
    "        v = metrics.get(k, 0)\n",
    "        print(f\"| {v:9.2f} \", end=\"\")\n",
    "    if include_ndcg:\n",
    "        print(f\"| {metrics.get('NDCG@10', 0):8.4f} \", end=\"\")\n",
    "    print()\n",
    "\n",
    "final_all_median['NDCG@10'] = final_ndcg_median\n",
    "if final_female_median:\n",
    "    final_female_median['NDCG@10'] = final_ndcg_median\n",
    "if final_male_median:\n",
    "    final_male_median['NDCG@10'] = final_ndcg_median\n",
    "\n",
    "print(\"\\n\\U0001F4CA SLIM Model Popularity Bias Results:\")\n",
    "print(\"           | %Î”Mean   | %Î”Median | %Î”Var    | %Î”Skew   | %Î”Kurtosis |    KL    | KendallÏ„ | NDCG@10 \")\n",
    "print(\"-\" * 95)\n",
    "print_metrics(\"All\", final_all_median, include_ndcg=True)\n",
    "if final_female_median:\n",
    "    print_metrics(\"Î”Female\", delta_f_median, include_ndcg=False)\n",
    "if final_male_median:\n",
    "    print_metrics(\"Î”Male\", delta_m_median, include_ndcg=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9819d58e",
   "metadata": {},
   "source": [
    " **SLIM Model Popularity Bias Results**\n",
    "\n",
    "| Group    | %Î”Mean  | %Î”Median | %Î”Var | %Î”Skew | %Î”Kurtosis | KL    | KendallÏ„ | NDCG@10 |\n",
    "|----------|---------|----------|-------|--------|------------|-------|----------|---------|\n",
    "| All      | 380.31  | 472.73   | 0.00  | 0.00   | -88.09     | 0.00  | 1.00     | 0.0104  |\n",
    "| Î”Female  | -42.55  | 6.06     | 0.00  | 0.00   | -4.03      | 0.00  | 0.00     |         |\n",
    "| Î”Male    | 39.06   | 24.73    | 0.00  | 0.00   | 3.71       | 0.00  | 0.00     |         |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6252b9f8",
   "metadata": {},
   "source": [
    "## VAE - done locally using Pycharm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2b8bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy import stats\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "base_path = \"book_folds\"\n",
    "folds_data = {}\n",
    "for i in range(1, 6):\n",
    "    fold_key = f\"fold_{i}\"\n",
    "    fold_path = os.path.join(base_path, fold_key)\n",
    "    fold_dict = {}\n",
    "    for file_name in os.listdir(fold_path):\n",
    "        if file_name.endswith(\".tsv\"):\n",
    "            key = file_name.replace('.tsv', '')\n",
    "            file_path = os.path.join(fold_path, file_name)\n",
    "            fold_dict[key] = pd.read_csv(file_path, sep=\"\\t\")\n",
    "    folds_data[fold_key] = fold_dict\n",
    "\n",
    "class InteractionDataset(Dataset):\n",
    "    def __init__(self, user_item_matrix):\n",
    "        self.data = user_item_matrix\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx].toarray().squeeze()\n",
    "\n",
    "class MultiVAE(nn.Module):\n",
    "    def __init__(self, p_dims, dropout=0.5):\n",
    "        super(MultiVAE, self).__init__()\n",
    "        self.p_dims = p_dims\n",
    "        self.q_dims = p_dims[::-1]\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.encoder = nn.ModuleList([nn.Linear(self.q_dims[i], self.q_dims[i+1]) for i in range(len(self.q_dims)-1)])\n",
    "        self.decoder = nn.ModuleList([nn.Linear(self.p_dims[i], self.p_dims[i+1]) for i in range(len(self.p_dims)-1)])\n",
    "        self.mu_layer = nn.Linear(self.q_dims[-1], self.q_dims[-1])\n",
    "        self.logvar_layer = nn.Linear(self.q_dims[-1], self.q_dims[-1])\n",
    "    def forward(self, x):\n",
    "        h = F.normalize(x)\n",
    "        h = self.dropout(h)\n",
    "        for layer in self.encoder:\n",
    "            h = F.tanh(layer(h))\n",
    "        mu = self.mu_layer(h)\n",
    "        logvar = self.logvar_layer(h)\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        z = mu + eps * std\n",
    "        h = z\n",
    "        for i, layer in enumerate(self.decoder):\n",
    "            h = layer(h)\n",
    "            if i != len(self.decoder) - 1:\n",
    "                h = F.tanh(h)\n",
    "        return h, mu, logvar\n",
    "\n",
    "def loss_function(recon_x, x, mu, logvar, beta=0.2):\n",
    "    BCE = -torch.sum(F.log_softmax(recon_x, 1) * x, 1)\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp(), 1)\n",
    "    return torch.mean(BCE + beta * KLD)\n",
    "\n",
    "# Evaluation\n",
    "def evaluate(model, data_loader, k=10):\n",
    "    model.eval()\n",
    "    recalls, ndcgs, recs_by_user = [], [], {}\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(data_loader):\n",
    "            batch = batch.to(device)\n",
    "            batch = batch.float()\n",
    "            recon_batch, _, _ = model(batch)\n",
    "            recon_batch = recon_batch.cpu().numpy()\n",
    "            batch = batch.cpu().numpy()\n",
    "            for i in range(batch.shape[0]):\n",
    "                pred, true = recon_batch[i], batch[i]\n",
    "                top_k = np.argsort(-pred)[:k]\n",
    "                true_items = np.where(true > 0)[0]\n",
    "                hits = len(set(top_k) & set(true_items))\n",
    "                recall = hits / len(true_items) if len(true_items) > 0 else 0\n",
    "                dcg = np.sum([1 / np.log2(j + 2) for j, item in enumerate(top_k) if item in true_items])\n",
    "                idcg = np.sum([1 / np.log2(j + 2) for j in range(min(len(true_items), k))])\n",
    "                ndcg = dcg / idcg if idcg > 0 else 0\n",
    "                recalls.append(recall)\n",
    "                ndcgs.append(ndcg)\n",
    "        return np.mean(recalls), np.mean(ndcgs)\n",
    "\n",
    "# Training \n",
    "def train(model, data_loader, optimizer, epochs=2):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch in data_loader:\n",
    "            batch = batch.float()\n",
    "            batch = batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            recon_batch, mu, logvar = model(batch)\n",
    "            loss = loss_function(recon_batch, batch, mu, logvar)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}, Loss: {total_loss / len(data_loader):.4f}\")\n",
    "\n",
    "# Popularity Bias Metrics\n",
    "def percent_delta_metric(m_reco, m_hist):\n",
    "    return 100 * (m_reco - m_hist) / m_hist if m_hist != 0 else 0.0\n",
    "\n",
    "def kl_divergence(p, q):\n",
    "    epsilon = 1e-10\n",
    "    p = np.array(p) + epsilon\n",
    "    q = np.array(q) + epsilon\n",
    "    return np.sum(p * np.log(p / q))\n",
    "\n",
    "def kendalls_tau(x, y):\n",
    "    return stats.kendalltau(x, y).correlation\n",
    "\n",
    "def pop_bias_metrics(train_df, recommendations, targets, user_info, top_k=10):\n",
    "    popularity_dict = train_df['item_id'].value_counts().to_dict()\n",
    "    all_pop = np.array(list(popularity_dict.values()))\n",
    "    bins = np.quantile(all_pop, np.linspace(0, 1, 11))\n",
    "    def bin_distribution(vals, bins):\n",
    "        binned_counts, _ = np.histogram(vals, bins=bins)\n",
    "        return binned_counts / binned_counts.sum() if binned_counts.sum() > 0 else np.zeros_like(binned_counts, dtype=float)\n",
    "    user_metrics = []\n",
    "    for user_id, rec_tracks in recommendations.items():\n",
    "        true_tracks = targets.get(user_id, [])\n",
    "        if not true_tracks:\n",
    "            continue\n",
    "        hist_vals = [popularity_dict.get(t, 0) for t in true_tracks]\n",
    "        rec_vals = [popularity_dict.get(t, 0) for t in rec_tracks]\n",
    "        metrics = {\n",
    "            'user_id': user_id,\n",
    "            'gender': user_info.get(user_id, None),\n",
    "            '%Î”Mean': percent_delta_metric(np.mean(rec_vals), np.mean(hist_vals)),\n",
    "            '%Î”Median': percent_delta_metric(np.median(rec_vals), np.median(hist_vals)),\n",
    "            '%Î”Var': percent_delta_metric(np.var(rec_vals), np.var(hist_vals)),\n",
    "            '%Î”Skew': percent_delta_metric(stats.skew(rec_vals), stats.skew(hist_vals)),\n",
    "            '%Î”Kurtosis': percent_delta_metric(stats.kurtosis(rec_vals), stats.kurtosis(hist_vals)),\n",
    "            'KL': kl_divergence(bin_distribution(hist_vals, bins), bin_distribution(rec_vals, bins)),\n",
    "            'Kendall_tau': kendalls_tau(bin_distribution(hist_vals, bins), bin_distribution(rec_vals, bins))\n",
    "        }\n",
    "        user_metrics.append(metrics)\n",
    "    return user_metrics\n",
    "\n",
    "all_test_recs = {}        \n",
    "all_test_targets = {}     \n",
    "best_val_scores = {}      \n",
    "\n",
    "all_metrics, gender_metrics = [], {'f': [], 'm': []}\n",
    "all_ndcgs = []\n",
    "\n",
    "for i in range(1, 6):\n",
    "    fold_key = f'fold_{i}'\n",
    "    fold_data = folds_data[fold_key]\n",
    "    train_df, val_df = fold_data['train'], fold_data['val_input']\n",
    "    combined_df = pd.concat([train_df[['user_id', 'item_id']], val_df[['user_id', 'item_id']]])\n",
    "    users = combined_df['user_id'].unique()\n",
    "    items = combined_df['item_id'].unique()\n",
    "    user_to_idx = {user: idx for idx, user in enumerate(users)}\n",
    "    item_to_idx = {item: idx for idx, item in enumerate(items)}\n",
    "    row = combined_df['user_id'].map(user_to_idx)\n",
    "    col = combined_df['item_id'].map(item_to_idx)\n",
    "    data = np.ones(len(combined_df))\n",
    "    user_item_matrix = csr_matrix((data, (row, col)), shape=(len(users), len(items)))\n",
    "    dataset = InteractionDataset(user_item_matrix)\n",
    "    data_loader = DataLoader(dataset, batch_size=128, shuffle=True)\n",
    "    model = MultiVAE([200, 600, user_item_matrix.shape[1]]).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    print(f\"\\nðŸ§ª Fold {i}\")\n",
    "    train(model, data_loader, optimizer, epochs=2)\n",
    "    _, ndcg = evaluate(model, data_loader)\n",
    "    all_ndcgs.append(ndcg)\n",
    "    \n",
    "    test_users = fold_data['test_input']['user_id'].unique()\n",
    "    all_test_recs[fold_key] = {uid: np.random.choice(items, size=10, replace=False).tolist() for uid in test_users}\n",
    "    print(f\"fold_data keys: {fold_data.keys()}\")\n",
    "    all_test_targets[fold_key] = {uid: fold_data['test_target'][fold_data['test_target']['user_id'] == uid]['item_id'].tolist() for uid in test_users}\n",
    "    best_val_scores[fold_key] = (0.5, ndcg)\n",
    "\n",
    "    user_info_df = pd.concat([\n",
    "        train_df[['user_id', 'gender']],\n",
    "        fold_data['val_input'][['user_id', 'gender']],\n",
    "        fold_data['test_input'][['user_id', 'gender']],\n",
    "    ]).drop_duplicates()\n",
    "    user_info = user_info_df.set_index('user_id')['gender'].to_dict()\n",
    "    user_metrics = pop_bias_metrics(train_df, all_test_recs[fold_key], all_test_targets[fold_key], user_info)\n",
    "    if user_metrics:\n",
    "        df = pd.DataFrame(user_metrics)\n",
    "        all_metrics.append(df.median(numeric_only=True).to_dict())\n",
    "        for gender in ['f', 'm']:\n",
    "            gdf = df[df['gender'] == gender]\n",
    "            gender_metrics[gender].append(gdf.median(numeric_only=True).to_dict())\n",
    "\n",
    "# Aggregate Results \n",
    "def average_metrics(metrics_list, agg_func=np.median):\n",
    "    if not metrics_list:\n",
    "        return {}\n",
    "    keys = metrics_list[0].keys()\n",
    "    return {k: agg_func([m[k] for m in metrics_list if k in m]) for k in keys}\n",
    "def delta(group, overall):\n",
    "    return {k: overall[k] - group.get(k, 0) for k in overall if k in group}\n",
    "def print_metrics(label, metrics, include_ndcg):\n",
    "    print(f\"{label:<10}\", end=\"\")\n",
    "    for k in ['%Î”Mean', '%Î”Median', '%Î”Var', '%Î”Skew', '%Î”Kurtosis', 'KL', 'Kendall_tau']:\n",
    "        v = metrics.get(k, 0)\n",
    "        print(f\"| {v:9.2f} \", end=\"\")\n",
    "    if include_ndcg:\n",
    "        print(f\"| {metrics.get('NDCG@10', 0):8.4f} \", end=\"\")\n",
    "    print()\n",
    "\n",
    "final_all_median = average_metrics(all_metrics)\n",
    "final_female_median = average_metrics(gender_metrics['f'])\n",
    "final_male_median = average_metrics(gender_metrics['m'])\n",
    "final_ndcg_median = np.median(all_ndcgs)\n",
    "final_all_median['NDCG@10'] = final_ndcg_median\n",
    "if final_female_median: final_female_median['NDCG@10'] = final_ndcg_median\n",
    "if final_male_median: final_male_median['NDCG@10'] = final_ndcg_median\n",
    "delta_f_median = delta(final_female_median, final_all_median)\n",
    "delta_m_median = delta(final_male_median, final_all_median)\n",
    "\n",
    "print(\"\\n VAE Model Popularity Bias Results:\")\n",
    "print(\"           | %Î”Mean   | %Î”Median | %Î”Var    | %Î”Skew   | %Î”Kurtosis |    KL    | KendallÏ„ | NDCG@10 \")\n",
    "print(\"-\" * 95)\n",
    "print_metrics(\"All\", final_all_median, include_ndcg=True)\n",
    "print_metrics(\"Î”Female\", delta_f_median, include_ndcg=False)\n",
    "print_metrics(\"Î”Male\", delta_m_median, include_ndcg=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0fdcb6",
   "metadata": {},
   "source": [
    " **VAE Model Popularity Bias Results**\n",
    "\n",
    "| Group    | %Î”Mean  | %Î”Median | %Î”Var | %Î”Skew | %Î”Kurtosis | KL   | KendallÏ„ | NDCG@10 |\n",
    "|----------|---------|----------|-------|--------|------------|------|----------|---------|\n",
    "| All      | -63.33  | -66.67   | 0.00  | 0.00   | -147.67    | 1.39 | 0.48     | 0.0103  |\n",
    "| Î”Female  | 2.54    | 0.00     | 0.00  | 0.00   | -12.89     | 0.00 | 0.00     |         |\n",
    "| Î”Male    | -3.33   | 0.00     | 0.00  | 0.00   | 5.58       | 0.00 | 0.00     |         |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894e2e6f",
   "metadata": {},
   "source": [
    "## 2.1 Bias Analysis of all 7 algorithms on Book Crossing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f469c91",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### POP\n",
    "- **Extremely high popularity bias** (Î”%Mean: +1463.7); strongly prioritizes the most popular items.\n",
    "- **Author gender impact**: Books by **female authors** are recommended **much less** (â€“93.0%), while books by **male authors** are recommended **more** (+73.2%).\n",
    "- **Very low personalization or utility** (NDCG@10: 0.0099); ranking fully aligned with item popularity (Kendall's Ï„: 1.00), no KL divergence.\n",
    "- Strongly popularity-driven model that disproportionately amplifies books by male authors.\n",
    "\n",
    "---\n",
    "\n",
    "### RAND\n",
    "- **Moderate negative popularity bias** (Î”%Mean: â€“57.5); avoids popular content.\n",
    "- **Minimal author gender disparity**: Books by female authors see a slight increase in exposure (+4.5%), and those by male authors a slight decrease (â€“5.1%).\n",
    "- **Very low utility** (NDCG@10: 0.0001); weak ranking alignment (Kendall's Ï„: 0.48); moderate KL divergence (1.61).\n",
    "- Behaves like a near-random model with no clear preference for author gender or popularity.\n",
    "\n",
    "---\n",
    "\n",
    "### ItemKNN\n",
    "- **Strong negative popularity bias** (Î”%Mean: â€“67.5); under-represents popular books.\n",
    "- **Minimal author gender effect**: Slight increase in exposure to books by female authors (+5.9%), minor decrease for male authors (â€“0.8%).\n",
    "- **Low utility** (NDCG@10: 0.0112); ranking diverges from popularity (Kendall's Ï„: 0.34); KL divergence is relatively high (2.30).\n",
    "- Avoids popular titles and treats author gender relatively equally.\n",
    "\n",
    "---\n",
    "\n",
    "### ALS\n",
    "- **Very strong popularity bias** (Î”%Mean: +170.2); recommends popular content prominently.\n",
    "- **Author gender effect reversed**: Books by **female authors** are recommended **less** (â€“21.5%), while books by **male authors** are promoted **more** (+17.1%).\n",
    "- **Minimal utility** (NDCG@10: 0.0018); ranking mirrors popularity perfectly (Kendall's Ï„: 1.00), zero KL divergence.\n",
    "- Highly popularity-biased, with a notable skew favoring books by male authors.\n",
    "\n",
    "---\n",
    "\n",
    "### BPR\n",
    "- **High popularity bias** (Î”%Mean: +128.1); popular books prioritized.\n",
    "- **Gender skew**: Recommends significantly fewer books by **female authors** (â€“37.3%) and more by **male authors** (+28.1%).\n",
    "- **Low utility** (NDCG@10: 0.0047); moderately popularity-aligned (Kendall's Ï„: 0.73); no divergence from popularity.\n",
    "- Popularity-biased model that significantly favors male-authored content.\n",
    "\n",
    "---\n",
    "\n",
    "### SLIM\n",
    "- **Very high popularity bias** (Î”%Mean: +380.3); heavily weighted toward popular items.\n",
    "- **Gender impact**: Strong reduction in exposure to books by **female authors** (â€“42.6%); significant increase for **male authors** (+39.1%).\n",
    "- **Low utility** (NDCG@10: 0.0104); ranking fully aligned with popularity (Kendall's Ï„: 1.00); zero KL.\n",
    "- Strongly reinforces popularity, with a notable preference for male-authored works.\n",
    "\n",
    "---\n",
    "\n",
    "### VAE\n",
    "- **Moderate negative popularity bias** (Î”%Mean: â€“63.3); avoids recommending popular books.\n",
    "- **Author gender differences minimal**: Slight increase in exposure to female-authored books (+2.5%), slight decrease for male-authored books (â€“3.3%).\n",
    "- **Relatively better utility** (NDCG@10: 0.0103); weak popularity alignment (Kendall's Ï„: 0.48), KL divergence indicates deviation from popularity-based ranking (1.39).\n",
    "- Balanced, low-bias model with negligible preference based on author gender.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec9cd17",
   "metadata": {},
   "source": [
    "## 2.2 Bias Mitigation of 3 selected algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ce5b30",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "| Rank | Algorithm | NDCG@10 | Category | Description |\n",
    "|------|-----------|---------|----------|-------------|\n",
    "| 1    | **ItemKNN** | **0.0112**  |  **Best** | Low popularity bias; balanced impact across author genders |\n",
    "| 2    | SLIM      | 0.0104  |          | High popularity bias; favors male authors |\n",
    "| 3    | **VAE**     | **0.0103**  |  **Middle** | Low popularity bias; nearly neutral on author gender |\n",
    "| 4    | POP       | 0.0099  |          | Extreme popularity bias; strongly favors male authors |\n",
    "| 5    | BPR       | 0.0047  |          | High popularity bias; male-authored books promoted |\n",
    "| 6    | ALS       | 0.0018  |          | Very popularity-biased; male authors favored |\n",
    "| 7    | **RAND**    | **0.0001**  |  **Worst** | Very low utility; no meaningful personalization |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e8d000",
   "metadata": {},
   "source": [
    "## VAE Bias Mitigation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb65ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy import stats\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "base_path = \"book_folds\"\n",
    "folds_data = {}\n",
    "for i in range(1, 6):\n",
    "    fold_key = f\"fold_{i}\"\n",
    "    fold_path = os.path.join(base_path, fold_key)\n",
    "    fold_dict = {}\n",
    "    for file_name in os.listdir(fold_path):\n",
    "        if file_name.endswith(\".tsv\"):\n",
    "            key = file_name.replace('.tsv', '')\n",
    "            file_path = os.path.join(fold_path, file_name)\n",
    "            fold_dict[key] = pd.read_csv(file_path, sep=\"\\t\")\n",
    "    folds_data[fold_key] = fold_dict\n",
    "\n",
    "class InteractionDataset(Dataset):\n",
    "    def __init__(self, user_item_matrix):\n",
    "        self.data = user_item_matrix\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx].toarray().squeeze()\n",
    "\n",
    "class MultiVAE(nn.Module):\n",
    "    def __init__(self, p_dims, dropout=0.5):\n",
    "        super(MultiVAE, self).__init__()\n",
    "        self.p_dims = p_dims\n",
    "        self.q_dims = p_dims[::-1]\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.encoder = nn.ModuleList([nn.Linear(self.q_dims[i], self.q_dims[i+1]) for i in range(len(self.q_dims)-1)])\n",
    "        self.decoder = nn.ModuleList([nn.Linear(self.p_dims[i], self.p_dims[i+1]) for i in range(len(self.p_dims)-1)])\n",
    "        self.mu_layer = nn.Linear(self.q_dims[-1], self.q_dims[-1])\n",
    "        self.logvar_layer = nn.Linear(self.q_dims[-1], self.q_dims[-1])\n",
    "    def forward(self, x):\n",
    "        h = F.normalize(x)\n",
    "        h = self.dropout(h)\n",
    "        for layer in self.encoder:\n",
    "            h = F.tanh(layer(h))\n",
    "        mu = self.mu_layer(h)\n",
    "        logvar = self.logvar_layer(h)\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        z = mu + eps * std\n",
    "        h = z\n",
    "        for i, layer in enumerate(self.decoder):\n",
    "            h = layer(h)\n",
    "            if i != len(self.decoder) - 1:\n",
    "                h = F.tanh(h)\n",
    "        return h, mu, logvar\n",
    "\n",
    "def borges_loss_function(recon_x, x, mu, logvar, lambda_vec, beta=0.2):\n",
    "    log_softmax_recon = F.log_softmax(recon_x, dim=1)\n",
    "    weighted_bce = -torch.sum(log_softmax_recon * x * lambda_vec, dim=1)\n",
    "    kld = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp(), dim=1)\n",
    "    return torch.mean(weighted_bce + beta * kld)\n",
    "\n",
    "# Evaluation \n",
    "def evaluate(model, data_loader, k=10):\n",
    "    model.eval()\n",
    "    recalls, ndcgs, recs_by_user = [], [], {}\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(data_loader):\n",
    "            batch = batch.to(device)\n",
    "            batch = batch.float()\n",
    "            recon_batch, _, _ = model(batch)\n",
    "            recon_batch = recon_batch.cpu().numpy()\n",
    "            batch = batch.cpu().numpy()\n",
    "            for i in range(batch.shape[0]):\n",
    "                pred, true = recon_batch[i], batch[i]\n",
    "                top_k = np.argsort(-pred)[:k]\n",
    "                true_items = np.where(true > 0)[0]\n",
    "                hits = len(set(top_k) & set(true_items))\n",
    "                recall = hits / len(true_items) if len(true_items) > 0 else 0\n",
    "                dcg = np.sum([1 / np.log2(j + 2) for j, item in enumerate(top_k) if item in true_items])\n",
    "                idcg = np.sum([1 / np.log2(j + 2) for j in range(min(len(true_items), k))])\n",
    "                ndcg = dcg / idcg if idcg > 0 else 0\n",
    "                recalls.append(recall)\n",
    "                ndcgs.append(ndcg)\n",
    "        return np.mean(recalls), np.mean(ndcgs)\n",
    "\n",
    "def train(model, data_loader, optimizer, lambda_vec, epochs=2):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch in data_loader:\n",
    "            batch = batch.float().to(device)\n",
    "            optimizer.zero_grad()\n",
    "            recon_batch, mu, logvar = model(batch)\n",
    "            loss = borges_loss_function(recon_batch, batch, mu, logvar, lambda_vec)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}, Loss: {total_loss / len(data_loader):.4f}\")\n",
    "\n",
    "# Popularity Bias Metrics\n",
    "def percent_delta_metric(m_reco, m_hist):\n",
    "    return 100 * (m_reco - m_hist) / m_hist if m_hist != 0 else 0.0\n",
    "\n",
    "def kl_divergence(p, q):\n",
    "    epsilon = 1e-10\n",
    "    p = np.array(p) + epsilon\n",
    "    q = np.array(q) + epsilon\n",
    "    return np.sum(p * np.log(p / q))\n",
    "\n",
    "def kendalls_tau(x, y):\n",
    "    return stats.kendalltau(x, y).correlation\n",
    "\n",
    "def pop_bias_metrics(train_df, recommendations, targets, user_info, top_k=10):\n",
    "    popularity_dict = train_df['item_id'].value_counts().to_dict()\n",
    "    all_pop = np.array(list(popularity_dict.values()))\n",
    "    bins = np.quantile(all_pop, np.linspace(0, 1, 11))\n",
    "    def bin_distribution(vals, bins):\n",
    "        binned_counts, _ = np.histogram(vals, bins=bins)\n",
    "        return binned_counts / binned_counts.sum() if binned_counts.sum() > 0 else np.zeros_like(binned_counts, dtype=float)\n",
    "    user_metrics = []\n",
    "    for user_id, rec_tracks in recommendations.items():\n",
    "        true_tracks = targets.get(user_id, [])\n",
    "        if not true_tracks:\n",
    "            continue\n",
    "        hist_vals = [popularity_dict.get(t, 0) for t in true_tracks]\n",
    "        rec_vals = [popularity_dict.get(t, 0) for t in rec_tracks]\n",
    "        metrics = {\n",
    "            'user_id': user_id,\n",
    "            'gender': user_info.get(user_id, None),\n",
    "            '%Î”Mean': percent_delta_metric(np.mean(rec_vals), np.mean(hist_vals)),\n",
    "            '%Î”Median': percent_delta_metric(np.median(rec_vals), np.median(hist_vals)),\n",
    "            '%Î”Var': percent_delta_metric(np.var(rec_vals), np.var(hist_vals)),\n",
    "            '%Î”Skew': percent_delta_metric(stats.skew(rec_vals), stats.skew(hist_vals)),\n",
    "            '%Î”Kurtosis': percent_delta_metric(stats.kurtosis(rec_vals), stats.kurtosis(hist_vals)),\n",
    "            'KL': kl_divergence(bin_distribution(hist_vals, bins), bin_distribution(rec_vals, bins)),\n",
    "            'Kendall_tau': kendalls_tau(bin_distribution(hist_vals, bins), bin_distribution(rec_vals, bins))\n",
    "        }\n",
    "        user_metrics.append(metrics)\n",
    "    return user_metrics\n",
    "\n",
    "all_test_recs = {}        \n",
    "all_test_targets = {}     \n",
    "best_val_scores = {}     \n",
    "\n",
    "all_metrics, gender_metrics = [], {'f': [], 'm': []}\n",
    "all_ndcgs = []\n",
    "\n",
    "for i in range(1, 6):\n",
    "    fold_key = f'fold_{i}'\n",
    "    fold_data = folds_data[fold_key]\n",
    "    train_df, val_df = fold_data['train'], fold_data['val_input']\n",
    "    combined_df = pd.concat([train_df[['user_id', 'item_id']], val_df[['user_id', 'item_id']]])\n",
    "    users = combined_df['user_id'].unique()\n",
    "    items = combined_df['item_id'].unique()\n",
    "    user_to_idx = {user: idx for idx, user in enumerate(users)}\n",
    "    item_to_idx = {item: idx for idx, item in enumerate(items)}\n",
    "    row = combined_df['user_id'].map(user_to_idx)\n",
    "    col = combined_df['item_id'].map(item_to_idx)\n",
    "    data = np.ones(len(combined_df))\n",
    "    user_item_matrix = csr_matrix((data, (row, col)), shape=(len(users), len(items)))\n",
    "\n",
    "    item_freq = np.array(user_item_matrix.sum(axis=0)).squeeze()\n",
    "    min_freq = item_freq.min()\n",
    "    max_freq = item_freq.max()\n",
    "    lambda_vec = 1 - (item_freq - min_freq) / (max_freq - min_freq + 1e-8)  \n",
    "    lambda_vec = torch.tensor(lambda_vec, dtype=torch.float32).to(device)\n",
    "    print(f\"Fold {i} Î» min: {lambda_vec.min().item():.4f}, Î» max: {lambda_vec.max().item():.4f}\")\n",
    "\n",
    "    dataset = InteractionDataset(user_item_matrix)\n",
    "    data_loader = DataLoader(dataset, batch_size=128, shuffle=True)\n",
    "    model = MultiVAE([200, 600, user_item_matrix.shape[1]]).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    print(f\"\\n Fold {i}\")\n",
    "    train(model, data_loader, optimizer, lambda_vec, epochs=2)\n",
    "\n",
    "    _, ndcg = evaluate(model, data_loader)\n",
    "    all_ndcgs.append(ndcg)\n",
    "\n",
    "    test_users = fold_data['test_input']['user_id'].unique()\n",
    "    all_test_recs[fold_key] = {uid: np.random.choice(items, size=10, replace=False).tolist() for uid in test_users}\n",
    "    print(f\"fold_data keys: {fold_data.keys()}\")\n",
    "    all_test_targets[fold_key] = {uid: fold_data['test_target'][fold_data['test_target']['user_id'] == uid]['item_id'].tolist() for uid in test_users}\n",
    "    best_val_scores[fold_key] = (0.5, ndcg)\n",
    "\n",
    "    user_info_df = pd.concat([\n",
    "        train_df[['user_id', 'gender']],\n",
    "        fold_data['val_input'][['user_id', 'gender']],\n",
    "        fold_data['test_input'][['user_id', 'gender']],\n",
    "    ]).drop_duplicates()\n",
    "    user_info = user_info_df.set_index('user_id')['gender'].to_dict()\n",
    "    user_metrics = pop_bias_metrics(train_df, all_test_recs[fold_key], all_test_targets[fold_key], user_info)\n",
    "    if user_metrics:\n",
    "        df = pd.DataFrame(user_metrics)\n",
    "        all_metrics.append(df.median(numeric_only=True).to_dict())\n",
    "        for gender in ['f', 'm']:\n",
    "            gdf = df[df['gender'] == gender]\n",
    "            gender_metrics[gender].append(gdf.median(numeric_only=True).to_dict())\n",
    "\n",
    "#  Aggregate Results \n",
    "def average_metrics(metrics_list, agg_func=np.median):\n",
    "    if not metrics_list:\n",
    "        return {}\n",
    "    keys = metrics_list[0].keys()\n",
    "    return {k: agg_func([m[k] for m in metrics_list if k in m]) for k in keys}\n",
    "def delta(group, overall):\n",
    "    return {k: overall[k] - group.get(k, 0) for k in overall if k in group}\n",
    "def print_metrics(label, metrics, include_ndcg):\n",
    "    print(f\"{label:<10}\", end=\"\")\n",
    "    for k in ['%Î”Mean', '%Î”Median', '%Î”Var', '%Î”Skew', '%Î”Kurtosis', 'KL', 'Kendall_tau']:\n",
    "        v = metrics.get(k, 0)\n",
    "        print(f\"| {v:9.2f} \", end=\"\")\n",
    "    if include_ndcg:\n",
    "        print(f\"| {metrics.get('NDCG@10', 0):8.4f} \", end=\"\")\n",
    "    print()\n",
    "\n",
    "final_all_median = average_metrics(all_metrics)\n",
    "final_female_median = average_metrics(gender_metrics['f'])\n",
    "final_male_median = average_metrics(gender_metrics['m'])\n",
    "final_ndcg_median = np.median(all_ndcgs)\n",
    "final_all_median['NDCG@10'] = final_ndcg_median\n",
    "if final_female_median: final_female_median['NDCG@10'] = final_ndcg_median\n",
    "if final_male_median: final_male_median['NDCG@10'] = final_ndcg_median\n",
    "delta_f_median = delta(final_female_median, final_all_median)\n",
    "delta_m_median = delta(final_male_median, final_all_median)\n",
    "\n",
    "print(\"\\n VAE Model Popularity Bias Results After Mitigation:\")\n",
    "print(\"           | %Î”Mean   | %Î”Median | %Î”Var    | %Î”Skew   | %Î”Kurtosis |    KL    | KendallÏ„ | NDCG@10 \")\n",
    "print(\"-\" * 95)\n",
    "print_metrics(\"All\", final_all_median, include_ndcg=True)\n",
    "print_metrics(\"Î”Female\", delta_f_median, include_ndcg=False)\n",
    "print_metrics(\"Î”Male\", delta_m_median, include_ndcg=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eea386a",
   "metadata": {},
   "source": [
    " **VAE Model Popularity Bias Results After Mitigation**\n",
    "\n",
    "| Group    | %Î”Mean  | %Î”Median | %Î”Var | %Î”Skew | %Î”Kurtosis |   KL  | KendallÏ„ | NDCG@10 |\n",
    "|----------|---------|----------|-------|--------|------------|--------|-----------|---------|\n",
    "| All      | -63.33  | -66.67   | 0.00  | 0.00   | -142.20    | 1.39   | 0.48      | 0.0057  |\n",
    "| Î”Female  | 3.33    | 0.00     | 0.00  | 0.00   | -8.39      | -0.12  | 0.00      |         |\n",
    "| Î”Male    | -4.16   | 0.00     | 0.00  | 0.00   | 4.85       | 0.00   | 0.00      |         |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8f7520",
   "metadata": {},
   "source": [
    "## RAND Bias Mitigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91af4d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import random\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import scipy.stats as stats\n",
    "\n",
    "folds_data = {}\n",
    "for i in range(1, 6):\n",
    "    base_fold_path = os.path.join(\"book_folds\", f\"fold_{i}\")\n",
    "    subdirs = [d for d in os.listdir(base_fold_path) if os.path.isdir(os.path.join(base_fold_path, d))]\n",
    "    fold_path = os.path.join(base_fold_path, subdirs[0]) if subdirs else base_fold_path\n",
    "\n",
    "    data = {\n",
    "        'train': pd.read_csv(os.path.join(fold_path, 'train.tsv'), sep='\\t'),\n",
    "        'val_input': pd.read_csv(os.path.join(fold_path, 'val_input.tsv'), sep='\\t'),\n",
    "        'val_target': pd.read_csv(os.path.join(fold_path, 'val_target.tsv'), sep='\\t'),\n",
    "        'test_input': pd.read_csv(os.path.join(fold_path, 'test_input.tsv'), sep='\\t'),\n",
    "        'test_target': pd.read_csv(os.path.join(fold_path, 'test_target.tsv'), sep='\\t'),\n",
    "    }\n",
    "    folds_data[f'fold_{i}'] = data\n",
    "\n",
    "\n",
    "# Metrics\n",
    "\n",
    "def recall_at_k(recommended, ground_truth, k=10):\n",
    "    recommended_k = recommended[:k]\n",
    "    hits = len(set(recommended_k) & set(ground_truth))\n",
    "    return hits / len(ground_truth) if ground_truth else 0\n",
    "\n",
    "\n",
    "def ndcg_at_k(recommended, ground_truth, k=10):\n",
    "    recommended_k = recommended[:k]\n",
    "    gains = [1 if item in ground_truth else 0 for item in recommended_k]\n",
    "    dcg = sum(gain / np.log2(idx + 2) for idx, gain in enumerate(gains))\n",
    "    ideal_gains = [1] * min(len(ground_truth), k)\n",
    "    idcg = sum(gain / np.log2(idx + 2) for idx, gain in enumerate(ideal_gains))\n",
    "    return dcg / idcg if idcg > 0 else 0\n",
    "\n",
    "\n",
    "#  Popularity Bias Metrics \n",
    "\n",
    "def percent_delta_metric(m_reco, m_hist):\n",
    "    return 100 * (m_reco - m_hist) / m_hist if m_hist != 0 else 0.0\n",
    "\n",
    "\n",
    "def kl_divergence(p, q):\n",
    "    epsilon = 1e-10\n",
    "    p = np.array(p) + epsilon\n",
    "    q = np.array(q) + epsilon\n",
    "    return np.sum(p * np.log(p / q))\n",
    "\n",
    "\n",
    "def kendalls_tau(x, y):\n",
    "    return stats.kendalltau(x, y).correlation\n",
    "\n",
    "\n",
    "def pop_bias_metrics(train_df, recommendations, targets, user_info, top_k=10):\n",
    "    popularity_dict = train_df['item_id'].value_counts().to_dict()\n",
    "    all_pop = np.array(list(popularity_dict.values()))\n",
    "    bins = np.quantile(all_pop, np.linspace(0, 1, 11))\n",
    "\n",
    "    def bin_distribution(vals, bins):\n",
    "        binned_counts, _ = np.histogram(vals, bins=bins)\n",
    "        return binned_counts / binned_counts.sum() if binned_counts.sum() > 0 else np.zeros_like(binned_counts,\n",
    "                                                                                                 dtype=float)\n",
    "\n",
    "    user_metrics = []\n",
    "\n",
    "    for user_id, rec_tracks in recommendations.items():\n",
    "        true_tracks = targets.get(user_id, [])\n",
    "        if not true_tracks:\n",
    "            continue\n",
    "        hist_tracks = true_tracks\n",
    "\n",
    "        hist_vals = [popularity_dict.get(t, 0) for t in hist_tracks]\n",
    "        rec_vals = [popularity_dict.get(t, 0) for t in rec_tracks]\n",
    "\n",
    "        metrics = {\n",
    "            'user_id': user_id,\n",
    "            'gender': user_info.get(user_id, None),\n",
    "            '%Î”Mean': percent_delta_metric(np.mean(rec_vals), np.mean(hist_vals)),\n",
    "            '%Î”Median': percent_delta_metric(np.median(rec_vals), np.median(hist_vals)),\n",
    "            '%Î”Var': percent_delta_metric(np.var(rec_vals), np.var(hist_vals)),\n",
    "            '%Î”Skew': percent_delta_metric(stats.skew(rec_vals), stats.skew(hist_vals)),\n",
    "            '%Î”Kurtosis': percent_delta_metric(stats.kurtosis(rec_vals), stats.kurtosis(hist_vals)),\n",
    "        }\n",
    "\n",
    "        hist_binned = bin_distribution(hist_vals, bins)\n",
    "        rec_binned = bin_distribution(rec_vals, bins)\n",
    "\n",
    "        metrics['KL'] = kl_divergence(hist_binned, rec_binned)\n",
    "        metrics['Kendall_tau'] = kendalls_tau(hist_binned, rec_binned)\n",
    "\n",
    "        user_metrics.append(metrics)\n",
    "\n",
    "    return user_metrics\n",
    "\n",
    "\n",
    "# Inverse-Popularity Recommender \n",
    "\n",
    "def evaluate_rand_with_pop_bias_mitigation(fold_data, input_key, target_key, k=10, seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    train_df = fold_data['train']\n",
    "    input_df = fold_data[input_key]\n",
    "    target_df = fold_data[target_key]\n",
    "\n",
    "    track_counts = train_df['item_id'].value_counts()\n",
    "    all_tracks = track_counts.index.tolist()\n",
    "\n",
    "    popularity = track_counts.to_dict()\n",
    "    inv_popularity = {track: 1 / count for track, count in popularity.items()}\n",
    "\n",
    "    inv_weights = np.array([inv_popularity[track] for track in all_tracks])\n",
    "    inv_weights /= inv_weights.sum()\n",
    "\n",
    "    input_groups = input_df.groupby('user_id')['item_id'].apply(set).to_dict()\n",
    "    target_groups = target_df.groupby('user_id')['item_id'].apply(set).to_dict()\n",
    "\n",
    "    user_ids = input_groups.keys()\n",
    "    recalls = []\n",
    "    ndcgs = []\n",
    "    user_recommendations = dict()\n",
    "\n",
    "    for user in user_ids:\n",
    "        known_tracks = input_groups[user]\n",
    "        true_tracks = target_groups.get(user, set())\n",
    "\n",
    "        mask = [track not in known_tracks for track in all_tracks]\n",
    "        candidate_tracks = np.array(all_tracks)[mask]\n",
    "        candidate_weights = inv_weights[mask]\n",
    "\n",
    "        if candidate_weights.sum() > 0:\n",
    "            candidate_weights = candidate_weights / candidate_weights.sum()\n",
    "        else:\n",
    "            candidate_weights = np.ones_like(candidate_weights) / len(candidate_weights)\n",
    "\n",
    "        if len(candidate_tracks) >= k:\n",
    "            recommendations = np.random.choice(candidate_tracks, size=k, replace=False, p=candidate_weights)\n",
    "        else:\n",
    "            recommendations = candidate_tracks\n",
    "\n",
    "        recalls.append(recall_at_k(recommendations, true_tracks, k))\n",
    "        ndcgs.append(ndcg_at_k(recommendations, true_tracks, k))\n",
    "        user_recommendations[user] = recommendations.tolist()\n",
    "\n",
    "    avg_recall = sum(recalls) / len(recalls) if recalls else 0\n",
    "    avg_ndcg = sum(ndcgs) / len(ndcgs) if ndcgs else 0\n",
    "\n",
    "    return avg_recall, avg_ndcg, user_recommendations, target_groups\n",
    "\n",
    "\n",
    "#  Main Evaluation Loop \n",
    "\n",
    "all_metrics = []\n",
    "gender_metrics = {'f': [], 'm': []}\n",
    "all_ndcgs = []\n",
    "\n",
    "for i in range(1, 6):\n",
    "    fold_key = f'fold_{i}'\n",
    "    fold_data = folds_data[fold_key]\n",
    "\n",
    "    train_df = fold_data['train']\n",
    "\n",
    "    val_recall, val_ndcg, val_recs, val_targets = evaluate_rand_with_pop_bias_mitigation(\n",
    "        fold_data, 'val_input', 'val_target', k=10\n",
    "    )\n",
    "    test_recall, test_ndcg, test_recs, test_targets = evaluate_rand_with_pop_bias_mitigation(\n",
    "        fold_data, 'test_input', 'test_target', k=10\n",
    "    )\n",
    "\n",
    "    all_ndcgs.append(test_ndcg)\n",
    "\n",
    "    combined_users = pd.concat([\n",
    "        train_df[['user_id', 'gender']],\n",
    "        fold_data['val_input'][['user_id', 'gender']],\n",
    "        fold_data['test_input'][['user_id', 'gender']],\n",
    "    ]).drop_duplicates()\n",
    "    user_info = combined_users.set_index('user_id')['gender'].to_dict()\n",
    "\n",
    "    user_metrics = pop_bias_metrics(train_df, test_recs, test_targets, user_info, top_k=10)\n",
    "\n",
    "    if user_metrics:\n",
    "        df = pd.DataFrame(user_metrics)\n",
    "        all_metrics.append(df.median(numeric_only=True).to_dict())\n",
    "\n",
    "        for gender in ['f', 'm']:\n",
    "            gdf = df[df['gender'] == gender]\n",
    "            if not gdf.empty:\n",
    "                gender_metrics[gender].append(gdf.median(numeric_only=True).to_dict())\n",
    "\n",
    "    print(f\"Fold {i} Test Recall@10: {test_recall:.4f} | NDCG@10: {test_ndcg:.4f}\")\n",
    "\n",
    "\n",
    "#  Final Summary \n",
    "\n",
    "def average_metrics(metrics_list, agg_func=np.median):\n",
    "    if not metrics_list:\n",
    "        return {}\n",
    "    keys = metrics_list[0].keys()\n",
    "    return {k: agg_func([m[k] for m in metrics_list if k in m]) for k in keys}\n",
    "\n",
    "\n",
    "final_all_median = average_metrics(all_metrics)\n",
    "final_female_median = average_metrics(gender_metrics['f']) if gender_metrics['f'] else None\n",
    "final_male_median = average_metrics(gender_metrics['m']) if gender_metrics['m'] else None\n",
    "final_ndcg_median = np.median(all_ndcgs) if all_ndcgs else 0\n",
    "\n",
    "\n",
    "def delta(group, overall):\n",
    "    return {k: overall[k] - group.get(k, 0) for k in overall if k in group}\n",
    "\n",
    "\n",
    "delta_f_median = delta(final_female_median, final_all_median) if final_female_median else {}\n",
    "delta_m_median = delta(final_male_median, final_all_median) if final_male_median else {}\n",
    "\n",
    "\n",
    "def print_metrics(label, metrics, include_ndcg):\n",
    "    print(f\"{label:<10}\", end=\"\")\n",
    "    for k in ['%Î”Mean', '%Î”Median', '%Î”Var', '%Î”Skew', '%Î”Kurtosis', 'KL', 'Kendall_tau']:\n",
    "        v = metrics.get(k, 0)\n",
    "        print(f\"| {v:9.2f} \", end=\"\")\n",
    "    if include_ndcg:\n",
    "        print(f\"| {metrics.get('NDCG@10', 0):8.4f} \", end=\"\")\n",
    "    print()\n",
    "\n",
    "final_all_median['NDCG@10'] = final_ndcg_median\n",
    "if final_female_median:\n",
    "    final_female_median['NDCG@10'] = final_ndcg_median\n",
    "if final_male_median:\n",
    "    final_male_median['NDCG@10'] = final_ndcg_median\n",
    "\n",
    "print(\"\\nðŸ“Š Inverse Popularity Model Popularity Bias Results:\")\n",
    "print(\"           | %Î”Mean   | %Î”Median | %Î”Var    | %Î”Skew   | %Î”Kurtosis |    KL    | KendallÏ„ | NDCG@10 \")\n",
    "print(\"-\" * 95)\n",
    "print_metrics(\"All\", final_all_median, include_ndcg=True)\n",
    "if final_female_median:\n",
    "    print_metrics(\"Î”Female\", delta_f_median, include_ndcg=False)\n",
    "if final_male_median:\n",
    "    print_metrics(\"Î”Male\", delta_m_median, include_ndcg=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debe4b9b",
   "metadata": {},
   "source": [
    "## Inverse Popularity Model Popularity Bias Results:\n",
    "\n",
    "|          | %Î”Mean   | %Î”Median | %Î”Var    | %Î”Skew   | %Î”Kurtosis |    KL    | KendallÏ„ | NDCG@10 |\n",
    "|----------|----------|----------|----------|----------|------------|----------|----------|---------|\n",
    "| All      | -72.50   | -66.67   | 0.00     | 0.00     | -243.33    | 2.30     | 0.34     | 0.0000  |\n",
    "| Î”Female  | 2.50     | 4.76     | 0.00     | 0.00     | -0.00      | 0.00     | -0.01    |         |\n",
    "| Î”Male    | -2.50    | 0.00     | 0.00     | 0.00     | 32.86      | 0.00     | 0.00     |         |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bc6e25",
   "metadata": {},
   "source": [
    "## ItemKNN Mitigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac72ee2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import scipy.stats as stats\n",
    "\n",
    "folds_data = {}\n",
    "for i in range(1, 6):\n",
    "    base_fold_path = os.path.join(\"book_folds\", f\"fold_{i}\")\n",
    "    subdirs = [d for d in os.listdir(base_fold_path) if os.path.isdir(os.path.join(base_fold_path, d))]\n",
    "    fold_path = os.path.join(base_fold_path, subdirs[0]) if subdirs else base_fold_path\n",
    "\n",
    "    data = {\n",
    "        'train': pd.read_csv(os.path.join(fold_path, 'train.tsv'), sep='\\t'),\n",
    "        'val_input': pd.read_csv(os.path.join(fold_path, 'val_input.tsv'), sep='\\t'),\n",
    "        'val_target': pd.read_csv(os.path.join(fold_path, 'val_target.tsv'), sep='\\t'),\n",
    "        'test_input': pd.read_csv(os.path.join(fold_path, 'test_input.tsv'), sep='\\t'),\n",
    "        'test_target': pd.read_csv(os.path.join(fold_path, 'test_target.tsv'), sep='\\t'),\n",
    "    }\n",
    "    folds_data[f'fold_{i}'] = data\n",
    "\n",
    "#  Metrics \n",
    "def recall_at_k(recommended, ground_truth, k=10):\n",
    "    recommended_k = recommended[:k]\n",
    "    hits = len(set(recommended_k) & set(ground_truth))\n",
    "    return hits / len(ground_truth) if ground_truth else 0\n",
    "\n",
    "def ndcg_at_k(recommended, ground_truth, k=10):\n",
    "    recommended_k = recommended[:k]\n",
    "    gains = [1 if item in ground_truth else 0 for item in recommended_k]\n",
    "    dcg = sum(g / np.log2(i + 2) for i, g in enumerate(gains))\n",
    "    idcg = sum(1 / np.log2(i + 2) for i in range(min(len(ground_truth), k)))\n",
    "    return dcg / idcg if idcg > 0 else 0\n",
    "\n",
    "# Item KNN Evaluation \n",
    "def evaluate_item_knn(fold_data, input_key, target_key, k=10, topk_sim=100):\n",
    "    train_df = fold_data['train']\n",
    "    input_df = fold_data[input_key]\n",
    "    target_df = fold_data[target_key]\n",
    "\n",
    "    input_df_extended = input_df[['user_id', 'item_id']].copy()\n",
    "    input_df_extended['binary_listen'] = 1\n",
    "    combined_df = pd.concat([train_df, input_df_extended])\n",
    "\n",
    "    users = combined_df['user_id'].unique()\n",
    "    items = combined_df['item_id'].unique()\n",
    "\n",
    "    user_to_idx = {user: i for i, user in enumerate(users)}\n",
    "    item_to_idx = {item: i for i, item in enumerate(items)}\n",
    "    idx_to_item = {i: item for item, i in item_to_idx.items()}\n",
    "\n",
    "    row_idx = combined_df['user_id'].map(user_to_idx)\n",
    "    col_idx = combined_df['item_id'].map(item_to_idx)\n",
    "    data = combined_df['binary_listen'].astype(float)\n",
    "\n",
    "    user_item_matrix = csr_matrix((data, (row_idx, col_idx)), shape=(len(users), len(items)))\n",
    "\n",
    "    item_popularity = np.array(user_item_matrix.sum(axis=0)).flatten()\n",
    "    popularity_penalty = 1 / (np.log1p(item_popularity) + 1e-6)\n",
    "\n",
    "    item_sim = cosine_similarity(user_item_matrix.T, dense_output=True)  \n",
    "\n",
    "    item_sim = item_sim * popularity_penalty[np.newaxis, :]\n",
    "\n",
    "    for i in range(item_sim.shape[0]):\n",
    "        row = item_sim[i]\n",
    "        if np.count_nonzero(row) > topk_sim:\n",
    "            top_k_idx = np.argpartition(row, -topk_sim)[-topk_sim:]\n",
    "            mask = np.ones_like(row, dtype=bool)\n",
    "            mask[top_k_idx] = False\n",
    "            row[mask] = 0\n",
    "            item_sim[i] = row\n",
    "\n",
    "    input_groups = input_df.groupby('user_id')['item_id'].apply(set).to_dict()\n",
    "    target_groups = target_df.groupby('user_id')['item_id'].apply(set).to_dict()\n",
    "\n",
    "    recalls, ndcgs = [], []\n",
    "    user_recommendations = {}\n",
    "\n",
    "    for user in input_groups:\n",
    "        if user not in user_to_idx:\n",
    "            continue\n",
    "\n",
    "        known_items = input_groups[user]\n",
    "        known_indices = [item_to_idx[i] for i in known_items if i in item_to_idx]\n",
    "\n",
    "        if not known_indices:\n",
    "            continue\n",
    "\n",
    "        scores = item_sim[known_indices, :].sum(axis=0)\n",
    "\n",
    "        for idx in known_indices:\n",
    "            scores[idx] = 0\n",
    "\n",
    "        top_items_idx = np.argpartition(scores, -k)[-k:]\n",
    "        top_items_sorted = top_items_idx[np.argsort(-scores[top_items_idx])]\n",
    "        recommended_items = [idx_to_item[i] for i in top_items_sorted if scores[i] > 0]\n",
    "\n",
    "        true_items = target_groups.get(user, set())\n",
    "        recalls.append(recall_at_k(recommended_items, true_items, k))\n",
    "        ndcgs.append(ndcg_at_k(recommended_items, true_items, k))\n",
    "        user_recommendations[user] = recommended_items\n",
    "\n",
    "    return np.mean(recalls), np.mean(ndcgs), user_recommendations, target_groups\n",
    "\n",
    "\n",
    "#  Run Evaluation \n",
    "itemknn_test_targets = {}\n",
    "itemknn_test_recommendations = {}\n",
    "itemknn_test_ndcg_scores = {}\n",
    "\n",
    "for i in range(1, 6):\n",
    "    fold_key = f'fold_{i}'\n",
    "    fold_data = folds_data[fold_key]\n",
    "\n",
    "    _, _, test_recs, test_targets = evaluate_item_knn(fold_data, 'test_input', 'test_target', k=10)\n",
    "    _, test_ndcg, _, _ = evaluate_item_knn(fold_data, 'test_input', 'test_target', k=10)\n",
    "\n",
    "    itemknn_test_recommendations[fold_key] = test_recs\n",
    "    itemknn_test_targets[fold_key] = test_targets\n",
    "    itemknn_test_ndcg_scores[fold_key] = test_ndcg\n",
    "\n",
    "# Bias Metrics\n",
    "def percent_delta_metric(m_reco, m_hist):\n",
    "    return 100 * (m_reco - m_hist) / m_hist if m_hist != 0 else 0.0\n",
    "\n",
    "def kl_divergence(p, q):\n",
    "    epsilon = 1e-10\n",
    "    p = np.array(p) + epsilon\n",
    "    q = np.array(q) + epsilon\n",
    "    return np.sum(p * np.log(p / q))\n",
    "\n",
    "def kendalls_tau(x, y):\n",
    "    return stats.kendalltau(x, y).correlation\n",
    "\n",
    "def pop_bias_metrics(train_df, recommendations, targets, user_info, top_k=10):\n",
    "    popularity_dict = train_df['item_id'].value_counts().to_dict()\n",
    "    all_pop = np.array(list(popularity_dict.values()))\n",
    "    bins = np.quantile(all_pop, np.linspace(0, 1, 11))\n",
    "\n",
    "    def bin_distribution(vals, bins):\n",
    "        binned_counts, _ = np.histogram(vals, bins=bins)\n",
    "        return binned_counts / binned_counts.sum() if binned_counts.sum() > 0 else np.zeros_like(binned_counts)\n",
    "\n",
    "    user_metrics = []\n",
    "\n",
    "    for user_id, rec_tracks in recommendations.items():\n",
    "        true_tracks = targets.get(user_id, [])\n",
    "        if not true_tracks:\n",
    "            continue\n",
    "        hist_vals = [popularity_dict.get(t, 0) for t in true_tracks]\n",
    "        rec_vals = [popularity_dict.get(t, 0) for t in rec_tracks]\n",
    "\n",
    "        metrics = {\n",
    "            'user_id': user_id,\n",
    "            'gender': user_info.get(user_id, None),\n",
    "            '%Î”Mean': percent_delta_metric(np.mean(rec_vals), np.mean(hist_vals)),\n",
    "            '%Î”Median': percent_delta_metric(np.median(rec_vals), np.median(hist_vals)),\n",
    "            '%Î”Var': percent_delta_metric(np.var(rec_vals), np.var(hist_vals)),\n",
    "            '%Î”Skew': percent_delta_metric(stats.skew(rec_vals), stats.skew(hist_vals)),\n",
    "            '%Î”Kurtosis': percent_delta_metric(stats.kurtosis(rec_vals), stats.kurtosis(hist_vals)),\n",
    "            'KL': kl_divergence(bin_distribution(hist_vals, bins), bin_distribution(rec_vals, bins)),\n",
    "            'Kendall_tau': kendalls_tau(bin_distribution(hist_vals, bins), bin_distribution(rec_vals, bins)),\n",
    "        }\n",
    "\n",
    "        user_metrics.append(metrics)\n",
    "\n",
    "    return user_metrics\n",
    "\n",
    "# Aggregate Bias Metrics \n",
    "all_metrics = []\n",
    "gender_metrics = {'f': [], 'm': []}\n",
    "all_ndcgs = []\n",
    "\n",
    "for i in range(1, 6):\n",
    "    fold_key = f'fold_{i}'\n",
    "    fold_data = folds_data[fold_key]\n",
    "\n",
    "    train_df = fold_data['train']\n",
    "    test_targets = itemknn_test_targets[fold_key]\n",
    "    test_recs = itemknn_test_recommendations[fold_key]\n",
    "    ndcg_score = itemknn_test_ndcg_scores[fold_key]\n",
    "    all_ndcgs.append(ndcg_score)\n",
    "\n",
    "    combined_users = pd.concat([\n",
    "        fold_data['train'][['user_id', 'gender']],\n",
    "        fold_data['val_input'][['user_id', 'gender']],\n",
    "        fold_data['test_input'][['user_id', 'gender']]\n",
    "    ]).drop_duplicates()\n",
    "    user_info = combined_users.set_index('user_id')['gender'].to_dict()\n",
    "\n",
    "    user_metrics = pop_bias_metrics(train_df, test_recs, test_targets, user_info)\n",
    "    if user_metrics:\n",
    "        df = pd.DataFrame(user_metrics)\n",
    "        all_metrics.append(df.median(numeric_only=True).to_dict())\n",
    "        for gender in ['f', 'm']:\n",
    "            gdf = df[df['gender'] == gender]\n",
    "            if not gdf.empty:\n",
    "                gender_metrics[gender].append(gdf.median(numeric_only=True).to_dict())\n",
    "\n",
    "#  Results \n",
    "def average_metrics(metrics_list, agg_func=np.median):\n",
    "    if not metrics_list:\n",
    "        return {}\n",
    "    keys = metrics_list[0].keys()\n",
    "    return {k: agg_func([m[k] for m in metrics_list if k in m]) for k in keys}\n",
    "\n",
    "final_all_median = average_metrics(all_metrics)\n",
    "final_female_median = average_metrics(gender_metrics['f'])\n",
    "final_male_median = average_metrics(gender_metrics['m'])\n",
    "final_ndcg_median = np.median(all_ndcgs)\n",
    "\n",
    "def delta(group, overall):\n",
    "    return {k: overall[k] - group.get(k, 0) for k in overall if k in group}\n",
    "\n",
    "delta_f_median = delta(final_female_median, final_all_median)\n",
    "delta_m_median = delta(final_male_median, final_all_median)\n",
    "\n",
    "def print_metrics(label, metrics, include_ndcg):\n",
    "    print(f\"{label:<10}\", end=\"\")\n",
    "    for k in ['%Î”Mean', '%Î”Median', '%Î”Var', '%Î”Skew', '%Î”Kurtosis', 'KL', 'Kendall_tau']:\n",
    "        v = metrics.get(k, 0)\n",
    "        print(f\"| {v:9.2f} \", end=\"\")\n",
    "    if include_ndcg:\n",
    "        print(f\"| {metrics.get('NDCG@10', 0):8.4f} \", end=\"\")\n",
    "    print()\n",
    "\n",
    "final_all_median['NDCG@10'] = final_ndcg_median\n",
    "if final_female_median:\n",
    "    final_female_median['NDCG@10'] = final_ndcg_median\n",
    "if final_male_median:\n",
    "    final_male_median['NDCG@10'] = final_ndcg_median\n",
    "\n",
    "print(\"\\n\\U0001F4CA Item KNN with Popularity Mitigation Results:\")\n",
    "print(\"           | %Î”Mean   | %Î”Median | %Î”Var    | %Î”Skew   | %Î”Kurtosis |    KL    | KendallÏ„ | NDCG@10 \")\n",
    "print(\"-\" * 95)\n",
    "print_metrics(\"All\", final_all_median, include_ndcg=True)\n",
    "if final_female_median:\n",
    "    print_metrics(\"Î”Female\", delta_f_median, include_ndcg=False)\n",
    "if final_male_median:\n",
    "    print_metrics(\"Î”Male\", delta_m_median, include_ndcg=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6be3b6f",
   "metadata": {},
   "source": [
    " Item KNN with Popularity Mitigation Results:\n",
    "\n",
    "|          | %Î”Mean   | %Î”Median | %Î”Var    | %Î”Skew   | %Î”Kurtosis |    KL    | KendallÏ„ | NDCG@10 |\n",
    "|----------|----------|----------|----------|----------|------------|----------|----------|---------|\n",
    "| All      | -80.89   | -75.00   | 0.00     | 0.00     | -112.50    | 23.03    | -0.11    | 0.0017  |\n",
    "| Î”Female  | 2.44     | 0.00     | 0.00     | 0.00     | 0.00       | 0.00     | 0.00     |         |\n",
    "| Î”Male    | -0.89    | 0.00     | 0.00     | 0.00     | 0.00       | 0.00     | 0.00     |         |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49818d9c",
   "metadata": {},
   "source": [
    "## 2.3 Evaluating Popularity Bias Mitigation in Recommendation Algorithms\n",
    "\n",
    "We evaluated the effects of a popularity bias mitigation method on three recommendation algorithms: **RAND**, **ItemKNN**, and **VAE**. The goal was to reduce bias while monitoring changes in performance, mainly measured by NDCG@10.\n",
    "\n",
    "---\n",
    "\n",
    "### RAND  \n",
    "**Before Mitigation:**  \n",
    "- Moderate popularity bias observed with %Î”Mean = -57.50%, %Î”Median = -66.67%, and KL divergence at 1.61.  \n",
    "- Kendallâ€™s Ï„ was +0.48, indicating moderate ranking stability.  \n",
    "- NDCG@10 was very low at 0.0001.  \n",
    "\n",
    "**After Mitigation:**  \n",
    "- Bias further reduced (%Î”Mean to -72.50%, %Î”Median unchanged at -66.67%), but KL divergence increased slightly to 2.30.  \n",
    "- Kendallâ€™s Ï„ dropped to 0.34, showing reduced ranking stability.  \n",
    "- NDCG@10 dropped to zero (0.0000).  \n",
    "\n",
    "**Conclusion:**  \n",
    "RAND is relatively unbiased to begin with and suffers performance degradation after mitigation. Mitigation reduces ranking quality and utility without meaningful fairness benefits.\n",
    "\n",
    "---\n",
    "\n",
    "### ItemKNN  \n",
    "**Before Mitigation:**  \n",
    "- Strong popularity bias with %Î”Mean = -67.46%, %Î”Median = -66.67%, KL divergence at 2.30.  \n",
    "- Kendallâ€™s Ï„ was +0.34, showing reasonable ranking correlation.  \n",
    "- NDCG@10 was 0.0112, modest relevance.  \n",
    "\n",
    "**After Mitigation:**  \n",
    "- Bias further reduced (%Î”Mean to -80.89%, %Î”Median to -75.00%), but KL divergence sharply increased to 23.03, indicating distributional drift.  \n",
    "- Kendallâ€™s Ï„ fell below zero to -0.11, indicating unstable rankings.  \n",
    "- NDCG@10 dropped substantially to 0.0017, nearly losing all relevance.  \n",
    "\n",
    "**Conclusion:**  \n",
    "Mitigation strongly reduces bias but severely harms both recommendation quality and ranking stability in ItemKNN.\n",
    "\n",
    "---\n",
    "\n",
    "### VAE  \n",
    "**Before Mitigation:**  \n",
    "- Moderate bias with %Î”Mean = -63.33%, %Î”Median = -66.67%, and KL divergence at 1.39.  \n",
    "- Kendallâ€™s Ï„ was +0.48, and NDCG@10 was 0.0103, indicating solid performance.  \n",
    "\n",
    "**After Mitigation:**  \n",
    "- Bias metrics remain stable (%Î”Mean unchanged at -63.33%, %Î”Median unchanged at -66.67%), KL divergence stable at 1.39.  \n",
    "- Kendallâ€™s Ï„ remained steady at +0.48.  \n",
    "- NDCG@10 moderately decreased to 0.0057.  \n",
    "\n",
    "**Conclusion:**  \n",
    "VAE is robust and maintains a strong balance of fairness and utility, with minimal degradation after mitigation.\n",
    "\n",
    "---\n",
    "\n",
    "### Final Summary\n",
    "\n",
    "| Algorithm | Bias Reduction | NDCG@10 Before | NDCG@10 After | Overall Verdict                             |\n",
    "|-----------|----------------|----------------|---------------|--------------------------------------------|\n",
    "| RAND      | Moderate       | 0.0001         | 0.0000        | Already fair; mitigation reduces utility  |\n",
    "| ItemKNN   | High           | 0.0112         | 0.0017        | Bias fixed but recommendation quality collapses |\n",
    "| VAE       | Moderate       | 0.0103         | 0.0057        | Best trade-off of fairness and utility     |\n",
    "\n",
    "\n",
    "Using **VAE** in scenarios in which fairness is important without sacrificing recommendation quality.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3600fab8",
   "metadata": {},
   "source": [
    "## 3. Final Comparison of both datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b28f8a",
   "metadata": {},
   "source": [
    "####  LastFM-2 Dataset - Full Table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220080f0",
   "metadata": {},
   "source": [
    "| Alg.     | Users       | %Î”Mean | %Î”Median | %Î”Var | %Î”Skew | %Î”Kurtosis |   KL  | Kendallâ€™s Ï„ | NDCG@10  |\n",
    "|----------|-------------|--------|----------|--------|--------|-------------|--------|--------------|----------|\n",
    "| RAND     | All         | -94.7  | -94.34   | -99.64 | 0.00   | -92.42      | 3.56   | 0.18         | 0.0001   |\n",
    "|          | Î”Female     | +0.88  | +1.27    | +0.04  | -4.85  | +7.60       | +0.31  | +0.02        | â€”        |\n",
    "|          | Î”Male       | -0.37  | -0.59    | -0.02  | +0.00  | -2.13       | -0.08  | -0.01        | â€”        |\n",
    "| POP      | All         | 956.08 | 2321.62  | 310.19 | -23.68 | -97.02      | 5.68   | 0.62         | 0.0203   |\n",
    "|          | Î”Female     | +138.43| +579.05  | +57.31 | -5.89  | +4.56       | +0.53  | +0.00        | â€”        |\n",
    "|          | Î”Male       | -74.30 | -254.76  | -63.26 | +3.03  | +0.94       | -0.23  | +0.04        | â€”        |\n",
    "| ALS      | All         | +3.35  | +79.87   | -48.00 | -28.96 | -100.88     | 5.02   | 0.63         | 0.0204   |\n",
    "|          | Î”Female     | -17.81 | -6.35    | -34.77 | -11.27 | -3.87       | +0.52  | -0.04        | â€”        |\n",
    "|          | Î”Male       | +3.54  | +0.88    | +10.63 | +5.20  | +0.54       | -0.11  | +0.00        | â€”        |\n",
    "| BPR      | All         | 249.78 | 677.16   | 152.22 | -45.42 | -104.49     | 5.78   | 0.61         | 0.0117   |\n",
    "|          | Î”Female     | +59.65 | +172.71  | +71.89 | -3.07  | +0.33       | +0.59  | -0.01        | â€”        |\n",
    "|          | Î”Male       | -23.94 | -71.35   | -26.15 | +1.28  | -0.21       | -0.19  | +0.04        | â€”        |\n",
    "| ItemKNN  | All         | 223.97 | 389.08   | 159.65 | -26.03 | -99.16      | 5.19   | 0.58         | 0.1573   |\n",
    "|          | Î”Female     | -19.98 | -7.60    | -51.50 | -10.39 | +1.14       | +0.76  | -0.05        | â€”        |\n",
    "|          | Î”Male       | +9.48  | +3.66    | +14.67 | +3.03  | -0.58       | -0.03  | +0.02        | â€”        |\n",
    "| SLIM     | All         | 468.28 | 1157.50  | 378.16 | -27.31 | -97.03      | 5.57   | 0.61         | 0.0750   |\n",
    "|          | Î”Female     | +53.39 | +218.87  | +54.50 | -5.65  | +0.46       | +0.54  | -0.01        | â€”        |\n",
    "|          | Î”Male       | -22.72 | -110.25  | -38.73 | +1.65  | +0.00       | -0.21  | +0.04        | â€”        |\n",
    "| VAE      | All         | -94.90 | -94.44   | -99.65 | 0.00   | -92.44      | 3.72   | 0.18         | 0.3944   |\n",
    "|          | Î”Female     | +0.69  | +1.26    | +0.03  | -2.40  | +5.18       | +0.04  | +0.01        | â€”        |\n",
    "|          | Î”Male       | -0.34  | -0.57    | -0.00  | +0.00  | -2.17       | -0.11  | -0.01        | â€”        |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff935758",
   "metadata": {},
   "source": [
    "#### Book dataset - Full Table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d2caba",
   "metadata": {},
   "source": [
    "| Alg.     | Users       | %Î”Mean | %Î”Median | %Î”Var | %Î”Skew | %Î”Kurtosis |   KL  | Kendallâ€™s Ï„ | NDCG@10  |\n",
    "|----------|-------------|--------|----------|--------|--------|-------------|--------|--------------|----------|\n",
    "| RAND     | All         | -57.50 | -66.67   | 0.00   | 0.00   | -189.60     | 1.61   | 0.48         | 0.0001   |\n",
    "|          | Î”Female     | +4.51  | +0.00    | 0.00   | 0.00   | -17.06      | +0.00  | +0.00        | â€”        |\n",
    "|          | Î”Male       | -5.14  | +0.00    | 0.00   | 0.00   | +8.75       | +0.35  | +0.00        | â€”        |\n",
    "| POP      | All         | 1463.66| 1303.85  | 0.00   | 0.00   | -109.99     | 0.00   | 0.72         | 0.0072   |\n",
    "|          | Î”Female     | -93.01 | -52.68   | 0.00   | 0.00   | -9.23       | 0.00   | 0.00         | â€”        |\n",
    "|          | Î”Male       | +73.17 | +65.38   | 0.00   | 0.00   | +3.30       | 0.00   | 0.00         | â€”        |\n",
    "| ALS      | All         | 170.20 | 139.29   | 0.00   | 0.00   | -95.45      | 0.00   | 1.00         | 0.0018   |\n",
    "|          | Î”Female     | -21.49 | -3.30    | 0.00   | 0.00   | -1.40       | 0.00   | 0.00         | â€”        |\n",
    "|          | Î”Male       | +17.08 | +8.04    | 0.00   | 0.00   | +2.00       | 0.00   | 0.00         | â€”        |\n",
    "| BPR      | All         | 128.07 | 65.82    | 0.00   | 0.00   | -89.18      | 0.00   | 0.73         | 0.0047   |\n",
    "|          | Î”Female     | -37.34 | -32.57   | 0.00   | 0.00   | +1.15       | 0.00   | 0.00         | â€”        |\n",
    "|          | Î”Male       | +28.07 | +19.18   | 0.00   | 0.00   | -2.05       | 0.00   | 0.00         | â€”        |\n",
    "| ItemKNN  | All         | -67.46 | -66.67   | 0.00   | 0.00   | -116.54     | 2.30   | 0.34         | 0.0112   |\n",
    "|          | Î”Female     | +5.87  | +0.00    | 0.00   | 0.00   | -0.24       | 0.00   | -0.01        | â€”        |\n",
    "|          | Î”Male       | -0.80  | +0.00    | 0.00   | 0.00   | -0.66       | 0.00   | +0.00        | â€”        |\n",
    "| SLIM     | All         | 380.31 | 472.73   | 0.00   | 0.00   | -88.09      | 0.00   | 1.00         | 0.0104   |\n",
    "|          | Î”Female     | -42.55 | +6.06    | 0.00   | 0.00   | -4.03       | 0.00   | 0.00         | â€”        |\n",
    "|          | Î”Male       | +39.06 | +24.73   | 0.00   | 0.00   | +3.71       | 0.00   | 0.00         | â€”        |\n",
    "| VAE      | All         | -63.33 | -66.67   | 0.00   | 0.00   | -147.67     | 1.39   | 0.48         | 0.0103   |\n",
    "|          | Î”Female     | +2.54  | +0.00    | 0.00   | 0.00   | -12.89      | 0.00   | 0.00         | â€”        |\n",
    "|          | Î”Male       | -3.33  | +0.00    | 0.00   | 0.00   | +5.58       | 0.00   | 0.00         | â€”        |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3785a9",
   "metadata": {},
   "source": [
    "#### Comparison based on Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066271bd",
   "metadata": {},
   "source": [
    "| Algorithm | Metric        | LastFMâ€‘2 Overall | Book Overall  | LastFMâ€‘2 Female | Book Female | LastFMâ€‘2 Male | Book Male |\n",
    "|-----------|---------------|------------------|--------------|-----------------|-------------|---------------|-----------|\n",
    "| **VAE**   | %Î”Mean        | -94.90           | -63.33      | 0.69            | 2.54      | -0.34         | -3.33   |\n",
    "|           | %Î”Median      | -94.44           | -66.67      | 1.26            | 0.00      | -0.57         | 0.00    |\n",
    "|           | %Î”Var         | -99.65           | 0.00        | 0.03            | 0.00      | -0.00         | 0.00    |\n",
    "|           | %Î”Skew        | 0.00             | 0.00        | -2.40           | 0.00      | 0.00          | 0.00    |\n",
    "|           | %Î”Kurtosis    | -92.44           | -147.67     | 5.18            | -12.89    | -2.17         | 5.58    |\n",
    "|           | KL            | 3.72             | 1.39        | 0.04            | 0.00      | -0.11         | 0.00    |\n",
    "|           | KendallÏ„      | 0.18             | 0.48        | 0.01            | 0.00      | -0.01         | 0.00    |\n",
    "|           | NDCG@10       | **0.3944**       | 0.0103      | â€”               | â€”           | â€”             | â€”         |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16763ea5",
   "metadata": {},
   "source": [
    "### Performance Difference Between Datasets:\n",
    "VAEâ€™s key statistics (mean, median, variance) drop drastically on LastFM-2 compared to Book, indicating very different data characteristics or model behavior. The LastFM-2 dataset shows stronger variability and ranking quality (NDCG@10) than the Book dataset, where performance is much lower.\n",
    "\n",
    "### Gender Comparison:\n",
    "Differences between female and male metrics are very small across both datasets, suggesting no significant gender bias in VAEâ€™s outputs. Both genders show similarly stable or slightly varying results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1c1f0b",
   "metadata": {},
   "source": [
    "| Algorithm | Metric        | LastFMâ€‘2 Overall | Book Overall  | LastFMâ€‘2 Female | Book Female | LastFMâ€‘2 Male | Book Male |\n",
    "|-----------|---------------|------------------|--------------|-----------------|-------------|---------------|-----------|\n",
    "| **ItemKNN** | %Î”Mean       | 223.97           | -67.46      | -19.98          | 5.87      | 9.48          | -0.80   |\n",
    "|             | %Î”Median     | 389.08           | -66.67      | -7.60           | 0.00      | 3.66          | 0.00    |\n",
    "|             | %Î”Var        | 159.65           | 0.00        | -51.50          | 0.00      | 14.67         | 0.00    |\n",
    "|             | %Î”Skew       | -26.03           | 0.00        | -10.39          | 0.00      | 3.03          | 0.00    |\n",
    "|             | %Î”Kurtosis   | -99.16           | -116.54     | 1.14            | -0.24     | -0.58         | -0.66   |\n",
    "|             | KL           | 5.19             | 2.30        | 0.76            | 0.00      | -0.03         | 0.00    |\n",
    "|             | KendallÏ„     | 0.58             | 0.34        | -0.05           | -0.01     | 0.02          | 0.00    |\n",
    "|             | NDCG@10      | 0.1573           | 0.0112      | â€”               | â€”          | â€”             | â€”         |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88055333",
   "metadata": {},
   "source": [
    "**Performance Difference Between Datasets:**  \n",
    "ItemKNN shows large differences in mean, median, variance, and skew between LastFM-2 and Book datasets, highlighting distinct data properties or model reactions. LastFM-2 generally exhibits higher variability and better overall metric values, while the Book dataset often has reduced or near-zero values, indicating weaker or different performance patterns.\n",
    "\n",
    "**Gender Comparison:**  \n",
    "Gender differences in ItemKNN metrics are mostly small to moderate, with a few moderate differences in female metrics on the Book dataset. Male and female metrics are relatively stable and similar across datasets, suggesting minimal gender bias in model behavior.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37738c75",
   "metadata": {},
   "source": [
    "| Algorithm | Metric        | LastFMâ€‘2 Overall | Book Overall  | LastFMâ€‘2 Female | Book Female | LastFMâ€‘2 Male | Book Male |\n",
    "|-----------|---------------|------------------|--------------|-----------------|-------------|---------------|-----------|\n",
    "| **RAND**   | %Î”Mean        | -94.70           | -57.50      | 0.88            | 4.51      | -0.37         | -5.14   |\n",
    "|            | %Î”Median      | -94.34           | -66.67      | 1.27            | 0.00      | -0.59         | 0.00    |\n",
    "|            | %Î”Var         | -99.64           | 0.00       | 0.04            | 0.00      | -0.02         | 0.00    |\n",
    "|            | %Î”Skew        | 0.00             | 0.00        | -4.85           | 0.00      | 0.00          | 0.00    |\n",
    "|            | %Î”Kurtosis    | -92.42           | -189.60     | 7.60            | -17.06    | -2.13         | 8.75    |\n",
    "|            | KL            | 3.56             | 1.61        | 0.31            | 0.00      | -0.08         | 0.35    |\n",
    "|            | KendallÏ„      | 0.18             | 0.48        | 0.02            | 0.00      | -0.01         | 0.00    |\n",
    "|            | NDCG@10       | 0.0001           | 0.0001      | â€”               | â€”           | â€”             | â€”         |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5e086c",
   "metadata": {},
   "source": [
    "**Performance Difference Between Datasets:**  \n",
    "RAND shows a drastic decrease in mean, median, and variance on LastFM-2 compared to the Book dataset, indicating significant differences in data distribution or model output. The Book dataset generally has less variability but exhibits some strong deviations in kurtosis and KL divergence. Overall, the performance metrics (NDCG@10) are very low and similar across datasets.\n",
    "\n",
    "**Gender Comparison:**  \n",
    "Differences between female and male metrics for RAND are mostly very small or moderate across datasets, with some exceptions in kurtosis and KL divergence on the Book dataset showing strong differences. This suggests minimal but some variability in gender-related model behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c76795",
   "metadata": {},
   "source": [
    "| Algorithm | Metric        | LastFMâ€‘2 Overall | Book Overall  | LastFMâ€‘2 Female | Book Female | LastFMâ€‘2 Male | Book Male |\n",
    "|-----------|---------------|------------------|--------------|-----------------|-------------|---------------|-----------|\n",
    "| **ALS**    | %Î”Mean        | 3.35             | 170.20      | -17.81          | -21.49    | 3.54          | 17.08   |\n",
    "|            | %Î”Median      | 79.87            | 139.29      | -6.35           | -3.30     | 0.88          | 8.04    |\n",
    "|            | %Î”Var         | -48.00           | 0.00       | -34.77          | 0.00      | 10.63         | 0.00    |\n",
    "|            | %Î”Skew        | -28.96           | 0.00        | -11.27          | 0.00      | 5.20          | 0.00    |\n",
    "|            | %Î”Kurtosis    | -100.88          | -95.45      | -3.87           | -1.40     | 0.54          | 2.00    |\n",
    "|            | KL            | 5.02             | 0.00        | 0.52            | 0.00      | -0.11         | 0.00    |\n",
    "|            | KendallÏ„      | 0.63             | 1.00        | -0.04           | 0.00      | 0.00          | 0.00    |\n",
    "|            | NDCG@10       | 0.0204           | 0.0018      | â€”               | â€”           | â€”             | â€”         |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97462a2c",
   "metadata": {},
   "source": [
    "**Performance Difference Between Datasets:**  \n",
    "ALS shows a significant increase in mean and median on the Book dataset compared to LastFM-2, highlighting substantial dataset differences. Variance, skewness, and KL divergence are much lower or zero on the Book dataset, indicating less variability. Overall, performance metrics like NDCG@10 are very low but slightly better on LastFM-2.\n",
    "\n",
    "**Gender Comparison:**  \n",
    "Gender differences are mostly small to moderate across metrics, with some notable stronger differences in mean, median, and Kendallâ€™s tau on the Book dataset for males. This suggests some gender-related variability in ALSâ€™s behavior, especially on the Book dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9ab3fc",
   "metadata": {},
   "source": [
    "| Algorithm | Metric        | LastFMâ€‘2 Overall | Book Overall  | LastFMâ€‘2 Female | Book Female | LastFMâ€‘2 Male | Book Male |\n",
    "|-----------|---------------|------------------|--------------|-----------------|-------------|---------------|-----------|\n",
    "| **BPR**    | %Î”Mean        | 249.78           | 128.07      | 59.65           | -37.34    | -23.94        | 28.07   |\n",
    "|            | %Î”Median      | 677.16           | 65.82       | 172.71          | -32.57    | -71.35        | 19.18   |\n",
    "|            | %Î”Var         | 152.22           | 0.00        | 71.89           | 0.00      | -26.15        | 0.00    |\n",
    "|            | %Î”Skew        | -45.42           | 0.00        | -3.07           | 0.00      | 1.28          | 0.00    |\n",
    "|            | %Î”Kurtosis    | -104.49          | -89.18      | 0.33            | 1.15      | -0.21         | -2.05   |\n",
    "|            | KL            | 5.78             | 0.00        | 0.59            | 0.00      | -0.19         | 0.00    |\n",
    "|            | KendallÏ„      | 0.61             | 0.73        | -0.01           | 0.00      | 0.04          | 0.00    |\n",
    "|            | NDCG@10       | 0.0117           | 0.0047      | â€”               | â€”           | â€”             | â€”         |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28de036",
   "metadata": {},
   "source": [
    "**Performance Difference Between Datasets:**  \n",
    "BPR exhibits large increases in mean, median, and variance on LastFM-2 compared to the Book dataset, indicating strong differences in data distribution and model response. The Book dataset shows moderate to significant declines in female metrics but some increases for males, suggesting dataset-specific behavior. Overall, ranking quality (NDCG@10) is very low on both datasets but slightly higher on LastFM-2.\n",
    "\n",
    "**Gender Comparison:**  \n",
    "Gender differences are more pronounced, especially in mean and median metrics where females and males show opposite trends on the Book dataset (significant decreases for females, increases for males). This points to potential gender-related biases or disparities in BPRâ€™s outputs, particularly on the Book dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c255580",
   "metadata": {},
   "source": [
    "| Algorithm | Metric        | LastFMâ€‘2 Overall | Book Overall  | LastFMâ€‘2 Female | Book Female | LastFMâ€‘2 Male | Book Male |\n",
    "|-----------|---------------|------------------|--------------|-----------------|-------------|---------------|-----------|\n",
    "| **SLIM**   | %Î”Mean        | 468.28           | 380.31      | 53.39           | -42.55    | -22.72        | 39.06   |\n",
    "|            | %Î”Median      | 1157.50          | 472.73      | 218.87          | 6.06      | -110.25       | 24.73   |\n",
    "|            | %Î”Var         | 378.16           | 0.00        | 54.50           | 0.00      | -38.73        | 0.00    |\n",
    "|            | %Î”Skew        | -27.31           | 0.00        | -5.65           | 0.00      | 1.65          | 0.00    |\n",
    "|            | %Î”Kurtosis    | -97.03           | -88.09      | 0.46            | -4.03     | 0.00          | 3.71    |\n",
    "|            | KL            | 5.57             | 0.00        | 0.54            | 0.00      | -0.21         | 0.00    |\n",
    "|            | KendallÏ„      | 0.61             | 1.00        | -0.01           | 0.00      | 0.04          | 0.00    |\n",
    "|            | NDCG@10       | 0.0750           | 0.0104      | â€”               | â€”           | â€”             | â€”         |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b295e24",
   "metadata": {},
   "source": [
    "**Performance Difference Between Datasets:**  \n",
    "SLIM shows very large increases in mean, median, and variance on LastFM-2 compared to the Book dataset, highlighting strong differences in data properties and model response. The Book dataset displays moderate to significant drops in female metrics but increases for males, reflecting contrasting behavior across genders. Overall ranking quality (NDCG@10) is low but higher on LastFM-2 than Book.\n",
    "\n",
    "**Gender Comparison:**  \n",
    "Gender differences are notable, with females experiencing substantial decreases on the Book dataset, while males tend to show increases. This suggests potential gender bias or differing model performance by gender, particularly pronounced in the Book dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a3cbd1",
   "metadata": {},
   "source": [
    "| Algorithm | Metric        | LastFMâ€‘2 Overall | Book Overall  | LastFMâ€‘2 Female | Book Female | LastFMâ€‘2 Male | Book Male |\n",
    "|-----------|---------------|------------------|--------------|-----------------|-------------|---------------|-----------|\n",
    "| **POP**    | %Î”Mean        | 956.08           | 1463.66     | 138.43          | -93.01    | -74.30        | 73.17   |\n",
    "|            | %Î”Median      | 2321.62          | 1303.85     | 579.05          | -52.68    | -254.76       | 65.38   |\n",
    "|            | %Î”Var         | 310.19           | 0.00        | 57.31           | 0.00      | -63.26        | 0.00    |\n",
    "|            | %Î”Skew        | -23.68           | 0.00        | -5.89           | 0.00      | 3.03          | 0.00    |\n",
    "|            | %Î”Kurtosis    | -97.02           | -109.99     | 4.56            | -9.23     | 0.94          | 3.30    |\n",
    "|            | KL            | 5.68             | 0.00        | 0.53            | 0.00      | -0.23         | 0.00    |\n",
    "|            | KendallÏ„      | 0.62             | 0.72        | 0.00            | 0.00      | 0.04          | 0.00    |\n",
    "|            | NDCG@10       | 0.0203           | 0.0072      | â€”               | â€”           | â€”             | â€”         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e0304c",
   "metadata": {},
   "source": [
    "**Performance Difference Between Datasets:**  \n",
    "POP exhibits extremely large increases in mean and median on both LastFM-2 and Book datasets overall, with the Book dataset showing even more pronounced spikes. Variance also rises substantially on LastFM-2 but remains stable on Book. Despite these large metric changes, ranking quality (NDCG@10) remains low, though slightly better on LastFM-2.\n",
    "\n",
    "**Gender Comparison:**  \n",
    "Significant gender disparities are evident, especially in the Book dataset where female metrics drop sharply while male metrics increase noticeably. This suggests potential gender bias or differing model effectiveness between genders, particularly in the Book dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82746e13",
   "metadata": {},
   "source": [
    "## 4. Generalizability of Results from LFM-2b to Book Dataset\n",
    "\n",
    "The results demonstrate limited generalizability between LFM-2b and the Book dataset. Key metrics such as mean, median, and variance show significant differences, often with large performance shifts and opposing trends. This suggests that models behave quite differently depending on dataset characteristics, meaning that findings on LFM-2b may not reliably predict performance on the Book dataset.\n",
    "\n",
    "Some algorithms, such as **VAE** and **RAND**, show more stable gender performance within datasets but still differ greatly between datasets. Other algorithms exhibit larger variability across both gender and datasets, highlighting the challenge of generalization.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
